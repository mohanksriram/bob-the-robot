{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "import random\n",
    "\n",
    "def hide_toggle(for_next=False):\n",
    "    this_cell = \"\"\"$('div.cell.code_cell.rendered.selected')\"\"\"\n",
    "    next_cell = this_cell + '.next()'\n",
    "\n",
    "    toggle_text = 'Toggle show/hide'  # text shown on toggle link\n",
    "    target_cell = this_cell  # target cell to control with toggle\n",
    "    js_hide_current = ''  # bit of JS to permanently hide code in current cell (only when toggling next cell)\n",
    "\n",
    "    if for_next:\n",
    "        target_cell = next_cell\n",
    "        toggle_text += ' next cell'\n",
    "        js_hide_current = this_cell + '.find(\"div.input\").hide();'\n",
    "\n",
    "    js_f_name = 'code_toggle_{}'.format(str(random.randint(1,2**64)))\n",
    "\n",
    "    html = \"\"\"\n",
    "        <script>\n",
    "            function {f_name}() {{\n",
    "                {cell_selector}.find('div.input').toggle();\n",
    "            }}\n",
    "\n",
    "            {js_hide_current}\n",
    "        </script>\n",
    "\n",
    "        <a href=\"javascript:{f_name}()\">{toggle_text}</a>\n",
    "    \"\"\".format(\n",
    "        f_name=js_f_name,\n",
    "        cell_selector=target_cell,\n",
    "        js_hide_current=js_hide_current, \n",
    "        toggle_text=toggle_text\n",
    "    )\n",
    "\n",
    "    return HTML(html)\n",
    "hide_toggle()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### All imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import functools\n",
    "import sys\n",
    "\n",
    "import gym\n",
    "import gym.wrappers\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import distributions, nn\n",
    "\n",
    "import pfrl\n",
    "from pfrl import experiments, replay_buffers, utils\n",
    "from pfrl.nn.lmbda import Lambda\n",
    "\n",
    "from distutils.version import LooseVersion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import robosuite as suite\n",
    "from robosuite.wrappers import GymWrapper\n",
    "\n",
    "from robosuite.controllers import load_controller_config, ALL_CONTROLLERS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args(dict):\n",
    "    def __init__(self):\n",
    "        dict.__init__(self)\n",
    "        self.outdir = \"results4\"\n",
    "        self.num_envs = 1\n",
    "        self.seed = 0\n",
    "        self.gpu = 0\n",
    "        self.load = \"\" # directory to load agent from\n",
    "        self.steps = 2000*2500 # total number of timesteps to train the agent.\n",
    "        self.eval_n_runs = 2500 # Number of episodes run for each evaluation.\n",
    "        self.eval_interval = 25000 # Interval in timesteps between evaluations\n",
    "        self.replay_start_size = 3300 # Minimum replay buffer size before performing gradient updates.\n",
    "        self.batch_size = 128 # Minibatch size\n",
    "        self.update_interval = 2500\n",
    "        self.n_times_update = 1000\n",
    "        self.render = False\n",
    "        self.demo = False\n",
    "        self.load_pretrained = False\n",
    "        self.pretrained_type = \"best\"\n",
    "        self.monitor = False\n",
    "        self.log_interval = 20000 # Interval in timesteps between outputting log messages during training\n",
    "        self.log_level = logging.INFO\n",
    "        self.policy_output_scale = 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Utilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Environment utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_config = {\n",
    "     \"control_freq\": 20,\n",
    "    \"env_name\": \"Lift\",\n",
    "    \"hard_reset\": False,\n",
    "    \"horizon\": 500,\n",
    "    \"ignore_done\": True,\n",
    "    \"reward_scale\": 1.0,\n",
    "    \"robots\": [\n",
    "      \"Sawyer\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "controller_config = load_controller_config(default_controller=\"OSC_POSE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(controller_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Environment utils\n",
    "\n",
    "def make_env(process_idx, test):\n",
    "        env = GymWrapper(\n",
    "        suite.make(**env_config,\n",
    "                 has_renderer=False,\n",
    "                 has_offscreen_renderer=False,\n",
    "                 use_object_obs=True,\n",
    "                 use_camera_obs=False,\n",
    "                 reward_shaping=True,\n",
    "                 controller_configs=controller_config,\n",
    "                 )\n",
    "        )\n",
    "        # Unwrap TimiLimit wrapper\n",
    "        assert isinstance(env, gym.wrappers.TimeLimit)\n",
    "        env = env.env\n",
    "        # Use different random seeds for train and test envs\n",
    "        process_seed = int(process_seeds[process_idx])\n",
    "        env_seed = 2 ** 32 - 1 - process_seed if test else process_seed\n",
    "        env.seed(env_seed)\n",
    "        # Cast observations to float32 because our model uses float32\n",
    "        env = pfrl.wrappers.CastObservationToFloat32(env)\n",
    "        # Normalize action space to [-1, 1]^n\n",
    "        env = pfrl.wrappers.NormalizeActionSpace(env)\n",
    "        if args.monitor:\n",
    "            env = gym.wrappers.Monitor(env, args.outdir)\n",
    "        if args.render:\n",
    "            env = pfrl.wrappers.Render(env)\n",
    "        return env\n",
    "\n",
    "def make_batch_env(test):\n",
    "    return pfrl.envs.SerialVectorEnv(\n",
    "            [make_env(0, test)]\n",
    "        )\n",
    "hide_toggle()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Autodiff utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### Autodiff package utils\n",
    "\n",
    "def squashed_diagonal_gaussian_head(x):\n",
    "        assert x.shape[-1] == action_size * 2\n",
    "        mean, log_scale = torch.chunk(x, 2, dim=1)\n",
    "        log_scale = torch.clamp(log_scale, -20.0, 2.0)\n",
    "        var = torch.exp(log_scale * 2)\n",
    "        base_distribution = distributions.Independent(\n",
    "            distributions.Normal(loc=mean, scale=torch.sqrt(var)), 1\n",
    "        )\n",
    "        # cache_size=1 is required for numerical stability\n",
    "        return distributions.transformed_distribution.TransformedDistribution(\n",
    "            base_distribution, [distributions.transforms.TanhTransform(cache_size=1)]\n",
    "        )\n",
    "\n",
    "def make_q_func_with_optimizer():\n",
    "        q_func = nn.Sequential(\n",
    "            pfrl.nn.ConcatObsAndAction(),\n",
    "            nn.Linear(obs_size + action_size, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 1),\n",
    "        )\n",
    "        torch.nn.init.xavier_uniform_(q_func[1].weight)\n",
    "        torch.nn.init.xavier_uniform_(q_func[3].weight)\n",
    "        torch.nn.init.xavier_uniform_(q_func[5].weight)\n",
    "        q_func_optimizer = torch.optim.Adam(q_func.parameters(), lr=5e-4)\n",
    "        return q_func, q_func_optimizer\n",
    "\n",
    "def burnin_action_func():\n",
    "        \"\"\"Select random actions until model is updated one or more times.\"\"\"\n",
    "        return np.random.uniform(action_space.low, action_space.high).astype(np.float32)\n",
    "    \n",
    "hide_toggle()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = Args()\n",
    "\n",
    "logging.basicConfig(level=args.log_level, stream=sys.stdout, format='')\n",
    "outdir = experiments.prepare_output_dir(args, args.outdir, None)\n",
    "\n",
    "# Set a random seed used in PFRL\n",
    "utils.set_random_seed(args.seed)\n",
    "process_seeds = np.arange(args.num_envs) + args.seed * args.num_envs\n",
    "\n",
    "sample_env = make_env(process_idx=0, test=False)\n",
    "timestep_limit = 500#sample_env.spec.max_episode_steps\n",
    "obs_space = sample_env.observation_space\n",
    "action_space = sample_env.action_space\n",
    "print(\"Observation space:\", obs_space)\n",
    "print(\"Action space:\", action_space)\n",
    "\n",
    "obs_size = obs_space.low.size\n",
    "action_size = action_space.low.size\n",
    "hide_toggle()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(timestep_limit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if LooseVersion(torch.__version__) < LooseVersion(\"1.5.0\"):\n",
    "        raise Exception(\"This script requires a PyTorch version >= 1.5.0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy = nn.Sequential(\n",
    "        nn.Linear(obs_size, 256),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(256, 256),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(256, action_size * 2),\n",
    "        Lambda(squashed_diagonal_gaussian_head),\n",
    "    )\n",
    "torch.nn.init.xavier_uniform_(policy[0].weight)\n",
    "torch.nn.init.xavier_uniform_(policy[2].weight)\n",
    "torch.nn.init.xavier_uniform_(policy[4].weight, gain=args.policy_output_scale)\n",
    "policy_optimizer = torch.optim.Adam(policy.parameters(), lr=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_func1, q_func1_optimizer = make_q_func_with_optimizer()\n",
    "q_func2, q_func2_optimizer = make_q_func_with_optimizer()\n",
    "\n",
    "rbuf = replay_buffers.ReplayBuffer(10 ** 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = pfrl.agents.SoftActorCritic(\n",
    "        policy,\n",
    "        q_func1,\n",
    "        q_func2,\n",
    "        policy_optimizer,\n",
    "        q_func1_optimizer,\n",
    "        q_func2_optimizer,\n",
    "        rbuf,\n",
    "        gamma=0.99,\n",
    "        replay_start_size=args.replay_start_size,\n",
    "        update_interval=args.update_interval,\n",
    "        n_times_update=args.n_times_update,\n",
    "        gpu=args.gpu,\n",
    "        minibatch_size=args.batch_size,\n",
    "        burnin_action_func=burnin_action_func,\n",
    "        entropy_target=-action_size,\n",
    "        temperature_optimizer_lr=3e-4,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args.load = \"./results4/best\"\n",
    "agent.load(args.load)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args.eval_n_runs = 10\n",
    "eval_stats = experiments.eval_performance(\n",
    "            env=make_batch_env(test=True),\n",
    "            agent=agent,\n",
    "            n_steps=None,\n",
    "            n_episodes=args.eval_n_runs,\n",
    "            max_episode_len=timestep_limit,\n",
    "        )\n",
    "print(\n",
    "    \"n_runs: {} mean: {} median: {} stdev {}\".format(\n",
    "        args.eval_n_runs,\n",
    "        eval_stats[\"mean\"],\n",
    "        eval_stats[\"median\"],\n",
    "        eval_stats[\"stdev\"],\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments.train_agent_batch_with_evaluation(\n",
    "            agent=agent,\n",
    "            env=make_batch_env(test=False),\n",
    "            eval_env=make_batch_env(test=True),\n",
    "            outdir=args.outdir,\n",
    "            steps=args.steps,\n",
    "            eval_n_steps=None,\n",
    "            eval_n_episodes=args.eval_n_runs,\n",
    "            eval_interval=args.eval_interval,\n",
    "            log_interval=args.log_interval,\n",
    "            max_episode_len=timestep_limit,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args.eval_n_runs = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_stats = experiments.eval_performance(\n",
    "            env=make_batch_env(test=True),\n",
    "            agent=agent,\n",
    "            n_steps=None,\n",
    "            n_episodes=args.eval_n_runs,\n",
    "            max_episode_len=timestep_limit,\n",
    "        )\n",
    "print(\n",
    "    \"n_runs: {} mean: {} median: {} stdev {}\".format(\n",
    "        args.eval_n_runs,\n",
    "        eval_stats[\"mean\"],\n",
    "        eval_stats[\"median\"],\n",
    "        eval_stats[\"stdev\"],\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args.render = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
