{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "import pfrl\n",
    "\n",
    "import gym\n",
    "import gym.spaces\n",
    "import gym.wrappers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import robosuite as suite\n",
    "from robosuite.wrappers import GymWrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adding key: robot0_robot-state\n",
      "adding key: object-state\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\91953\\Anaconda3\\envs\\pfrl\\lib\\site-packages\\gym\\logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    }
   ],
   "source": [
    "### Create the sawyer lift environment\n",
    "env = GymWrapper(\n",
    "        suite.make(\n",
    "            \"Lift\",\n",
    "            robots=\"Sawyer\",                # use Sawyer robot\n",
    "            use_camera_obs=False,           # do not use pixel observations\n",
    "            has_offscreen_renderer=False,   # not needed since not using pixel obs\n",
    "            has_renderer=False,              # make sure we can render to the screen\n",
    "            reward_shaping=True,            # use dense rewards\n",
    "            control_freq=20,                # control should happen fast enough so that simulation looks smooth\n",
    "        )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ref: https://github.com/ARISE-Initiative/robosuite-benchmark/blob/master/runs/Lift-Sawyer-OSC-POSE-SEED129/Lift_Sawyer_OSC_POSE_SEED129_2020_09_21_20_07_20_0000--s-0/variant.json\n",
    "### args setup\n",
    "outdir = \"results\"\n",
    "steps = 2 * 10 ** 6 #num_epochs\n",
    "# num_eval_steps_per_epoch = 2500\n",
    "eval_interval = 800 # steps/num_eval_steps_per_epoch\n",
    "eval_n_runs = 1\n",
    "offset = 3300\n",
    "\n",
    "render = False\n",
    "demo = True\n",
    "load_pretrained = False\n",
    "pretrained_type = \"best\"\n",
    "log_level = logging.INFO\n",
    "seed = 0\n",
    "trpo_update_interval = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## initial setup\n",
    "logging.basicConfig(level=log_level)\n",
    "pfrl.utils.set_random_seed(seed)\n",
    "outdir = pfrl.experiments.prepare_output_dir(None, outdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_env(env, seed, outdir, test=False, monitor=False, render=False):\n",
    "        # Use different random seeds for train and test envs\n",
    "        env_seed = 2 ** 32 - 1 - seed if test else seed\n",
    "        env.seed(env_seed)\n",
    "        # Cast observations to float32 because our model uses float32\n",
    "        env = pfrl.wrappers.CastObservationToFloat32(env)\n",
    "        if monitor:\n",
    "            env = gym.wrappers.Monitor(env, outdir)\n",
    "        if render:\n",
    "            env = pfrl.wrappers.Render(env)\n",
    "        return env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sawyer_env = make_env(env, seed, outdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observation space: Box(-inf, inf, (42,), float32)\n",
      "Action space: Box(-1.0, 1.0, (8,), float32)\n"
     ]
    }
   ],
   "source": [
    "timestep_limit = 500#sawyer_env.spec.max_episode_steps\n",
    "obs_space = sawyer_env.observation_space\n",
    "action_space = sawyer_env.action_space\n",
    "print(\"Observation space:\", obs_space)\n",
    "print(\"Action space:\", action_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert isinstance(obs_space, gym.spaces.Box)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\91953\\Anaconda3\\envs\\pfrl\\lib\\site-packages\\pfrl\\policies\\gaussian_policy.py:38: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ..\\torch\\csrc\\utils\\tensor_numpy.cpp:141.)\n",
      "  torch.tensor(np.broadcast_to(var_param_init, var_size), dtype=torch.float,)\n"
     ]
    }
   ],
   "source": [
    "# Normalize observations based on their empirical mean and variance\n",
    "obs_normalizer = pfrl.nn.EmpiricalNormalization(\n",
    "    obs_space.low.size, clip_threshold=5\n",
    ")\n",
    "\n",
    "obs_size = obs_space.low.size\n",
    "action_size = action_space.low.size\n",
    "policy = torch.nn.Sequential(\n",
    "    nn.Linear(obs_size, 64),\n",
    "    nn.Tanh(),\n",
    "    nn.Linear(64, 64),\n",
    "    nn.Tanh(),\n",
    "    nn.Linear(64, action_size),\n",
    "    pfrl.policies.GaussianHeadWithStateIndependentCovariance(\n",
    "        action_size=action_size,\n",
    "        var_type=\"diagonal\",\n",
    "        var_func=lambda x: torch.exp(2 * x),  # Parameterize log std\n",
    "        var_param_init=0,  # log std = 0 => std = 1\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "vf = torch.nn.Sequential(\n",
    "        nn.Linear(obs_size, 64),\n",
    "        nn.Tanh(),\n",
    "        nn.Linear(64, 64),\n",
    "        nn.Tanh(),\n",
    "        nn.Linear(64, 1),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# While the original paper initialized weights by normal distribution,\n",
    "# we use orthogonal initialization as the latest openai/baselines does.\n",
    "def ortho_init(layer, gain):\n",
    "    nn.init.orthogonal_(layer.weight, gain=gain)\n",
    "    nn.init.zeros_(layer.bias)\n",
    "\n",
    "ortho_init(policy[0], gain=1)\n",
    "ortho_init(policy[2], gain=1)\n",
    "ortho_init(policy[4], gain=1e-2)\n",
    "ortho_init(vf[0], gain=1)\n",
    "ortho_init(vf[2], gain=1)\n",
    "ortho_init(vf[4], gain=1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRPO's policy is optimized via CG and line search, so it doesn't require\n",
    "# an Optimizer. Only the value function needs it.\n",
    "vf_opt = torch.optim.Adam(vf.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Hyperparameters in http://arxiv.org/abs/1709.06560\n",
    "agent = pfrl.agents.TRPO(\n",
    "    policy=policy,\n",
    "    vf=vf,\n",
    "    vf_optimizer=vf_opt,\n",
    "    obs_normalizer=obs_normalizer,\n",
    "    gpu=0,\n",
    "    update_interval=trpo_update_interval,\n",
    "    max_kl=0.01,\n",
    "    conjugate_gradient_max_iter=20,\n",
    "    conjugate_gradient_damping=1e-1,\n",
    "    gamma=0.995,\n",
    "    lambd=0.97,\n",
    "    vf_epochs=5,\n",
    "    entropy_coef=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:3800 episode:0 R:0.1665350169807385\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', -0.0005691441), ('average_entropy', 11.351507), ('average_kl', nan), ('average_policy_step_size', nan), ('explained_variance', nan)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:4300 episode:1 R:1.3981484230507155\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', -0.001488245), ('average_entropy', 11.351506), ('average_kl', nan), ('average_policy_step_size', nan), ('explained_variance', nan)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:0.5202092157166793\n",
      "INFO:pfrl.experiments.train_agent:The best score is updated -3.4028235e+38 -> 0.5202092157166793\n",
      "INFO:pfrl.experiments.train_agent:Saved the agent to results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f\\best\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:4800 episode:2 R:2.9151138991515695\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', -0.0013962619), ('average_entropy', 11.351506), ('average_kl', nan), ('average_policy_step_size', nan), ('explained_variance', nan)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:0.29794367289619433\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:5300 episode:3 R:2.031465982461006\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', -0.00032047366), ('average_entropy', 11.351506), ('average_kl', nan), ('average_policy_step_size', nan), ('explained_variance', nan)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:5800 episode:4 R:0.2347273754759058\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', -0.0010285194), ('average_entropy', 11.351506), ('average_kl', nan), ('average_policy_step_size', nan), ('explained_variance', nan)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:0.16833736424733814\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:6300 episode:5 R:1.8334129392258467\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', -0.0016117134), ('average_entropy', 11.351506), ('average_kl', nan), ('average_policy_step_size', nan), ('explained_variance', nan)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:6800 episode:6 R:0.35591773061968246\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', -0.001754519), ('average_entropy', 11.351506), ('average_kl', nan), ('average_policy_step_size', nan), ('explained_variance', nan)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:0.4474457467280768\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:7300 episode:7 R:1.5358315657091821\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', -0.0010204116), ('average_entropy', 11.351506), ('average_kl', nan), ('average_policy_step_size', nan), ('explained_variance', nan)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:0.22689574299062662\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:7800 episode:8 R:1.283685403321755\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', -0.00050917495), ('average_entropy', 11.351506), ('average_kl', nan), ('average_policy_step_size', nan), ('explained_variance', nan)]\n",
      "INFO:pfrl.agents.trpo:Line search iteration: 0 step size: 1.0\n",
      "INFO:pfrl.agents.trpo:Surrogate objective improve: 0.025428036505218188\n",
      "INFO:pfrl.agents.trpo:KL divergence: 0.007035945542156696\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:8300 episode:9 R:0.17072662285902793\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', -0.0008691183), ('average_entropy', 11.351506), ('average_kl', 0.007035945542156696), ('average_policy_step_size', 1.0), ('explained_variance', 0.004829827545341003)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:0.4228801381104555\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:8800 episode:10 R:0.6466110008109324\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 0.004537219), ('average_entropy', 11.340621), ('average_kl', 0.007035945542156696), ('average_policy_step_size', 1.0), ('explained_variance', 0.004829827545341003)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:14.952798646814902\n",
      "INFO:pfrl.experiments.train_agent:The best score is updated 0.5202092157166793 -> 14.952798646814902\n",
      "INFO:pfrl.experiments.train_agent:Saved the agent to results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f\\best\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:9300 episode:11 R:0.47631841250685425\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 0.036270358), ('average_entropy', 11.329737), ('average_kl', 0.007035945542156696), ('average_policy_step_size', 1.0), ('explained_variance', 0.004829827545341003)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:9800 episode:12 R:0.8983206420956604\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 0.072277255), ('average_entropy', 11.329737), ('average_kl', 0.007035945542156696), ('average_policy_step_size', 1.0), ('explained_variance', 0.004829827545341003)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:0.8076470923150485\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:10300 episode:13 R:0.9174851371379297\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 0.086540714), ('average_entropy', 11.329737), ('average_kl', 0.007035945542156696), ('average_policy_step_size', 1.0), ('explained_variance', 0.004829827545341003)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:10800 episode:14 R:0.6143853081621625\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 0.09369691), ('average_entropy', 11.329737), ('average_kl', 0.007035945542156696), ('average_policy_step_size', 1.0), ('explained_variance', 0.004829827545341003)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:0.479150033261072\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:11300 episode:15 R:2.308900810826423\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 0.08834729), ('average_entropy', 11.329737), ('average_kl', 0.007035945542156696), ('average_policy_step_size', 1.0), ('explained_variance', 0.004829827545341003)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:1.2496854220364657\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:11800 episode:16 R:0.5164227944100347\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 0.051318116), ('average_entropy', 11.329737), ('average_kl', 0.007035945542156696), ('average_policy_step_size', 1.0), ('explained_variance', 0.004829827545341003)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:12300 episode:17 R:0.22693439050950895\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 0.0058596623), ('average_entropy', 11.329737), ('average_kl', 0.007035945542156696), ('average_policy_step_size', 1.0), ('explained_variance', 0.004829827545341003)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:1.1898265349651995\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:12800 episode:18 R:1.2092680189093064\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 0.021015633), ('average_entropy', 11.329737), ('average_kl', 0.007035945542156696), ('average_policy_step_size', 1.0), ('explained_variance', 0.004829827545341003)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:6.405681833749427\n",
      "INFO:pfrl.agents.trpo:Line search iteration: 0 step size: 1.0\n",
      "INFO:pfrl.agents.trpo:Surrogate objective improve: 0.029495913928258233\n",
      "INFO:pfrl.agents.trpo:KL divergence: 0.0075407009571790695\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:13300 episode:19 R:0.26763957566655155\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 0.04738365), ('average_entropy', 11.329737), ('average_kl', 0.007288323249667883), ('average_policy_step_size', 1.0), ('explained_variance', 0.48417587702128406)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:13800 episode:20 R:13.031608828203405\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 0.17464301), ('average_entropy', 11.323603), ('average_kl', 0.007288323249667883), ('average_policy_step_size', 1.0), ('explained_variance', 0.48417587702128406)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:6.366835369995717\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:14300 episode:21 R:5.090394461304698\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 0.20712964), ('average_entropy', 11.317469), ('average_kl', 0.007288323249667883), ('average_policy_step_size', 1.0), ('explained_variance', 0.48417587702128406)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:14800 episode:22 R:3.7436387268144142\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 0.13827316), ('average_entropy', 11.317469), ('average_kl', 0.007288323249667883), ('average_policy_step_size', 1.0), ('explained_variance', 0.48417587702128406)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:2.257009400337158\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:15300 episode:23 R:40.67179364862996\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 0.2070642), ('average_entropy', 11.317469), ('average_kl', 0.007288323249667883), ('average_policy_step_size', 1.0), ('explained_variance', 0.48417587702128406)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:4.85719918722258\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:15800 episode:24 R:5.979168538036495\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 0.21157351), ('average_entropy', 11.317469), ('average_kl', 0.007288323249667883), ('average_policy_step_size', 1.0), ('explained_variance', 0.48417587702128406)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:16300 episode:25 R:1.8904030673953345\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 0.14567205), ('average_entropy', 11.317469), ('average_kl', 0.007288323249667883), ('average_policy_step_size', 1.0), ('explained_variance', 0.48417587702128406)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:37.28551257719346\n",
      "INFO:pfrl.experiments.train_agent:The best score is updated 14.952798646814902 -> 37.28551257719346\n",
      "INFO:pfrl.experiments.train_agent:Saved the agent to results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f\\best\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:16800 episode:26 R:2.3805098019801703\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 0.06348588), ('average_entropy', 11.317469), ('average_kl', 0.007288323249667883), ('average_policy_step_size', 1.0), ('explained_variance', 0.48417587702128406)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:1.2189938653430126\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:17300 episode:27 R:1.390866035783587\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 0.052642692), ('average_entropy', 11.317469), ('average_kl', 0.007288323249667883), ('average_policy_step_size', 1.0), ('explained_variance', 0.48417587702128406)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:17800 episode:28 R:16.566715579607663\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 0.18266106), ('average_entropy', 11.317469), ('average_kl', 0.007288323249667883), ('average_policy_step_size', 1.0), ('explained_variance', 0.48417587702128406)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:11.265391353456225\n",
      "INFO:pfrl.agents.trpo:Line search iteration: 0 step size: 1.0\n",
      "INFO:pfrl.agents.trpo:Surrogate objective improve: 0.022315750622510677\n",
      "INFO:pfrl.agents.trpo:KL divergence: 0.0062278262339532375\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:18300 episode:29 R:5.7263158600312725\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 0.22205436), ('average_entropy', 11.317469), ('average_kl', 0.0069348242444296675), ('average_policy_step_size', 1.0), ('explained_variance', 0.10845825688815303)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:18800 episode:30 R:6.480433015456358\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 0.2745961), ('average_entropy', 11.316561), ('average_kl', 0.0069348242444296675), ('average_policy_step_size', 1.0), ('explained_variance', 0.10845825688815303)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:6.887472536798444\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:19300 episode:31 R:3.6129350333427963\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 0.36733967), ('average_entropy', 11.315655), ('average_kl', 0.0069348242444296675), ('average_policy_step_size', 1.0), ('explained_variance', 0.10845825688815303)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:11.097335534933036\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:19800 episode:32 R:2.9008541538903145\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 0.41078028), ('average_entropy', 11.315655), ('average_kl', 0.0069348242444296675), ('average_policy_step_size', 1.0), ('explained_variance', 0.10845825688815303)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:20300 episode:33 R:1.3802287775458755\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 0.41608468), ('average_entropy', 11.315655), ('average_kl', 0.0069348242444296675), ('average_policy_step_size', 1.0), ('explained_variance', 0.10845825688815303)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:7.8593095245351\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:20800 episode:34 R:11.152458937840294\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 0.6735827), ('average_entropy', 11.315655), ('average_kl', 0.0069348242444296675), ('average_policy_step_size', 1.0), ('explained_variance', 0.10845825688815303)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:0.8429086705445836\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:21300 episode:35 R:2.5455017000704943\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 0.7477791), ('average_entropy', 11.315655), ('average_kl', 0.0069348242444296675), ('average_policy_step_size', 1.0), ('explained_variance', 0.10845825688815303)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:21800 episode:36 R:3.4203400067937526\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 0.60220987), ('average_entropy', 11.315655), ('average_kl', 0.0069348242444296675), ('average_policy_step_size', 1.0), ('explained_variance', 0.10845825688815303)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:3.3434105901788147\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:22300 episode:37 R:14.72092137877535\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 1.3718466), ('average_entropy', 11.315655), ('average_kl', 0.0069348242444296675), ('average_policy_step_size', 1.0), ('explained_variance', 0.10845825688815303)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:22800 episode:38 R:0.20060401139034648\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 1.0485973), ('average_entropy', 11.315655), ('average_kl', 0.0069348242444296675), ('average_policy_step_size', 1.0), ('explained_variance', 0.10845825688815303)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:3.0820235127050783\n",
      "INFO:pfrl.agents.trpo:Line search iteration: 0 step size: 1.0\n",
      "INFO:pfrl.agents.trpo:Surrogate objective improve: 0.028324788945610635\n",
      "INFO:pfrl.agents.trpo:KL divergence: 0.007223478518426418\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:23300 episode:39 R:8.542511981358231\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 0.48362684), ('average_entropy', 11.315655), ('average_kl', 0.007006987812928855), ('average_policy_step_size', 1.0), ('explained_variance', 0.7427068765525302)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:19.304073294928113\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:23800 episode:40 R:9.098878300442617\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 1.0251706), ('average_entropy', 11.318957), ('average_kl', 0.007006987812928855), ('average_policy_step_size', 1.0), ('explained_variance', 0.7427068765525302)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:24300 episode:41 R:12.234397195907189\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 0.89467067), ('average_entropy', 11.322261), ('average_kl', 0.007006987812928855), ('average_policy_step_size', 1.0), ('explained_variance', 0.7427068765525302)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:4.797346794543358\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:24800 episode:42 R:14.409758672917686\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 1.6116158), ('average_entropy', 11.322261), ('average_kl', 0.007006987812928855), ('average_policy_step_size', 1.0), ('explained_variance', 0.7427068765525302)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:11.498273939833016\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:25300 episode:43 R:30.65959954471348\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 2.2796953), ('average_entropy', 11.322261), ('average_kl', 0.007006987812928855), ('average_policy_step_size', 1.0), ('explained_variance', 0.7427068765525302)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:25800 episode:44 R:1.450994524907193\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 1.1383134), ('average_entropy', 11.322261), ('average_kl', 0.007006987812928855), ('average_policy_step_size', 1.0), ('explained_variance', 0.7427068765525302)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:0.7248821432998868\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:26300 episode:45 R:10.067701969627876\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 0.58390075), ('average_entropy', 11.322261), ('average_kl', 0.007006987812928855), ('average_policy_step_size', 1.0), ('explained_variance', 0.7427068765525302)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:26800 episode:46 R:12.42512106755197\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 0.9265013), ('average_entropy', 11.322261), ('average_kl', 0.007006987812928855), ('average_policy_step_size', 1.0), ('explained_variance', 0.7427068765525302)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:39.60036268493749\n",
      "INFO:pfrl.experiments.train_agent:The best score is updated 37.28551257719346 -> 39.60036268493749\n",
      "INFO:pfrl.experiments.train_agent:Saved the agent to results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f\\best\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:27300 episode:47 R:7.810700761464368\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 0.88057697), ('average_entropy', 11.322261), ('average_kl', 0.007006987812928855), ('average_policy_step_size', 1.0), ('explained_variance', 0.7427068765525302)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:21.072900950949336\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:27800 episode:48 R:15.741706932725622\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 1.224488), ('average_entropy', 11.322261), ('average_kl', 0.007006987812928855), ('average_policy_step_size', 1.0), ('explained_variance', 0.7427068765525302)]\n",
      "INFO:pfrl.agents.trpo:Line search iteration: 0 step size: 1.0\n",
      "INFO:pfrl.agents.trpo:Surrogate objective improve: 0.027669933682773262\n",
      "INFO:pfrl.agents.trpo:KL divergence: 0.006632714532315731\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:28300 episode:49 R:7.12344852983707\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 1.7001953), ('average_entropy', 11.322261), ('average_kl', 0.00693213315680623), ('average_policy_step_size', 1.0), ('explained_variance', 0.534629162158107)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:22.3789832228298\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:28800 episode:50 R:8.843488790101176\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 1.331961), ('average_entropy', 11.329209), ('average_kl', 0.00693213315680623), ('average_policy_step_size', 1.0), ('explained_variance', 0.534629162158107)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:19.746511985850866\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:29300 episode:51 R:45.619331621182454\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 1.7282542), ('average_entropy', 11.336156), ('average_kl', 0.00693213315680623), ('average_policy_step_size', 1.0), ('explained_variance', 0.534629162158107)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:29800 episode:52 R:11.640915427496823\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 2.321651), ('average_entropy', 11.336156), ('average_kl', 0.00693213315680623), ('average_policy_step_size', 1.0), ('explained_variance', 0.534629162158107)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:2.92475791320779\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:30300 episode:53 R:12.592281706585535\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 2.2453825), ('average_entropy', 11.336156), ('average_kl', 0.00693213315680623), ('average_policy_step_size', 1.0), ('explained_variance', 0.534629162158107)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:30800 episode:54 R:1.5170580714326287\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 0.96609837), ('average_entropy', 11.336156), ('average_kl', 0.00693213315680623), ('average_policy_step_size', 1.0), ('explained_variance', 0.534629162158107)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:3.9412698947578653\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:31300 episode:55 R:20.350485803914324\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 1.1313936), ('average_entropy', 11.336156), ('average_kl', 0.00693213315680623), ('average_policy_step_size', 1.0), ('explained_variance', 0.534629162158107)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:4.118635836844037\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:31800 episode:56 R:5.726042440788925\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 2.1429226), ('average_entropy', 11.336156), ('average_kl', 0.00693213315680623), ('average_policy_step_size', 1.0), ('explained_variance', 0.534629162158107)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:32300 episode:57 R:22.042694945110092\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 1.9916364), ('average_entropy', 11.336156), ('average_kl', 0.00693213315680623), ('average_policy_step_size', 1.0), ('explained_variance', 0.534629162158107)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:35.01215879342801\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:32800 episode:58 R:34.56215245123828\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 2.7735677), ('average_entropy', 11.336156), ('average_kl', 0.00693213315680623), ('average_policy_step_size', 1.0), ('explained_variance', 0.534629162158107)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:20.17263402935964\n",
      "INFO:pfrl.agents.trpo:Line search iteration: 0 step size: 1.0\n",
      "INFO:pfrl.agents.trpo:Surrogate objective improve: 0.025909873424097896\n",
      "INFO:pfrl.agents.trpo:KL divergence: 0.006888908799737692\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:33300 episode:59 R:7.398445099866592\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 2.4959471), ('average_entropy', 11.336156), ('average_kl', 0.0069249290972948074), ('average_policy_step_size', 1.0), ('explained_variance', 0.6219700138944388)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:33800 episode:60 R:62.155286575700195\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 3.599295), ('average_entropy', 11.348027), ('average_kl', 0.0069249290972948074), ('average_policy_step_size', 1.0), ('explained_variance', 0.6219700138944388)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:7.224161224270678\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:34300 episode:61 R:9.555006516522031\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 3.6075308), ('average_entropy', 11.3599), ('average_kl', 0.0069249290972948074), ('average_policy_step_size', 1.0), ('explained_variance', 0.6219700138944388)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:34800 episode:62 R:12.717898967089132\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 3.5377586), ('average_entropy', 11.3599), ('average_kl', 0.0069249290972948074), ('average_policy_step_size', 1.0), ('explained_variance', 0.6219700138944388)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:21.093668966099187\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:35300 episode:63 R:15.791938426156964\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 5.0075192), ('average_entropy', 11.3599), ('average_kl', 0.0069249290972948074), ('average_policy_step_size', 1.0), ('explained_variance', 0.6219700138944388)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:10.890769686392135\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:35800 episode:64 R:37.206129268330706\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 3.3426752), ('average_entropy', 11.3599), ('average_kl', 0.0069249290972948074), ('average_policy_step_size', 1.0), ('explained_variance', 0.6219700138944388)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:36300 episode:65 R:11.741424934659822\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 3.434122), ('average_entropy', 11.3599), ('average_kl', 0.0069249290972948074), ('average_policy_step_size', 1.0), ('explained_variance', 0.6219700138944388)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:29.566024869869125\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:36800 episode:66 R:14.01360254325244\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 3.7658458), ('average_entropy', 11.3599), ('average_kl', 0.0069249290972948074), ('average_policy_step_size', 1.0), ('explained_variance', 0.6219700138944388)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:9.91524424580989\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:37300 episode:67 R:32.734907379058974\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 3.328307), ('average_entropy', 11.3599), ('average_kl', 0.0069249290972948074), ('average_policy_step_size', 1.0), ('explained_variance', 0.6219700138944388)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:37800 episode:68 R:9.485987284941752\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 4.387873), ('average_entropy', 11.3599), ('average_kl', 0.0069249290972948074), ('average_policy_step_size', 1.0), ('explained_variance', 0.6219700138944388)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:41.42939369568611\n",
      "INFO:pfrl.experiments.train_agent:The best score is updated 39.60036268493749 -> 41.42939369568611\n",
      "INFO:pfrl.experiments.train_agent:Saved the agent to results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f\\best\n",
      "INFO:pfrl.agents.trpo:Line search iteration: 0 step size: 1.0\n",
      "INFO:pfrl.agents.trpo:Surrogate objective improve: 0.03139043558621779\n",
      "INFO:pfrl.agents.trpo:KL divergence: 0.006916442885994911\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:38300 episode:69 R:52.23540860674971\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 4.5252795), ('average_entropy', 11.3599), ('average_kl', 0.006923716781394822), ('average_policy_step_size', 1.0), ('explained_variance', 0.6140310255805482)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:38800 episode:70 R:12.466754730999577\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 3.0307002), ('average_entropy', 11.359936), ('average_kl', 0.006923716781394822), ('average_policy_step_size', 1.0), ('explained_variance', 0.6140310255805482)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:8.73644614796805\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:39300 episode:71 R:53.561387297526956\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 2.971628), ('average_entropy', 11.359972), ('average_kl', 0.006923716781394822), ('average_policy_step_size', 1.0), ('explained_variance', 0.6140310255805482)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:27.665168387860867\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:39800 episode:72 R:45.84642543312321\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 4.832034), ('average_entropy', 11.359972), ('average_kl', 0.006923716781394822), ('average_policy_step_size', 1.0), ('explained_variance', 0.6140310255805482)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:40300 episode:73 R:27.863730329966938\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 4.710304), ('average_entropy', 11.359972), ('average_kl', 0.006923716781394822), ('average_policy_step_size', 1.0), ('explained_variance', 0.6140310255805482)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:37.221246320475025\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:40800 episode:74 R:53.16890940483181\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 4.1203594), ('average_entropy', 11.359972), ('average_kl', 0.006923716781394822), ('average_policy_step_size', 1.0), ('explained_variance', 0.6140310255805482)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:10.259770867653614\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:41300 episode:75 R:20.4701341640232\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 4.5031357), ('average_entropy', 11.359972), ('average_kl', 0.006923716781394822), ('average_policy_step_size', 1.0), ('explained_variance', 0.6140310255805482)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:41800 episode:76 R:58.99132881266218\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 5.39331), ('average_entropy', 11.359972), ('average_kl', 0.006923716781394822), ('average_policy_step_size', 1.0), ('explained_variance', 0.6140310255805482)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:22.296950342566234\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:42300 episode:77 R:30.707889328236103\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 4.6935554), ('average_entropy', 11.359972), ('average_kl', 0.006923716781394822), ('average_policy_step_size', 1.0), ('explained_variance', 0.6140310255805482)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:42800 episode:78 R:17.472214573599828\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 3.3343968), ('average_entropy', 11.359972), ('average_kl', 0.006923716781394822), ('average_policy_step_size', 1.0), ('explained_variance', 0.6140310255805482)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:13.963452082306054\n",
      "INFO:pfrl.agents.trpo:Line search iteration: 0 step size: 1.0\n",
      "INFO:pfrl.agents.trpo:Surrogate objective improve: 0.026847917353734374\n",
      "INFO:pfrl.agents.trpo:KL divergence: 0.007445883005857468\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:43300 episode:79 R:36.55223129893561\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 2.944458), ('average_entropy', 11.359972), ('average_kl', 0.006988987559452653), ('average_policy_step_size', 1.0), ('explained_variance', 0.6643745481494201)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:39.70070731108696\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:43800 episode:80 R:8.76435681841097\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 2.0124614), ('average_entropy', 11.358406), ('average_kl', 0.006988987559452653), ('average_policy_step_size', 1.0), ('explained_variance', 0.6643745481494201)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:44300 episode:81 R:50.90019042670498\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 3.2391331), ('average_entropy', 11.356841), ('average_kl', 0.006988987559452653), ('average_policy_step_size', 1.0), ('explained_variance', 0.6643745481494201)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:32.35931151917832\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:44800 episode:82 R:27.253653753673063\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 4.506229), ('average_entropy', 11.356841), ('average_kl', 0.006988987559452653), ('average_policy_step_size', 1.0), ('explained_variance', 0.6643745481494201)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:43.98899902006384\n",
      "INFO:pfrl.experiments.train_agent:The best score is updated 41.42939369568611 -> 43.98899902006384\n",
      "INFO:pfrl.experiments.train_agent:Saved the agent to results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f\\best\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:45300 episode:83 R:24.098298288669252\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 3.4727015), ('average_entropy', 11.356841), ('average_kl', 0.006988987559452653), ('average_policy_step_size', 1.0), ('explained_variance', 0.6643745481494201)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:45800 episode:84 R:10.135167987036352\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 2.7448452), ('average_entropy', 11.356841), ('average_kl', 0.006988987559452653), ('average_policy_step_size', 1.0), ('explained_variance', 0.6643745481494201)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:36.97064422779544\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:46300 episode:85 R:36.175433070352696\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 2.4372983), ('average_entropy', 11.356841), ('average_kl', 0.006988987559452653), ('average_policy_step_size', 1.0), ('explained_variance', 0.6643745481494201)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:46800 episode:86 R:34.55242183827511\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 3.6082964), ('average_entropy', 11.356841), ('average_kl', 0.006988987559452653), ('average_policy_step_size', 1.0), ('explained_variance', 0.6643745481494201)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:28.727190548769748\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:47300 episode:87 R:20.351982161611947\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 5.000727), ('average_entropy', 11.356841), ('average_kl', 0.006988987559452653), ('average_policy_step_size', 1.0), ('explained_variance', 0.6643745481494201)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:59.441636009460595\n",
      "INFO:pfrl.experiments.train_agent:The best score is updated 43.98899902006384 -> 59.441636009460595\n",
      "INFO:pfrl.experiments.train_agent:Saved the agent to results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f\\best\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:47800 episode:88 R:23.126705638586923\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 4.662579), ('average_entropy', 11.356841), ('average_kl', 0.006988987559452653), ('average_policy_step_size', 1.0), ('explained_variance', 0.6643745481494201)]\n",
      "INFO:pfrl.agents.trpo:Line search iteration: 0 step size: 1.0\n",
      "INFO:pfrl.agents.trpo:Surrogate objective improve: 0.030246287875343114\n",
      "INFO:pfrl.agents.trpo:KL divergence: 0.006943192798644304\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:48300 episode:89 R:27.496455516894795\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 3.773225), ('average_entropy', 11.356841), ('average_kl', 0.0069838992526961696), ('average_policy_step_size', 1.0), ('explained_variance', 0.6999097937948486)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:42.953174820201895\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:48800 episode:90 R:40.63603520637918\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 4.5992827), ('average_entropy', 11.350135), ('average_kl', 0.0069838992526961696), ('average_policy_step_size', 1.0), ('explained_variance', 0.6999097937948486)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:13.765523970199336\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:49300 episode:91 R:27.263277031219367\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 3.7516992), ('average_entropy', 11.34343), ('average_kl', 0.0069838992526961696), ('average_policy_step_size', 1.0), ('explained_variance', 0.6999097937948486)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:49800 episode:92 R:46.48377683471886\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 4.030326), ('average_entropy', 11.34343), ('average_kl', 0.0069838992526961696), ('average_policy_step_size', 1.0), ('explained_variance', 0.6999097937948486)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:14.83297985249499\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:50300 episode:93 R:12.089005095159894\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 5.626806), ('average_entropy', 11.34343), ('average_kl', 0.0069838992526961696), ('average_policy_step_size', 1.0), ('explained_variance', 0.6999097937948486)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:50800 episode:94 R:15.914916173372532\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 5.6926713), ('average_entropy', 11.34343), ('average_kl', 0.0069838992526961696), ('average_policy_step_size', 1.0), ('explained_variance', 0.6999097937948486)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:33.804754679242436\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:51300 episode:95 R:55.88302784070565\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 7.919712), ('average_entropy', 11.34343), ('average_kl', 0.0069838992526961696), ('average_policy_step_size', 1.0), ('explained_variance', 0.6999097937948486)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:28.480153357778704\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:51800 episode:96 R:47.33944385133221\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 6.8848476), ('average_entropy', 11.34343), ('average_kl', 0.0069838992526961696), ('average_policy_step_size', 1.0), ('explained_variance', 0.6999097937948486)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:52300 episode:97 R:32.396405217678186\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 4.95288), ('average_entropy', 11.34343), ('average_kl', 0.0069838992526961696), ('average_policy_step_size', 1.0), ('explained_variance', 0.6999097937948486)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:42.913658706588244\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:52800 episode:98 R:25.483950852893415\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 6.72148), ('average_entropy', 11.34343), ('average_kl', 0.0069838992526961696), ('average_policy_step_size', 1.0), ('explained_variance', 0.6999097937948486)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:24.237125093353292\n",
      "INFO:pfrl.agents.trpo:Line search iteration: 0 step size: 1.0\n",
      "INFO:pfrl.agents.trpo:Surrogate objective improve: 0.028656647395109758\n",
      "INFO:pfrl.agents.trpo:KL divergence: 0.0066306255757808685\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:53300 episode:99 R:25.92346897540134\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 7.7878604), ('average_entropy', 11.34343), ('average_kl', 0.00694857188500464), ('average_policy_step_size', 1.0), ('explained_variance', 0.790246209624362)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:53800 episode:100 R:16.07355940659688\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 6.8941507), ('average_entropy', 11.344975), ('average_kl', 0.00694857188500464), ('average_policy_step_size', 1.0), ('explained_variance', 0.790246209624362)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:56.4939717478527\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:54300 episode:101 R:34.44365679688027\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 7.006094), ('average_entropy', 11.346522), ('average_kl', 0.00694857188500464), ('average_policy_step_size', 1.0), ('explained_variance', 0.790246209624362)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:54800 episode:102 R:59.184268018381104\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 7.1963162), ('average_entropy', 11.346522), ('average_kl', 0.00694857188500464), ('average_policy_step_size', 1.0), ('explained_variance', 0.790246209624362)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:94.70810825475857\n",
      "INFO:pfrl.experiments.train_agent:The best score is updated 59.441636009460595 -> 94.70810825475857\n",
      "INFO:pfrl.experiments.train_agent:Saved the agent to results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f\\best\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:55300 episode:103 R:46.8582149130436\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 7.811662), ('average_entropy', 11.346522), ('average_kl', 0.00694857188500464), ('average_policy_step_size', 1.0), ('explained_variance', 0.790246209624362)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:30.134953569729344\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:55800 episode:104 R:22.986605584929677\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 7.5813665), ('average_entropy', 11.346522), ('average_kl', 0.00694857188500464), ('average_policy_step_size', 1.0), ('explained_variance', 0.790246209624362)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:56300 episode:105 R:21.44842928016462\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 6.293215), ('average_entropy', 11.346522), ('average_kl', 0.00694857188500464), ('average_policy_step_size', 1.0), ('explained_variance', 0.790246209624362)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:64.50489553509621\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:56800 episode:106 R:78.15895612804933\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 5.7714367), ('average_entropy', 11.346522), ('average_kl', 0.00694857188500464), ('average_policy_step_size', 1.0), ('explained_variance', 0.790246209624362)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:14.713480060997457\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:57300 episode:107 R:21.456027655503885\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 5.6775155), ('average_entropy', 11.346522), ('average_kl', 0.00694857188500464), ('average_policy_step_size', 1.0), ('explained_variance', 0.790246209624362)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:57800 episode:108 R:15.278135173971068\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 6.0404873), ('average_entropy', 11.346522), ('average_kl', 0.00694857188500464), ('average_policy_step_size', 1.0), ('explained_variance', 0.790246209624362)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:28.898447136811015\n",
      "INFO:pfrl.agents.trpo:Line search iteration: 0 step size: 1.0\n",
      "INFO:pfrl.agents.trpo:Surrogate objective improve: 0.0277934325276874\n",
      "INFO:pfrl.agents.trpo:KL divergence: 0.006609225180000067\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:58300 episode:109 R:34.339470918090804\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 7.224385), ('average_entropy', 11.346522), ('average_kl', 0.006917722184549679), ('average_policy_step_size', 1.0), ('explained_variance', 0.8012175159344883)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:58800 episode:110 R:39.70391144213411\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 7.2375894), ('average_entropy', 11.35114), ('average_kl', 0.006917722184549679), ('average_policy_step_size', 1.0), ('explained_variance', 0.8012175159344883)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:62.401188145751334\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:59300 episode:111 R:31.06602850206951\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 7.941445), ('average_entropy', 11.355758), ('average_kl', 0.006917722184549679), ('average_policy_step_size', 1.0), ('explained_variance', 0.8012175159344883)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:80.3959633178293\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:59800 episode:112 R:54.099724978815\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 8.181179), ('average_entropy', 11.355758), ('average_kl', 0.006917722184549679), ('average_policy_step_size', 1.0), ('explained_variance', 0.8012175159344883)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:60300 episode:113 R:37.69941850630071\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 6.300736), ('average_entropy', 11.355758), ('average_kl', 0.006917722184549679), ('average_policy_step_size', 1.0), ('explained_variance', 0.8012175159344883)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:102.06406322433084\n",
      "INFO:pfrl.experiments.train_agent:The best score is updated 94.70810825475857 -> 102.06406322433084\n",
      "INFO:pfrl.experiments.train_agent:Saved the agent to results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f\\best\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:60800 episode:114 R:44.99211691148008\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 7.596917), ('average_entropy', 11.355758), ('average_kl', 0.006917722184549679), ('average_policy_step_size', 1.0), ('explained_variance', 0.8012175159344883)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:21.277973473727297\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:61300 episode:115 R:56.894963804477776\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 8.48603), ('average_entropy', 11.355758), ('average_kl', 0.006917722184549679), ('average_policy_step_size', 1.0), ('explained_variance', 0.8012175159344883)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:61800 episode:116 R:78.66343982581971\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 7.361263), ('average_entropy', 11.355758), ('average_kl', 0.006917722184549679), ('average_policy_step_size', 1.0), ('explained_variance', 0.8012175159344883)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:42.6984179835461\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:62300 episode:117 R:69.54946910283768\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 6.341581), ('average_entropy', 11.355758), ('average_kl', 0.006917722184549679), ('average_policy_step_size', 1.0), ('explained_variance', 0.8012175159344883)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:62800 episode:118 R:58.86336837984542\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 7.349876), ('average_entropy', 11.355758), ('average_kl', 0.006917722184549679), ('average_policy_step_size', 1.0), ('explained_variance', 0.8012175159344883)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:69.11909566719414\n",
      "INFO:pfrl.agents.trpo:Line search iteration: 0 step size: 1.0\n",
      "INFO:pfrl.agents.trpo:Surrogate objective improve: 0.030367234750883654\n",
      "INFO:pfrl.agents.trpo:KL divergence: 0.006752464920282364\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:63300 episode:119 R:44.533822958855886\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 7.70462), ('average_entropy', 11.355758), ('average_kl', 0.006903950745860736), ('average_policy_step_size', 1.0), ('explained_variance', 0.8197901103843979)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:27.13847115827491\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:63800 episode:120 R:34.65040425165048\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 6.6083016), ('average_entropy', 11.375163), ('average_kl', 0.006903950745860736), ('average_policy_step_size', 1.0), ('explained_variance', 0.8197901103843979)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:64300 episode:121 R:54.712388615345816\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 7.3383965), ('average_entropy', 11.394568), ('average_kl', 0.006903950745860736), ('average_policy_step_size', 1.0), ('explained_variance', 0.8197901103843979)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:35.663322896717844\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:64800 episode:122 R:93.31676141852836\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 10.47765), ('average_entropy', 11.394568), ('average_kl', 0.006903950745860736), ('average_policy_step_size', 1.0), ('explained_variance', 0.8197901103843979)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:82.87289818456023\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:65300 episode:123 R:38.17865180938553\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 9.091218), ('average_entropy', 11.394568), ('average_kl', 0.006903950745860736), ('average_policy_step_size', 1.0), ('explained_variance', 0.8197901103843979)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:65800 episode:124 R:49.987425589502976\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 6.007476), ('average_entropy', 11.394568), ('average_kl', 0.006903950745860736), ('average_policy_step_size', 1.0), ('explained_variance', 0.8197901103843979)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:61.69937198185002\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:66300 episode:125 R:61.55097178958246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 9.363654), ('average_entropy', 11.394568), ('average_kl', 0.006903950745860736), ('average_policy_step_size', 1.0), ('explained_variance', 0.8197901103843979)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:66800 episode:126 R:36.228266951500416\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 11.539191), ('average_entropy', 11.394568), ('average_kl', 0.006903950745860736), ('average_policy_step_size', 1.0), ('explained_variance', 0.8197901103843979)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:42.85644775158427\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:67300 episode:127 R:31.193353422780078\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 8.816221), ('average_entropy', 11.394568), ('average_kl', 0.006903950745860736), ('average_policy_step_size', 1.0), ('explained_variance', 0.8197901103843979)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:60.58199483405794\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:67800 episode:128 R:45.19762363040213\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 7.618265), ('average_entropy', 11.394568), ('average_kl', 0.006903950745860736), ('average_policy_step_size', 1.0), ('explained_variance', 0.8197901103843979)]\n",
      "INFO:pfrl.agents.trpo:Line search iteration: 0 step size: 1.0\n",
      "INFO:pfrl.agents.trpo:Surrogate objective improve: 0.03083442136994563\n",
      "INFO:pfrl.agents.trpo:KL divergence: 0.00634486461058259\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:68300 episode:129 R:42.74065383328177\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 7.285676), ('average_entropy', 11.394568), ('average_kl', 0.006860944120070109), ('average_policy_step_size', 1.0), ('explained_variance', 0.8914869248799067)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:66.48702794602687\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:68800 episode:130 R:68.27319572795099\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 6.416987), ('average_entropy', 11.388047), ('average_kl', 0.006860944120070109), ('average_policy_step_size', 1.0), ('explained_variance', 0.8914869248799067)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:47.0527320375285\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:69300 episode:131 R:60.81552638657326\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 9.308401), ('average_entropy', 11.381525), ('average_kl', 0.006860944120070109), ('average_policy_step_size', 1.0), ('explained_variance', 0.8914869248799067)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:69800 episode:132 R:37.042045561014845\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 10.551173), ('average_entropy', 11.381525), ('average_kl', 0.006860944120070109), ('average_policy_step_size', 1.0), ('explained_variance', 0.8914869248799067)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:25.62182126221844\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:70300 episode:133 R:53.47306090915075\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 12.280518), ('average_entropy', 11.381525), ('average_kl', 0.006860944120070109), ('average_policy_step_size', 1.0), ('explained_variance', 0.8914869248799067)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:70800 episode:134 R:54.03616129446525\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 13.860944), ('average_entropy', 11.381525), ('average_kl', 0.006860944120070109), ('average_policy_step_size', 1.0), ('explained_variance', 0.8914869248799067)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:41.45579829801603\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:71300 episode:135 R:68.587705434006\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 11.5099), ('average_entropy', 11.381525), ('average_kl', 0.006860944120070109), ('average_policy_step_size', 1.0), ('explained_variance', 0.8914869248799067)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:31.687684972531635\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:71800 episode:136 R:82.90394393133322\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 10.498918), ('average_entropy', 11.381525), ('average_kl', 0.006860944120070109), ('average_policy_step_size', 1.0), ('explained_variance', 0.8914869248799067)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:72300 episode:137 R:17.158155425200494\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 9.721338), ('average_entropy', 11.381525), ('average_kl', 0.006860944120070109), ('average_policy_step_size', 1.0), ('explained_variance', 0.8914869248799067)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:21.720950806262763\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:72800 episode:138 R:59.08192813276636\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 11.187225), ('average_entropy', 11.381525), ('average_kl', 0.006860944120070109), ('average_policy_step_size', 1.0), ('explained_variance', 0.8914869248799067)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:90.77985243873582\n",
      "INFO:pfrl.agents.trpo:Line search iteration: 0 step size: 1.0\n",
      "INFO:pfrl.agents.trpo:Surrogate objective improve: 0.02686406446082401\n",
      "INFO:pfrl.agents.trpo:KL divergence: 0.006784513592720032\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:73300 episode:139 R:30.32928092230153\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 11.66218), ('average_entropy', 11.381525), ('average_kl', 0.006855484796687961), ('average_policy_step_size', 1.0), ('explained_variance', 0.7977323406321339)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:73800 episode:140 R:86.01391333634346\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 11.763668), ('average_entropy', 11.384123), ('average_kl', 0.006855484796687961), ('average_policy_step_size', 1.0), ('explained_variance', 0.7977323406321339)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:38.100198680155124\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:74300 episode:141 R:37.85636970375943\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 13.264473), ('average_entropy', 11.386721), ('average_kl', 0.006855484796687961), ('average_policy_step_size', 1.0), ('explained_variance', 0.7977323406321339)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:74800 episode:142 R:94.03078436516273\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 13.716357), ('average_entropy', 11.386721), ('average_kl', 0.006855484796687961), ('average_policy_step_size', 1.0), ('explained_variance', 0.7977323406321339)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:33.09763516536307\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:75300 episode:143 R:47.1214465720837\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 13.0867815), ('average_entropy', 11.386721), ('average_kl', 0.006855484796687961), ('average_policy_step_size', 1.0), ('explained_variance', 0.7977323406321339)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:81.51091369339848\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:75800 episode:144 R:57.97770031126254\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 12.830227), ('average_entropy', 11.386721), ('average_kl', 0.006855484796687961), ('average_policy_step_size', 1.0), ('explained_variance', 0.7977323406321339)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:76300 episode:145 R:33.36135213331126\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 12.626918), ('average_entropy', 11.386721), ('average_kl', 0.006855484796687961), ('average_policy_step_size', 1.0), ('explained_variance', 0.7977323406321339)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:59.94742159810845\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:76800 episode:146 R:61.0233546606316\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 13.248501), ('average_entropy', 11.386721), ('average_kl', 0.006855484796687961), ('average_policy_step_size', 1.0), ('explained_variance', 0.7977323406321339)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:30.127750760706732\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:77300 episode:147 R:97.50565234756293\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 11.736661), ('average_entropy', 11.386721), ('average_kl', 0.006855484796687961), ('average_policy_step_size', 1.0), ('explained_variance', 0.7977323406321339)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:77800 episode:148 R:66.01128571220539\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 11.017172), ('average_entropy', 11.386721), ('average_kl', 0.006855484796687961), ('average_policy_step_size', 1.0), ('explained_variance', 0.7977323406321339)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:55.93692128937386\n",
      "INFO:pfrl.agents.trpo:Line search iteration: 0 step size: 1.0\n",
      "INFO:pfrl.agents.trpo:Surrogate objective improve: 0.031779353448655456\n",
      "INFO:pfrl.agents.trpo:KL divergence: 0.006930551957339048\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:78300 episode:149 R:44.6254276056216\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 11.916014), ('average_entropy', 11.386721), ('average_kl', 0.0068604892740647), ('average_policy_step_size', 1.0), ('explained_variance', 0.7144395392599514)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:78800 episode:150 R:99.46173973668316\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 13.256108), ('average_entropy', 11.3888855), ('average_kl', 0.0068604892740647), ('average_policy_step_size', 1.0), ('explained_variance', 0.7144395392599514)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:30.948288302660615\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:79300 episode:151 R:46.409018116744015\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 14.566986), ('average_entropy', 11.39105), ('average_kl', 0.0068604892740647), ('average_policy_step_size', 1.0), ('explained_variance', 0.7144395392599514)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:33.13464622377673\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:79800 episode:152 R:109.3823268024834\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 13.7235365), ('average_entropy', 11.39105), ('average_kl', 0.0068604892740647), ('average_policy_step_size', 1.0), ('explained_variance', 0.7144395392599514)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:80300 episode:153 R:49.675352035787974\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 15.01011), ('average_entropy', 11.39105), ('average_kl', 0.0068604892740647), ('average_policy_step_size', 1.0), ('explained_variance', 0.7144395392599514)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:80.49445269590197\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:80800 episode:154 R:78.56863591921251\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 15.278093), ('average_entropy', 11.39105), ('average_kl', 0.0068604892740647), ('average_policy_step_size', 1.0), ('explained_variance', 0.7144395392599514)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:56.9737974612348\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:81300 episode:155 R:80.6226829304953\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 15.287715), ('average_entropy', 11.39105), ('average_kl', 0.0068604892740647), ('average_policy_step_size', 1.0), ('explained_variance', 0.7144395392599514)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:81800 episode:156 R:48.474528066778525\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 11.803394), ('average_entropy', 11.39105), ('average_kl', 0.0068604892740647), ('average_policy_step_size', 1.0), ('explained_variance', 0.7144395392599514)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:38.33053030551074\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:82300 episode:157 R:61.40101688863452\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 10.326863), ('average_entropy', 11.39105), ('average_kl', 0.0068604892740647), ('average_policy_step_size', 1.0), ('explained_variance', 0.7144395392599514)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:82800 episode:158 R:68.02620112063109\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 12.789424), ('average_entropy', 11.39105), ('average_kl', 0.0068604892740647), ('average_policy_step_size', 1.0), ('explained_variance', 0.7144395392599514)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:35.51060499103534\n",
      "INFO:pfrl.agents.trpo:Line search iteration: 0 step size: 1.0\n",
      "INFO:pfrl.agents.trpo:Surrogate objective improve: 0.027886247233254835\n",
      "INFO:pfrl.agents.trpo:KL divergence: 0.006594320293515921\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:83300 episode:159 R:59.20360220232467\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 14.653838), ('average_entropy', 11.39105), ('average_kl', 0.006843853712780401), ('average_policy_step_size', 1.0), ('explained_variance', 0.7879667104178821)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:14.707496672076834\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:83800 episode:160 R:28.065839906482474\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 13.956908), ('average_entropy', 11.39292), ('average_kl', 0.006843853712780401), ('average_policy_step_size', 1.0), ('explained_variance', 0.7879667104178821)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:84300 episode:161 R:107.48165475498624\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 15.19934), ('average_entropy', 11.394789), ('average_kl', 0.006843853712780401), ('average_policy_step_size', 1.0), ('explained_variance', 0.7879667104178821)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:32.840195982905136\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:84800 episode:162 R:74.1429738804595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 15.712686), ('average_entropy', 11.394789), ('average_kl', 0.006843853712780401), ('average_policy_step_size', 1.0), ('explained_variance', 0.7879667104178821)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:84.2161986348784\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:85300 episode:163 R:118.91329366547919\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 15.950294), ('average_entropy', 11.394789), ('average_kl', 0.006843853712780401), ('average_policy_step_size', 1.0), ('explained_variance', 0.7879667104178821)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:85800 episode:164 R:87.45054732213832\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 17.923351), ('average_entropy', 11.394789), ('average_kl', 0.006843853712780401), ('average_policy_step_size', 1.0), ('explained_variance', 0.7879667104178821)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:82.45971168571086\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:86300 episode:165 R:36.3883561431526\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 14.907829), ('average_entropy', 11.394789), ('average_kl', 0.006843853712780401), ('average_policy_step_size', 1.0), ('explained_variance', 0.7879667104178821)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:86800 episode:166 R:23.952071226512068\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 13.249266), ('average_entropy', 11.394789), ('average_kl', 0.006843853712780401), ('average_policy_step_size', 1.0), ('explained_variance', 0.7879667104178821)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:20.68937453699111\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:87300 episode:167 R:86.13512109466667\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 14.103457), ('average_entropy', 11.394789), ('average_kl', 0.006843853712780401), ('average_policy_step_size', 1.0), ('explained_variance', 0.7879667104178821)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:65.39749702866814\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:87800 episode:168 R:61.31660003142069\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 15.955989), ('average_entropy', 11.394789), ('average_kl', 0.006843853712780401), ('average_policy_step_size', 1.0), ('explained_variance', 0.7879667104178821)]\n",
      "INFO:pfrl.agents.trpo:Line search iteration: 0 step size: 1.0\n",
      "INFO:pfrl.agents.trpo:Surrogate objective improve: 0.028199653897900134\n",
      "INFO:pfrl.agents.trpo:KL divergence: 0.006178678013384342\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:88300 episode:169 R:102.96697074192653\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 16.394087), ('average_entropy', 11.394789), ('average_kl', 0.006804725730462986), ('average_policy_step_size', 1.0), ('explained_variance', 0.8400689121634958)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:97.82473561740088\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:88800 episode:170 R:98.31717183511168\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 14.287191), ('average_entropy', 11.38398), ('average_kl', 0.006804725730462986), ('average_policy_step_size', 1.0), ('explained_variance', 0.8400689121634958)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:37.34620431960411\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:89300 episode:171 R:81.56325296090792\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 15.795481), ('average_entropy', 11.37317), ('average_kl', 0.006804725730462986), ('average_policy_step_size', 1.0), ('explained_variance', 0.8400689121634958)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:89800 episode:172 R:88.27492286227317\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 14.918464), ('average_entropy', 11.37317), ('average_kl', 0.006804725730462986), ('average_policy_step_size', 1.0), ('explained_variance', 0.8400689121634958)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:90.84688782465744\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:90300 episode:173 R:39.7522021693545\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 12.954242), ('average_entropy', 11.37317), ('average_kl', 0.006804725730462986), ('average_policy_step_size', 1.0), ('explained_variance', 0.8400689121634958)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:90800 episode:174 R:85.83268058305957\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 18.006567), ('average_entropy', 11.37317), ('average_kl', 0.006804725730462986), ('average_policy_step_size', 1.0), ('explained_variance', 0.8400689121634958)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:80.24370705557253\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:91300 episode:175 R:78.80152045021862\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 20.88306), ('average_entropy', 11.37317), ('average_kl', 0.006804725730462986), ('average_policy_step_size', 1.0), ('explained_variance', 0.8400689121634958)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:89.53391974375988\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:91800 episode:176 R:51.47010366817342\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 15.835916), ('average_entropy', 11.37317), ('average_kl', 0.006804725730462986), ('average_policy_step_size', 1.0), ('explained_variance', 0.8400689121634958)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:92300 episode:177 R:52.4293832590587\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 14.634923), ('average_entropy', 11.37317), ('average_kl', 0.006804725730462986), ('average_policy_step_size', 1.0), ('explained_variance', 0.8400689121634958)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:91.14633732112408\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:92800 episode:178 R:73.59536832058225\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 14.71635), ('average_entropy', 11.37317), ('average_kl', 0.006804725730462986), ('average_policy_step_size', 1.0), ('explained_variance', 0.8400689121634958)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:83.53830786662881\n",
      "INFO:pfrl.agents.trpo:Line search iteration: 0 step size: 1.0\n",
      "INFO:pfrl.agents.trpo:Surrogate objective improve: 0.02799089130712673\n",
      "INFO:pfrl.agents.trpo:KL divergence: 0.006759469397366047\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:93300 episode:179 R:102.48482559355418\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 16.35731), ('average_entropy', 11.37317), ('average_kl', 0.006802211489735378), ('average_policy_step_size', 1.0), ('explained_variance', 0.8529337306511491)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:93800 episode:180 R:76.59374903291437\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 21.585241), ('average_entropy', 11.366154), ('average_kl', 0.006802211489735378), ('average_policy_step_size', 1.0), ('explained_variance', 0.8529337306511491)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:49.67533011292653\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:94300 episode:181 R:67.17922537403244\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 19.187193), ('average_entropy', 11.359137), ('average_kl', 0.006802211489735378), ('average_policy_step_size', 1.0), ('explained_variance', 0.8529337306511491)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:94800 episode:182 R:60.50260160605654\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 18.98168), ('average_entropy', 11.359137), ('average_kl', 0.006802211489735378), ('average_policy_step_size', 1.0), ('explained_variance', 0.8529337306511491)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:42.07051398109645\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:95300 episode:183 R:88.50439809845868\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 17.545168), ('average_entropy', 11.359137), ('average_kl', 0.006802211489735378), ('average_policy_step_size', 1.0), ('explained_variance', 0.8529337306511491)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:48.13123283942686\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:95800 episode:184 R:59.763378715792975\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 14.224174), ('average_entropy', 11.359137), ('average_kl', 0.006802211489735378), ('average_policy_step_size', 1.0), ('explained_variance', 0.8529337306511491)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:96300 episode:185 R:109.07857721710818\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 17.985447), ('average_entropy', 11.359137), ('average_kl', 0.006802211489735378), ('average_policy_step_size', 1.0), ('explained_variance', 0.8529337306511491)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:52.472457059653216\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:96800 episode:186 R:76.55784530958023\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 19.533678), ('average_entropy', 11.359137), ('average_kl', 0.006802211489735378), ('average_policy_step_size', 1.0), ('explained_variance', 0.8529337306511491)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:58.20705873204306\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:97300 episode:187 R:88.35789600601528\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 20.114122), ('average_entropy', 11.359137), ('average_kl', 0.006802211489735378), ('average_policy_step_size', 1.0), ('explained_variance', 0.8529337306511491)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:97800 episode:188 R:24.27541732520059\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 16.51688), ('average_entropy', 11.359137), ('average_kl', 0.006802211489735378), ('average_policy_step_size', 1.0), ('explained_variance', 0.8529337306511491)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:79.53329650580332\n",
      "INFO:pfrl.agents.trpo:Line search iteration: 0 step size: 1.0\n",
      "INFO:pfrl.agents.trpo:Surrogate objective improve: 0.02970394241856411\n",
      "INFO:pfrl.agents.trpo:KL divergence: 0.006549503188580275\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:98300 episode:189 R:68.10169972790779\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 14.147769), ('average_entropy', 11.359137), ('average_kl', 0.006788911052832478), ('average_policy_step_size', 1.0), ('explained_variance', 0.8815892169272501)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:98800 episode:190 R:76.69368936132312\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 19.260075), ('average_entropy', 11.358119), ('average_kl', 0.006788911052832478), ('average_policy_step_size', 1.0), ('explained_variance', 0.8815892169272501)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:53.26104809718497\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:99300 episode:191 R:74.54678630299851\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 18.845688), ('average_entropy', 11.3571005), ('average_kl', 0.006788911052832478), ('average_policy_step_size', 1.0), ('explained_variance', 0.8815892169272501)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:98.82443025525832\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:99800 episode:192 R:106.97081607659203\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 21.656525), ('average_entropy', 11.3571005), ('average_kl', 0.006788911052832478), ('average_policy_step_size', 1.0), ('explained_variance', 0.8815892169272501)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:100300 episode:193 R:75.67173321801349\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 26.16561), ('average_entropy', 11.3571005), ('average_kl', 0.006788911052832478), ('average_policy_step_size', 1.0), ('explained_variance', 0.8815892169272501)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:23.105551577339174\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:100800 episode:194 R:96.41940892815687\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 24.044645), ('average_entropy', 11.3571005), ('average_kl', 0.006788911052832478), ('average_policy_step_size', 1.0), ('explained_variance', 0.8815892169272501)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:114.62440155536989\n",
      "INFO:pfrl.experiments.train_agent:The best score is updated 102.06406322433084 -> 114.62440155536989\n",
      "INFO:pfrl.experiments.train_agent:Saved the agent to results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f\\best\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:101300 episode:195 R:78.17200970394964\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 19.50093), ('average_entropy', 11.3571005), ('average_kl', 0.006788911052832478), ('average_policy_step_size', 1.0), ('explained_variance', 0.8815892169272501)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:101800 episode:196 R:56.67828923814156\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 14.622981), ('average_entropy', 11.3571005), ('average_kl', 0.006788911052832478), ('average_policy_step_size', 1.0), ('explained_variance', 0.8815892169272501)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:37.64591486986049\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:102300 episode:197 R:93.67750167741605\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 14.358249), ('average_entropy', 11.3571005), ('average_kl', 0.006788911052832478), ('average_policy_step_size', 1.0), ('explained_variance', 0.8815892169272501)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:102800 episode:198 R:82.97453490032962\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 19.089663), ('average_entropy', 11.3571005), ('average_kl', 0.006788911052832478), ('average_policy_step_size', 1.0), ('explained_variance', 0.8815892169272501)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:77.00538636215866\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pfrl.agents.trpo:Line search iteration: 0 step size: 1.0\n",
      "INFO:pfrl.agents.trpo:Surrogate objective improve: 0.02999834856018424\n",
      "INFO:pfrl.agents.trpo:KL divergence: 0.00639085890725255\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:103300 episode:199 R:74.80282168925577\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 22.890085), ('average_entropy', 11.3571005), ('average_kl', 0.006769008445553481), ('average_policy_step_size', 1.0), ('explained_variance', 0.865154079139719)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:64.03450354421446\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:103800 episode:200 R:82.26931001909831\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 21.186441), ('average_entropy', 11.347249), ('average_kl', 0.006769008445553481), ('average_policy_step_size', 1.0), ('explained_variance', 0.865154079139719)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:104300 episode:201 R:38.93629843846089\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 17.38448), ('average_entropy', 11.337398), ('average_kl', 0.006769008445553481), ('average_policy_step_size', 1.0), ('explained_variance', 0.865154079139719)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:109.35102323992153\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:104800 episode:202 R:46.005774558738324\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 15.255321), ('average_entropy', 11.337398), ('average_kl', 0.006769008445553481), ('average_policy_step_size', 1.0), ('explained_variance', 0.865154079139719)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:72.47385146690199\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:105300 episode:203 R:70.02869438845181\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 20.146824), ('average_entropy', 11.337398), ('average_kl', 0.006769008445553481), ('average_policy_step_size', 1.0), ('explained_variance', 0.865154079139719)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:105800 episode:204 R:43.16737670039539\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 21.873648), ('average_entropy', 11.337398), ('average_kl', 0.006769008445553481), ('average_policy_step_size', 1.0), ('explained_variance', 0.865154079139719)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:56.01743842871637\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:106300 episode:205 R:86.44325993240952\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 22.50779), ('average_entropy', 11.337398), ('average_kl', 0.006769008445553481), ('average_policy_step_size', 1.0), ('explained_variance', 0.865154079139719)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:106800 episode:206 R:88.64117585409691\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 25.025545), ('average_entropy', 11.337398), ('average_kl', 0.006769008445553481), ('average_policy_step_size', 1.0), ('explained_variance', 0.865154079139719)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:60.28122596923204\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:107300 episode:207 R:75.40051488165103\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 21.973606), ('average_entropy', 11.337398), ('average_kl', 0.006769008445553481), ('average_policy_step_size', 1.0), ('explained_variance', 0.865154079139719)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:102.32373410208538\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:107800 episode:208 R:50.456066495639014\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 21.236351), ('average_entropy', 11.337398), ('average_kl', 0.006769008445553481), ('average_policy_step_size', 1.0), ('explained_variance', 0.865154079139719)]\n",
      "INFO:pfrl.agents.trpo:Line search iteration: 0 step size: 1.0\n",
      "INFO:pfrl.agents.trpo:Surrogate objective improve: 0.028980073191632982\n",
      "INFO:pfrl.agents.trpo:KL divergence: 0.0062917484901845455\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:108300 episode:209 R:69.01326262447385\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 22.540106), ('average_entropy', 11.337398), ('average_kl', 0.006746281781012104), ('average_policy_step_size', 1.0), ('explained_variance', 0.8941282122824623)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:64.7021136611661\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:108800 episode:210 R:39.673457108101864\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 22.004301), ('average_entropy', 11.331074), ('average_kl', 0.006746281781012104), ('average_policy_step_size', 1.0), ('explained_variance', 0.8941282122824623)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:88.8812665726413\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:109300 episode:211 R:68.20193119589098\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 21.166674), ('average_entropy', 11.32475), ('average_kl', 0.006746281781012104), ('average_policy_step_size', 1.0), ('explained_variance', 0.8941282122824623)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:109800 episode:212 R:47.73199718767605\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 20.625986), ('average_entropy', 11.32475), ('average_kl', 0.006746281781012104), ('average_policy_step_size', 1.0), ('explained_variance', 0.8941282122824623)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:77.43025489178414\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:110300 episode:213 R:75.69556177637547\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 19.166367), ('average_entropy', 11.32475), ('average_kl', 0.006746281781012104), ('average_policy_step_size', 1.0), ('explained_variance', 0.8941282122824623)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:110800 episode:214 R:71.69172883852184\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 21.098425), ('average_entropy', 11.32475), ('average_kl', 0.006746281781012104), ('average_policy_step_size', 1.0), ('explained_variance', 0.8941282122824623)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:71.25926411704799\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:111300 episode:215 R:96.1664374663002\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 22.496859), ('average_entropy', 11.32475), ('average_kl', 0.006746281781012104), ('average_policy_step_size', 1.0), ('explained_variance', 0.8941282122824623)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:87.86275488253261\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:111800 episode:216 R:112.25360266729334\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 23.52371), ('average_entropy', 11.32475), ('average_kl', 0.006746281781012104), ('average_policy_step_size', 1.0), ('explained_variance', 0.8941282122824623)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:112300 episode:217 R:102.35805423040595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 24.563211), ('average_entropy', 11.32475), ('average_kl', 0.006746281781012104), ('average_policy_step_size', 1.0), ('explained_variance', 0.8941282122824623)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:124.17354143808488\n",
      "INFO:pfrl.experiments.train_agent:The best score is updated 114.62440155536989 -> 124.17354143808488\n",
      "INFO:pfrl.experiments.train_agent:Saved the agent to results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f\\best\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:112800 episode:218 R:56.65043448180905\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 19.852331), ('average_entropy', 11.32475), ('average_kl', 0.006746281781012104), ('average_policy_step_size', 1.0), ('explained_variance', 0.8941282122824623)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:66.21564708149704\n",
      "INFO:pfrl.agents.trpo:Line search iteration: 0 step size: 1.0\n",
      "INFO:pfrl.agents.trpo:Surrogate objective improve: 0.030934308510040864\n",
      "INFO:pfrl.agents.trpo:KL divergence: 0.006172904744744301\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:113300 episode:219 R:74.60004896422363\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 15.672991), ('average_entropy', 11.32475), ('average_kl', 0.006720219188454476), ('average_policy_step_size', 1.0), ('explained_variance', 0.8625325960401686)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:113800 episode:220 R:78.21295573717097\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 20.23915), ('average_entropy', 11.325545), ('average_kl', 0.006720219188454476), ('average_policy_step_size', 1.0), ('explained_variance', 0.8625325960401686)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:54.085254592479615\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:114300 episode:221 R:93.1338655227836\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 23.383482), ('average_entropy', 11.326339), ('average_kl', 0.006720219188454476), ('average_policy_step_size', 1.0), ('explained_variance', 0.8625325960401686)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:114800 episode:222 R:121.66286993951535\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 22.546938), ('average_entropy', 11.326339), ('average_kl', 0.006720219188454476), ('average_policy_step_size', 1.0), ('explained_variance', 0.8625325960401686)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:83.9290139953408\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:115300 episode:223 R:98.14241130622979\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 23.996859), ('average_entropy', 11.326339), ('average_kl', 0.006720219188454476), ('average_policy_step_size', 1.0), ('explained_variance', 0.8625325960401686)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:101.03088247745788\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:115800 episode:224 R:107.44855023053555\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 24.655926), ('average_entropy', 11.326339), ('average_kl', 0.006720219188454476), ('average_policy_step_size', 1.0), ('explained_variance', 0.8625325960401686)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:116300 episode:225 R:115.48132586962753\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 24.519), ('average_entropy', 11.326339), ('average_kl', 0.006720219188454476), ('average_policy_step_size', 1.0), ('explained_variance', 0.8625325960401686)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:68.26147346910557\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:116800 episode:226 R:79.63776042579889\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 22.456863), ('average_entropy', 11.326339), ('average_kl', 0.006720219188454476), ('average_policy_step_size', 1.0), ('explained_variance', 0.8625325960401686)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:84.08425855788411\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:117300 episode:227 R:57.80123139142183\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 18.822502), ('average_entropy', 11.326339), ('average_kl', 0.006720219188454476), ('average_policy_step_size', 1.0), ('explained_variance', 0.8625325960401686)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:117800 episode:228 R:95.868418926375\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 21.124533), ('average_entropy', 11.326339), ('average_kl', 0.006720219188454476), ('average_policy_step_size', 1.0), ('explained_variance', 0.8625325960401686)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:105.29903083944319\n",
      "INFO:pfrl.agents.trpo:Line search iteration: 0 step size: 1.0\n",
      "INFO:pfrl.agents.trpo:Surrogate objective improve: 0.028249286697246134\n",
      "INFO:pfrl.agents.trpo:KL divergence: 0.006629754323512316\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:118300 episode:229 R:52.197301994741956\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 23.783422), ('average_entropy', 11.326339), ('average_kl', 0.006716285933456991), ('average_policy_step_size', 1.0), ('explained_variance', 0.8035879869747498)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:118800 episode:230 R:95.03442258298843\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 25.01245), ('average_entropy', 11.337852), ('average_kl', 0.006716285933456991), ('average_policy_step_size', 1.0), ('explained_variance', 0.8035879869747498)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:110.41499424611182\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:119300 episode:231 R:88.83460072438677\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 25.368717), ('average_entropy', 11.349364), ('average_kl', 0.006716285933456991), ('average_policy_step_size', 1.0), ('explained_variance', 0.8035879869747498)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:118.33261510329692\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:119800 episode:232 R:121.4429456277585\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 24.083664), ('average_entropy', 11.349364), ('average_kl', 0.006716285933456991), ('average_policy_step_size', 1.0), ('explained_variance', 0.8035879869747498)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:120300 episode:233 R:65.06758661180099\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 23.926573), ('average_entropy', 11.349364), ('average_kl', 0.006716285933456991), ('average_policy_step_size', 1.0), ('explained_variance', 0.8035879869747498)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:84.51541487200129\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:120800 episode:234 R:44.01936454055958\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 22.761726), ('average_entropy', 11.349364), ('average_kl', 0.006716285933456991), ('average_policy_step_size', 1.0), ('explained_variance', 0.8035879869747498)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:101.45026409042488\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:121300 episode:235 R:77.45328594633835\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 23.131863), ('average_entropy', 11.349364), ('average_kl', 0.006716285933456991), ('average_policy_step_size', 1.0), ('explained_variance', 0.8035879869747498)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:121800 episode:236 R:61.21743467409283\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 21.314264), ('average_entropy', 11.349364), ('average_kl', 0.006716285933456991), ('average_policy_step_size', 1.0), ('explained_variance', 0.8035879869747498)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:55.55503318880764\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:122300 episode:237 R:82.11675811365413\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 23.126802), ('average_entropy', 11.349364), ('average_kl', 0.006716285933456991), ('average_policy_step_size', 1.0), ('explained_variance', 0.8035879869747498)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:122800 episode:238 R:81.68194460801872\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 26.911453), ('average_entropy', 11.349364), ('average_kl', 0.006716285933456991), ('average_policy_step_size', 1.0), ('explained_variance', 0.8035879869747498)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:122.92463387572131\n",
      "INFO:pfrl.agents.trpo:Line search iteration: 0 step size: 1.0\n",
      "INFO:pfrl.agents.trpo:Surrogate objective improve: 0.031163677354925312\n",
      "INFO:pfrl.agents.trpo:KL divergence: 0.006348493974655867\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:123300 episode:239 R:66.39659241805965\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 26.026684), ('average_entropy', 11.349364), ('average_kl', 0.006700961268506944), ('average_policy_step_size', 1.0), ('explained_variance', 0.8490030596128314)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:102.27393967365114\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:123800 episode:240 R:113.77638040600965\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 25.370132), ('average_entropy', 11.344322), ('average_kl', 0.006700961268506944), ('average_policy_step_size', 1.0), ('explained_variance', 0.8490030596128314)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:124300 episode:241 R:109.11736195510248\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 25.27793), ('average_entropy', 11.339279), ('average_kl', 0.006700961268506944), ('average_policy_step_size', 1.0), ('explained_variance', 0.8490030596128314)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:58.72073457645244\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:124800 episode:242 R:108.96686476952101\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 26.91846), ('average_entropy', 11.339279), ('average_kl', 0.006700961268506944), ('average_policy_step_size', 1.0), ('explained_variance', 0.8490030596128314)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:142.68081588074156\n",
      "INFO:pfrl.experiments.train_agent:The best score is updated 124.17354143808488 -> 142.68081588074156\n",
      "INFO:pfrl.experiments.train_agent:Saved the agent to results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f\\best\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:125300 episode:243 R:51.0945024941196\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 25.923714), ('average_entropy', 11.339279), ('average_kl', 0.006700961268506944), ('average_policy_step_size', 1.0), ('explained_variance', 0.8490030596128314)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:125800 episode:244 R:88.82716121690596\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 23.100016), ('average_entropy', 11.339279), ('average_kl', 0.006700961268506944), ('average_policy_step_size', 1.0), ('explained_variance', 0.8490030596128314)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:96.57907491675371\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:126300 episode:245 R:34.91940785122577\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 18.968742), ('average_entropy', 11.339279), ('average_kl', 0.006700961268506944), ('average_policy_step_size', 1.0), ('explained_variance', 0.8490030596128314)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:126800 episode:246 R:49.38807925617794\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 18.649193), ('average_entropy', 11.339279), ('average_kl', 0.006700961268506944), ('average_policy_step_size', 1.0), ('explained_variance', 0.8490030596128314)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:110.16943100553549\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:127300 episode:247 R:117.37519811430292\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 24.161924), ('average_entropy', 11.339279), ('average_kl', 0.006700961268506944), ('average_policy_step_size', 1.0), ('explained_variance', 0.8490030596128314)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:76.52707891715117\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:127800 episode:248 R:64.84904900344586\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 24.691807), ('average_entropy', 11.339279), ('average_kl', 0.006700961268506944), ('average_policy_step_size', 1.0), ('explained_variance', 0.8490030596128314)]\n",
      "INFO:pfrl.agents.trpo:Line search iteration: 0 step size: 1.0\n",
      "INFO:pfrl.agents.trpo:Surrogate objective improve: 0.02971106197219342\n",
      "INFO:pfrl.agents.trpo:KL divergence: 0.006328993942588568\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:128300 episode:249 R:92.24648151206242\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 26.274935), ('average_entropy', 11.339279), ('average_kl', 0.006686082575470209), ('average_policy_step_size', 1.0), ('explained_variance', 0.8392840312105586)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:84.08505288094203\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:128800 episode:250 R:68.80240276513055\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 27.392418), ('average_entropy', 11.331711), ('average_kl', 0.006686082575470209), ('average_policy_step_size', 1.0), ('explained_variance', 0.8392840312105586)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:99.68222047846531\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:129300 episode:251 R:110.84406962835321\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 28.058048), ('average_entropy', 11.324143), ('average_kl', 0.006686082575470209), ('average_policy_step_size', 1.0), ('explained_variance', 0.8392840312105586)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:129800 episode:252 R:104.85202834318319\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 27.380867), ('average_entropy', 11.324143), ('average_kl', 0.006686082575470209), ('average_policy_step_size', 1.0), ('explained_variance', 0.8392840312105586)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:106.62895374112259\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:130300 episode:253 R:69.1697116932717\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 24.98907), ('average_entropy', 11.324143), ('average_kl', 0.006686082575470209), ('average_policy_step_size', 1.0), ('explained_variance', 0.8392840312105586)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:130800 episode:254 R:54.925555144061434\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 23.835426), ('average_entropy', 11.324143), ('average_kl', 0.006686082575470209), ('average_policy_step_size', 1.0), ('explained_variance', 0.8392840312105586)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:46.77352707174164\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:131300 episode:255 R:83.59198841794469\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 25.344582), ('average_entropy', 11.324143), ('average_kl', 0.006686082575470209), ('average_policy_step_size', 1.0), ('explained_variance', 0.8392840312105586)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:86.64668265765371\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:131800 episode:256 R:82.54433633568816\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 27.450418), ('average_entropy', 11.324143), ('average_kl', 0.006686082575470209), ('average_policy_step_size', 1.0), ('explained_variance', 0.8392840312105586)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:132300 episode:257 R:110.8532737436538\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 24.624172), ('average_entropy', 11.324143), ('average_kl', 0.006686082575470209), ('average_policy_step_size', 1.0), ('explained_variance', 0.8392840312105586)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:67.18763711869795\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:132800 episode:258 R:68.20761739061948\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 23.3189), ('average_entropy', 11.324143), ('average_kl', 0.006686082575470209), ('average_policy_step_size', 1.0), ('explained_variance', 0.8392840312105586)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:98.02108294309794\n",
      "INFO:pfrl.agents.trpo:Line search iteration: 0 step size: 1.0\n",
      "INFO:pfrl.agents.trpo:Surrogate objective improve: 0.030918895827198867\n",
      "INFO:pfrl.agents.trpo:KL divergence: 0.006665412802249193\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:133300 episode:259 R:99.30468992788794\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 26.975695), ('average_entropy', 11.324143), ('average_kl', 0.006685287584192478), ('average_policy_step_size', 1.0), ('explained_variance', 0.8398368155510919)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:133800 episode:260 R:102.30770786341324\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 31.23628), ('average_entropy', 11.3275795), ('average_kl', 0.006685287584192478), ('average_policy_step_size', 1.0), ('explained_variance', 0.8398368155510919)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:83.74053662319936\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:134300 episode:261 R:106.66328322013635\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 30.45877), ('average_entropy', 11.331014), ('average_kl', 0.006685287584192478), ('average_policy_step_size', 1.0), ('explained_variance', 0.8398368155510919)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:134800 episode:262 R:98.30054184331712\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 30.237522), ('average_entropy', 11.331014), ('average_kl', 0.006685287584192478), ('average_policy_step_size', 1.0), ('explained_variance', 0.8398368155510919)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:90.90907386414749\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:135300 episode:263 R:98.95210821673132\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 31.070803), ('average_entropy', 11.331014), ('average_kl', 0.006685287584192478), ('average_policy_step_size', 1.0), ('explained_variance', 0.8398368155510919)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:98.55486813976259\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:135800 episode:264 R:88.8842074615034\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 26.574446), ('average_entropy', 11.331014), ('average_kl', 0.006685287584192478), ('average_policy_step_size', 1.0), ('explained_variance', 0.8398368155510919)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:136300 episode:265 R:95.68403050622513\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 23.511942), ('average_entropy', 11.331014), ('average_kl', 0.006685287584192478), ('average_policy_step_size', 1.0), ('explained_variance', 0.8398368155510919)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:97.77973850754124\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:136800 episode:266 R:71.49076653728683\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 23.849907), ('average_entropy', 11.331014), ('average_kl', 0.006685287584192478), ('average_policy_step_size', 1.0), ('explained_variance', 0.8398368155510919)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:97.37948008546564\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:137300 episode:267 R:87.23607436315882\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 23.074163), ('average_entropy', 11.331014), ('average_kl', 0.006685287584192478), ('average_policy_step_size', 1.0), ('explained_variance', 0.8398368155510919)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:137800 episode:268 R:69.74105881833101\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 23.453218), ('average_entropy', 11.331014), ('average_kl', 0.006685287584192478), ('average_policy_step_size', 1.0), ('explained_variance', 0.8398368155510919)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:82.63185180173919\n",
      "INFO:pfrl.agents.trpo:Line search iteration: 0 step size: 1.0\n",
      "INFO:pfrl.agents.trpo:Surrogate objective improve: 0.029577907465863973\n",
      "INFO:pfrl.agents.trpo:KL divergence: 0.005849217064678669\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:138300 episode:269 R:84.72737185967992\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 22.536781), ('average_entropy', 11.331014), ('average_kl', 0.00665432200939567), ('average_policy_step_size', 1.0), ('explained_variance', 0.8975352004943064)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:138800 episode:270 R:88.17521647922645\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 25.598469), ('average_entropy', 11.343681), ('average_kl', 0.00665432200939567), ('average_policy_step_size', 1.0), ('explained_variance', 0.8975352004943064)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:76.65513068937523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:139300 episode:271 R:86.3606377513315\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 26.626234), ('average_entropy', 11.356349), ('average_kl', 0.00665432200939567), ('average_policy_step_size', 1.0), ('explained_variance', 0.8975352004943064)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:90.7687362526333\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:139800 episode:272 R:138.15157563360108\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 26.215687), ('average_entropy', 11.356349), ('average_kl', 0.00665432200939567), ('average_policy_step_size', 1.0), ('explained_variance', 0.8975352004943064)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:140300 episode:273 R:112.1252188154855\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 28.138798), ('average_entropy', 11.356349), ('average_kl', 0.00665432200939567), ('average_policy_step_size', 1.0), ('explained_variance', 0.8975352004943064)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:91.31341577546821\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:140800 episode:274 R:55.498211350869596\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 25.95194), ('average_entropy', 11.356349), ('average_kl', 0.00665432200939567), ('average_policy_step_size', 1.0), ('explained_variance', 0.8975352004943064)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:103.89742304295034\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:141300 episode:275 R:102.64186378235055\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 26.478022), ('average_entropy', 11.356349), ('average_kl', 0.00665432200939567), ('average_policy_step_size', 1.0), ('explained_variance', 0.8975352004943064)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:141800 episode:276 R:72.27014641971311\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 27.86488), ('average_entropy', 11.356349), ('average_kl', 0.00665432200939567), ('average_policy_step_size', 1.0), ('explained_variance', 0.8975352004943064)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:107.56529044643642\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:142300 episode:277 R:124.91070052789418\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 27.258987), ('average_entropy', 11.356349), ('average_kl', 0.00665432200939567), ('average_policy_step_size', 1.0), ('explained_variance', 0.8975352004943064)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:142800 episode:278 R:83.37033708121143\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 26.999632), ('average_entropy', 11.356349), ('average_kl', 0.00665432200939567), ('average_policy_step_size', 1.0), ('explained_variance', 0.8975352004943064)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:91.0903497011535\n",
      "INFO:pfrl.agents.trpo:Line search iteration: 0 step size: 1.0\n",
      "INFO:pfrl.agents.trpo:Surrogate objective improve: 0.031707291753264144\n",
      "INFO:pfrl.agents.trpo:KL divergence: 0.005997444968670607\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:143300 episode:279 R:98.31624898043839\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 27.567844), ('average_entropy', 11.356349), ('average_kl', 0.006630862115084061), ('average_policy_step_size', 1.0), ('explained_variance', 0.8295279704522445)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:91.50204020525652\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:143800 episode:280 R:111.74265280877073\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 30.403217), ('average_entropy', 11.340872), ('average_kl', 0.006630862115084061), ('average_policy_step_size', 1.0), ('explained_variance', 0.8295279704522445)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:144300 episode:281 R:109.74618964260414\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 33.587334), ('average_entropy', 11.325395), ('average_kl', 0.006630862115084061), ('average_policy_step_size', 1.0), ('explained_variance', 0.8295279704522445)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:114.70275205681551\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:144800 episode:282 R:80.8077008752061\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 31.608786), ('average_entropy', 11.325395), ('average_kl', 0.006630862115084061), ('average_policy_step_size', 1.0), ('explained_variance', 0.8295279704522445)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:99.45655579994217\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:145300 episode:283 R:79.2832250855469\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 29.93239), ('average_entropy', 11.325395), ('average_kl', 0.006630862115084061), ('average_policy_step_size', 1.0), ('explained_variance', 0.8295279704522445)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:145800 episode:284 R:97.86867802456749\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 26.021523), ('average_entropy', 11.325395), ('average_kl', 0.006630862115084061), ('average_policy_step_size', 1.0), ('explained_variance', 0.8295279704522445)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:104.34527087991961\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:146300 episode:285 R:96.57104565842897\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 27.067211), ('average_entropy', 11.325395), ('average_kl', 0.006630862115084061), ('average_policy_step_size', 1.0), ('explained_variance', 0.8295279704522445)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:146800 episode:286 R:135.04965081735833\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 31.65707), ('average_entropy', 11.325395), ('average_kl', 0.006630862115084061), ('average_policy_step_size', 1.0), ('explained_variance', 0.8295279704522445)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:88.84032156114714\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:147300 episode:287 R:84.83033620941237\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 29.617996), ('average_entropy', 11.325395), ('average_kl', 0.006630862115084061), ('average_policy_step_size', 1.0), ('explained_variance', 0.8295279704522445)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:93.4641524595154\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:147800 episode:288 R:96.73450422315325\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 29.420208), ('average_entropy', 11.325395), ('average_kl', 0.006630862115084061), ('average_policy_step_size', 1.0), ('explained_variance', 0.8295279704522445)]\n",
      "INFO:pfrl.agents.trpo:Line search iteration: 0 step size: 1.0\n",
      "INFO:pfrl.agents.trpo:Surrogate objective improve: 0.032525553193408996\n",
      "INFO:pfrl.agents.trpo:KL divergence: 0.006482692435383797\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:148300 episode:289 R:103.1523738464264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 29.058926), ('average_entropy', 11.325395), ('average_kl', 0.006625752815784052), ('average_policy_step_size', 1.0), ('explained_variance', 0.9227890081312357)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:96.13232857313328\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:148800 episode:290 R:108.32098392705318\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 28.366337), ('average_entropy', 11.314224), ('average_kl', 0.006625752815784052), ('average_policy_step_size', 1.0), ('explained_variance', 0.9227890081312357)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:135.71661312251356\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:149300 episode:291 R:102.68723587656854\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 30.509205), ('average_entropy', 11.303056), ('average_kl', 0.006625752815784052), ('average_policy_step_size', 1.0), ('explained_variance', 0.9227890081312357)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:149800 episode:292 R:99.56655628908315\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 28.826637), ('average_entropy', 11.303056), ('average_kl', 0.006625752815784052), ('average_policy_step_size', 1.0), ('explained_variance', 0.9227890081312357)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:103.95393569287558\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:150300 episode:293 R:66.88699232355317\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 28.057081), ('average_entropy', 11.303056), ('average_kl', 0.006625752815784052), ('average_policy_step_size', 1.0), ('explained_variance', 0.9227890081312357)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:150800 episode:294 R:88.03870330761589\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 30.586973), ('average_entropy', 11.303056), ('average_kl', 0.006625752815784052), ('average_policy_step_size', 1.0), ('explained_variance', 0.9227890081312357)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:84.3451801871161\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:151300 episode:295 R:126.71137018496151\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 28.572742), ('average_entropy', 11.303056), ('average_kl', 0.006625752815784052), ('average_policy_step_size', 1.0), ('explained_variance', 0.9227890081312357)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:110.97084628784695\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:151800 episode:296 R:85.77511903347902\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 29.045187), ('average_entropy', 11.303056), ('average_kl', 0.006625752815784052), ('average_policy_step_size', 1.0), ('explained_variance', 0.9227890081312357)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:152300 episode:297 R:118.30006199141879\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 29.03755), ('average_entropy', 11.303056), ('average_kl', 0.006625752815784052), ('average_policy_step_size', 1.0), ('explained_variance', 0.9227890081312357)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:78.73946896557281\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:152800 episode:298 R:115.7441803227804\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 30.412703), ('average_entropy', 11.303056), ('average_kl', 0.006625752815784052), ('average_policy_step_size', 1.0), ('explained_variance', 0.9227890081312357)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:114.2192157946738\n",
      "INFO:pfrl.agents.trpo:Line search iteration: 0 step size: 1.0\n",
      "INFO:pfrl.agents.trpo:Surrogate objective improve: 0.031052444042870775\n",
      "INFO:pfrl.agents.trpo:KL divergence: 0.004615712445229292\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:153300 episode:299 R:128.5002262808398\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 33.002163), ('average_entropy', 11.303056), ('average_kl', 0.006558751470098893), ('average_policy_step_size', 1.0), ('explained_variance', 0.8326870913431812)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:153800 episode:300 R:107.03775875327798\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 29.91306), ('average_entropy', 11.29925), ('average_kl', 0.006558751470098893), ('average_policy_step_size', 1.0), ('explained_variance', 0.8326870913431812)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:117.36533705837243\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:154300 episode:301 R:97.92164174683984\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 30.881744), ('average_entropy', 11.295445), ('average_kl', 0.006558751470098893), ('average_policy_step_size', 1.0), ('explained_variance', 0.8326870913431812)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:154800 episode:302 R:109.65797418040948\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 31.888123), ('average_entropy', 11.295445), ('average_kl', 0.006558751470098893), ('average_policy_step_size', 1.0), ('explained_variance', 0.8326870913431812)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:87.12966399497081\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:155300 episode:303 R:108.2246787379687\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 32.042202), ('average_entropy', 11.295445), ('average_kl', 0.006558751470098893), ('average_policy_step_size', 1.0), ('explained_variance', 0.8326870913431812)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:81.27184101583839\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:155800 episode:304 R:89.25240895380217\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 29.644323), ('average_entropy', 11.295445), ('average_kl', 0.006558751470098893), ('average_policy_step_size', 1.0), ('explained_variance', 0.8326870913431812)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:156300 episode:305 R:75.87052482806057\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 22.437422), ('average_entropy', 11.295445), ('average_kl', 0.006558751470098893), ('average_policy_step_size', 1.0), ('explained_variance', 0.8326870913431812)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:113.33532218435481\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:156800 episode:306 R:113.00101984434814\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 28.01299), ('average_entropy', 11.295445), ('average_kl', 0.006558751470098893), ('average_policy_step_size', 1.0), ('explained_variance', 0.8326870913431812)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:115.44250104267151\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:157300 episode:307 R:121.95481583118273\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 34.03195), ('average_entropy', 11.295445), ('average_kl', 0.006558751470098893), ('average_policy_step_size', 1.0), ('explained_variance', 0.8326870913431812)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:157800 episode:308 R:119.08948274308185\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 30.303005), ('average_entropy', 11.295445), ('average_kl', 0.006558751470098893), ('average_policy_step_size', 1.0), ('explained_variance', 0.8326870913431812)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:114.1392169073829\n",
      "INFO:pfrl.agents.trpo:Line search iteration: 0 step size: 1.0\n",
      "INFO:pfrl.agents.trpo:Surrogate objective improve: 0.03006012024707161\n",
      "INFO:pfrl.agents.trpo:KL divergence: 0.006494430359452963\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:158300 episode:309 R:113.87855377776877\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 28.66399), ('average_entropy', 11.295445), ('average_kl', 0.006556676595561927), ('average_policy_step_size', 1.0), ('explained_variance', 0.9243026235916763)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:158800 episode:310 R:121.57657122778001\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 31.004387), ('average_entropy', 11.313781), ('average_kl', 0.006556676595561927), ('average_policy_step_size', 1.0), ('explained_variance', 0.9243026235916763)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:124.67197479373488\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:159300 episode:311 R:109.8594522476168\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 32.079876), ('average_entropy', 11.332117), ('average_kl', 0.006556676595561927), ('average_policy_step_size', 1.0), ('explained_variance', 0.9243026235916763)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:105.47280179597507\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:159800 episode:312 R:94.3499632597493\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 30.98497), ('average_entropy', 11.332117), ('average_kl', 0.006556676595561927), ('average_policy_step_size', 1.0), ('explained_variance', 0.9243026235916763)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:160300 episode:313 R:117.85643614201564\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 33.72174), ('average_entropy', 11.332117), ('average_kl', 0.006556676595561927), ('average_policy_step_size', 1.0), ('explained_variance', 0.9243026235916763)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:96.10564867441248\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:160800 episode:314 R:103.90948203040257\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 33.989452), ('average_entropy', 11.332117), ('average_kl', 0.006556676595561927), ('average_policy_step_size', 1.0), ('explained_variance', 0.9243026235916763)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:109.56308642204552\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:161300 episode:315 R:94.84041385996314\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 28.311285), ('average_entropy', 11.332117), ('average_kl', 0.006556676595561927), ('average_policy_step_size', 1.0), ('explained_variance', 0.9243026235916763)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:161800 episode:316 R:112.16870347939044\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 29.163776), ('average_entropy', 11.332117), ('average_kl', 0.006556676595561927), ('average_policy_step_size', 1.0), ('explained_variance', 0.9243026235916763)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:68.79170715810248\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:162300 episode:317 R:137.49109000634093\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 34.95146), ('average_entropy', 11.332117), ('average_kl', 0.006556676595561927), ('average_policy_step_size', 1.0), ('explained_variance', 0.9243026235916763)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:162800 episode:318 R:93.70959772358462\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 35.621464), ('average_entropy', 11.332117), ('average_kl', 0.006556676595561927), ('average_policy_step_size', 1.0), ('explained_variance', 0.9243026235916763)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:107.86451560957147\n",
      "INFO:pfrl.agents.trpo:Line search iteration: 0 step size: 1.0\n",
      "INFO:pfrl.agents.trpo:Surrogate objective improve: 0.02645556046627462\n",
      "INFO:pfrl.agents.trpo:KL divergence: 0.0062887901440262794\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:163300 episode:319 R:94.26165429362423\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 32.876606), ('average_entropy', 11.332117), ('average_kl', 0.006548305143951438), ('average_policy_step_size', 1.0), ('explained_variance', 0.8829260126155334)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:129.82456449758325\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:163800 episode:320 R:113.49349713688258\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 34.332214), ('average_entropy', 11.3266735), ('average_kl', 0.006548305143951438), ('average_policy_step_size', 1.0), ('explained_variance', 0.8829260126155334)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:164300 episode:321 R:102.99620800874756\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 35.345978), ('average_entropy', 11.321231), ('average_kl', 0.006548305143951438), ('average_policy_step_size', 1.0), ('explained_variance', 0.8829260126155334)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:81.94666060263839\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:164800 episode:322 R:98.44704117551245\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 33.648766), ('average_entropy', 11.321231), ('average_kl', 0.006548305143951438), ('average_policy_step_size', 1.0), ('explained_variance', 0.8829260126155334)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:100.57102469908628\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:165300 episode:323 R:106.09903233127366\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 33.545124), ('average_entropy', 11.321231), ('average_kl', 0.006548305143951438), ('average_policy_step_size', 1.0), ('explained_variance', 0.8829260126155334)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:165800 episode:324 R:102.5971535215413\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 31.074232), ('average_entropy', 11.321231), ('average_kl', 0.006548305143951438), ('average_policy_step_size', 1.0), ('explained_variance', 0.8829260126155334)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:110.18536606930154\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:166300 episode:325 R:120.76294726960155\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 33.7855), ('average_entropy', 11.321231), ('average_kl', 0.006548305143951438), ('average_policy_step_size', 1.0), ('explained_variance', 0.8829260126155334)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:166800 episode:326 R:89.37214583969977\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 34.048733), ('average_entropy', 11.321231), ('average_kl', 0.006548305143951438), ('average_policy_step_size', 1.0), ('explained_variance', 0.8829260126155334)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:57.02688667113497\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:167300 episode:327 R:114.42400386835541\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 30.490555), ('average_entropy', 11.321231), ('average_kl', 0.006548305143951438), ('average_policy_step_size', 1.0), ('explained_variance', 0.8829260126155334)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:111.82493849747526\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:167800 episode:328 R:102.07823739870342\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 33.45204), ('average_entropy', 11.321231), ('average_kl', 0.006548305143951438), ('average_policy_step_size', 1.0), ('explained_variance', 0.8829260126155334)]\n",
      "INFO:pfrl.agents.trpo:Line search iteration: 0 step size: 1.0\n",
      "INFO:pfrl.agents.trpo:Surrogate objective improve: 0.029564042895799503\n",
      "INFO:pfrl.agents.trpo:KL divergence: 0.005640856456011534\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:168300 episode:329 R:50.845232289052504\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 30.815832), ('average_entropy', 11.321231), ('average_kl', 0.0065208066988623505), ('average_policy_step_size', 1.0), ('explained_variance', 0.8693564392396804)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:93.51478725321854\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:168800 episode:330 R:70.48602518324394\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 29.886126), ('average_entropy', 11.319192), ('average_kl', 0.0065208066988623505), ('average_policy_step_size', 1.0), ('explained_variance', 0.8693564392396804)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:94.75141115536725\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:169300 episode:331 R:113.02987484039181\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 31.721132), ('average_entropy', 11.317154), ('average_kl', 0.0065208066988623505), ('average_policy_step_size', 1.0), ('explained_variance', 0.8693564392396804)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:169800 episode:332 R:132.80400222524543\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 31.607883), ('average_entropy', 11.317154), ('average_kl', 0.0065208066988623505), ('average_policy_step_size', 1.0), ('explained_variance', 0.8693564392396804)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:118.42604490886528\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:170300 episode:333 R:107.6679808911611\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 35.124413), ('average_entropy', 11.317154), ('average_kl', 0.0065208066988623505), ('average_policy_step_size', 1.0), ('explained_variance', 0.8693564392396804)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:170800 episode:334 R:100.06177196992223\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 35.75825), ('average_entropy', 11.317154), ('average_kl', 0.0065208066988623505), ('average_policy_step_size', 1.0), ('explained_variance', 0.8693564392396804)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:46.15735434503604\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:171300 episode:335 R:114.32506974881026\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 36.67639), ('average_entropy', 11.317154), ('average_kl', 0.0065208066988623505), ('average_policy_step_size', 1.0), ('explained_variance', 0.8693564392396804)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:101.22674363192424\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:171800 episode:336 R:98.35163293200114\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 34.23104), ('average_entropy', 11.317154), ('average_kl', 0.0065208066988623505), ('average_policy_step_size', 1.0), ('explained_variance', 0.8693564392396804)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:172300 episode:337 R:118.98998232671494\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 32.342556), ('average_entropy', 11.317154), ('average_kl', 0.0065208066988623505), ('average_policy_step_size', 1.0), ('explained_variance', 0.8693564392396804)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:196.78586875202896\n",
      "INFO:pfrl.experiments.train_agent:The best score is updated 142.68081588074156 -> 196.78586875202896\n",
      "INFO:pfrl.experiments.train_agent:Saved the agent to results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f\\best\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:172800 episode:338 R:116.75637157944658\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 35.57279), ('average_entropy', 11.317154), ('average_kl', 0.0065208066988623505), ('average_policy_step_size', 1.0), ('explained_variance', 0.8693564392396804)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:64.01074891349468\n",
      "INFO:pfrl.agents.trpo:Line search iteration: 0 step size: 1.0\n",
      "INFO:pfrl.agents.trpo:Surrogate objective improve: 0.0312474701404426\n",
      "INFO:pfrl.agents.trpo:KL divergence: 0.006458938587456942\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:173300 episode:339 R:90.73920074951872\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 35.354744), ('average_entropy', 11.317154), ('average_kl', 0.006518987048526897), ('average_policy_step_size', 1.0), ('explained_variance', 0.8458895427629602)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:173800 episode:340 R:92.76179523262344\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 34.513462), ('average_entropy', 11.301637), ('average_kl', 0.006518987048526897), ('average_policy_step_size', 1.0), ('explained_variance', 0.8458895427629602)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:74.78962696651553\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:174300 episode:341 R:126.11508240379996\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 35.62804), ('average_entropy', 11.286119), ('average_kl', 0.006518987048526897), ('average_policy_step_size', 1.0), ('explained_variance', 0.8458895427629602)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:174800 episode:342 R:135.90842489125646\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 37.223648), ('average_entropy', 11.286119), ('average_kl', 0.006518987048526897), ('average_policy_step_size', 1.0), ('explained_variance', 0.8458895427629602)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:118.44398251103293\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:175300 episode:343 R:96.47109024644196\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 36.487072), ('average_entropy', 11.286119), ('average_kl', 0.006518987048526897), ('average_policy_step_size', 1.0), ('explained_variance', 0.8458895427629602)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:103.12714290615563\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:175800 episode:344 R:102.45719261959077\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 33.548737), ('average_entropy', 11.286119), ('average_kl', 0.006518987048526897), ('average_policy_step_size', 1.0), ('explained_variance', 0.8458895427629602)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:176300 episode:345 R:112.38240972146957\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 32.739197), ('average_entropy', 11.286119), ('average_kl', 0.006518987048526897), ('average_policy_step_size', 1.0), ('explained_variance', 0.8458895427629602)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:82.61458240158963\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:176800 episode:346 R:72.01830107945216\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 29.579899), ('average_entropy', 11.286119), ('average_kl', 0.006518987048526897), ('average_policy_step_size', 1.0), ('explained_variance', 0.8458895427629602)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:118.87068316014924\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:177300 episode:347 R:112.53902576929781\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 29.817385), ('average_entropy', 11.286119), ('average_kl', 0.006518987048526897), ('average_policy_step_size', 1.0), ('explained_variance', 0.8458895427629602)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:177800 episode:348 R:128.1944380956709\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 34.16474), ('average_entropy', 11.286119), ('average_kl', 0.006518987048526897), ('average_policy_step_size', 1.0), ('explained_variance', 0.8458895427629602)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:114.69987665605485\n",
      "INFO:pfrl.agents.trpo:Line search iteration: 0 step size: 1.0\n",
      "INFO:pfrl.agents.trpo:Surrogate objective improve: 0.030548039547284134\n",
      "INFO:pfrl.agents.trpo:KL divergence: 0.006257989909499884\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:178300 episode:349 R:94.50257479250257\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 34.197384), ('average_entropy', 11.286119), ('average_kl', 0.006511529987411839), ('average_policy_step_size', 1.0), ('explained_variance', 0.9031530631980476)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:178800 episode:350 R:106.97477652538663\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 36.151382), ('average_entropy', 11.277359), ('average_kl', 0.006511529987411839), ('average_policy_step_size', 1.0), ('explained_variance', 0.9031530631980476)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:98.390005220722\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:179300 episode:351 R:109.57525463761995\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 37.623), ('average_entropy', 11.2685995), ('average_kl', 0.006511529987411839), ('average_policy_step_size', 1.0), ('explained_variance', 0.9031530631980476)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:110.35501922865552\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:179800 episode:352 R:110.16012915148963\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 36.548206), ('average_entropy', 11.2685995), ('average_kl', 0.006511529987411839), ('average_policy_step_size', 1.0), ('explained_variance', 0.9031530631980476)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:180300 episode:353 R:104.98669964381467\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 34.377094), ('average_entropy', 11.2685995), ('average_kl', 0.006511529987411839), ('average_policy_step_size', 1.0), ('explained_variance', 0.9031530631980476)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:109.12778710314352\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:180800 episode:354 R:102.71358199386641\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 34.948883), ('average_entropy', 11.2685995), ('average_kl', 0.006511529987411839), ('average_policy_step_size', 1.0), ('explained_variance', 0.9031530631980476)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:114.9946120971641\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:181300 episode:355 R:110.22578633328595\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 36.19819), ('average_entropy', 11.2685995), ('average_kl', 0.006511529987411839), ('average_policy_step_size', 1.0), ('explained_variance', 0.9031530631980476)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:181800 episode:356 R:96.17001562223953\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 34.432568), ('average_entropy', 11.2685995), ('average_kl', 0.006511529987411839), ('average_policy_step_size', 1.0), ('explained_variance', 0.9031530631980476)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:103.30782750446699\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:182300 episode:357 R:123.06338999124479\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 36.081345), ('average_entropy', 11.2685995), ('average_kl', 0.006511529987411839), ('average_policy_step_size', 1.0), ('explained_variance', 0.9031530631980476)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:182800 episode:358 R:107.16773243948211\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 38.272583), ('average_entropy', 11.2685995), ('average_kl', 0.006511529987411839), ('average_policy_step_size', 1.0), ('explained_variance', 0.9031530631980476)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:125.52344413656627\n",
      "INFO:pfrl.agents.trpo:Line search iteration: 0 step size: 1.0\n",
      "INFO:pfrl.agents.trpo:Surrogate objective improve: 0.028820844781876076\n",
      "INFO:pfrl.agents.trpo:KL divergence: 0.006128028035163879\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:183300 episode:359 R:109.95822342423358\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 37.76306), ('average_entropy', 11.2685995), ('average_kl', 0.0065008771554049515), ('average_policy_step_size', 1.0), ('explained_variance', 0.8293548154093593)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:126.73720147461653\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:183800 episode:360 R:105.912995476081\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 37.295044), ('average_entropy', 11.263813), ('average_kl', 0.0065008771554049515), ('average_policy_step_size', 1.0), ('explained_variance', 0.8293548154093593)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:184300 episode:361 R:204.20115364878748\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 37.706467), ('average_entropy', 11.2590275), ('average_kl', 0.0065008771554049515), ('average_policy_step_size', 1.0), ('explained_variance', 0.8293548154093593)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:103.68755350818128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:184800 episode:362 R:119.3023533529984\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 37.940475), ('average_entropy', 11.2590275), ('average_kl', 0.0065008771554049515), ('average_policy_step_size', 1.0), ('explained_variance', 0.8293548154093593)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:126.3437913382164\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:185300 episode:363 R:109.61722197094515\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 37.49182), ('average_entropy', 11.2590275), ('average_kl', 0.0065008771554049515), ('average_policy_step_size', 1.0), ('explained_variance', 0.8293548154093593)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:185800 episode:364 R:102.74161195728233\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 36.530586), ('average_entropy', 11.2590275), ('average_kl', 0.0065008771554049515), ('average_policy_step_size', 1.0), ('explained_variance', 0.8293548154093593)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:88.07466002824661\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:186300 episode:365 R:111.05189126971005\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 35.316265), ('average_entropy', 11.2590275), ('average_kl', 0.0065008771554049515), ('average_policy_step_size', 1.0), ('explained_variance', 0.8293548154093593)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:186800 episode:366 R:84.41229674041863\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 35.79212), ('average_entropy', 11.2590275), ('average_kl', 0.0065008771554049515), ('average_policy_step_size', 1.0), ('explained_variance', 0.8293548154093593)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:97.04244649298549\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:187300 episode:367 R:110.81384318037938\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 37.94187), ('average_entropy', 11.2590275), ('average_kl', 0.0065008771554049515), ('average_policy_step_size', 1.0), ('explained_variance', 0.8293548154093593)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:135.95491924689424\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:187800 episode:368 R:105.02362414218229\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 35.30019), ('average_entropy', 11.2590275), ('average_kl', 0.0065008771554049515), ('average_policy_step_size', 1.0), ('explained_variance', 0.8293548154093593)]\n",
      "INFO:pfrl.agents.trpo:Line search iteration: 0 step size: 1.0\n",
      "INFO:pfrl.agents.trpo:Surrogate objective improve: 0.027507732826052234\n",
      "INFO:pfrl.agents.trpo:KL divergence: 0.0062200771644711494\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:188300 episode:369 R:107.75125181814293\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 35.219288), ('average_entropy', 11.2590275), ('average_kl', 0.0064932879664607954), ('average_policy_step_size', 1.0), ('explained_variance', 0.7269028325863021)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:98.39189259029098\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:188800 episode:370 R:117.83263066266305\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 39.634087), ('average_entropy', 11.261212), ('average_kl', 0.0064932879664607954), ('average_policy_step_size', 1.0), ('explained_variance', 0.7269028325863021)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:115.15737538880315\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:189300 episode:371 R:88.63234229074583\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 36.619366), ('average_entropy', 11.263396), ('average_kl', 0.0064932879664607954), ('average_policy_step_size', 1.0), ('explained_variance', 0.7269028325863021)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:189800 episode:372 R:112.46986073934363\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 34.988968), ('average_entropy', 11.263396), ('average_kl', 0.0064932879664607954), ('average_policy_step_size', 1.0), ('explained_variance', 0.7269028325863021)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:77.1732695562044\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:190300 episode:373 R:105.13579591639669\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 38.140663), ('average_entropy', 11.263396), ('average_kl', 0.0064932879664607954), ('average_policy_step_size', 1.0), ('explained_variance', 0.7269028325863021)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:190800 episode:374 R:115.52956478879737\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 37.73139), ('average_entropy', 11.263396), ('average_kl', 0.0064932879664607954), ('average_policy_step_size', 1.0), ('explained_variance', 0.7269028325863021)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:118.9904401762518\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:191300 episode:375 R:140.0325244919697\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 36.45282), ('average_entropy', 11.263396), ('average_kl', 0.0064932879664607954), ('average_policy_step_size', 1.0), ('explained_variance', 0.7269028325863021)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:100.70327746868587\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:191800 episode:376 R:129.6130401893352\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 36.920334), ('average_entropy', 11.263396), ('average_kl', 0.0064932879664607954), ('average_policy_step_size', 1.0), ('explained_variance', 0.7269028325863021)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:192300 episode:377 R:108.56382634723158\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 39.25513), ('average_entropy', 11.263396), ('average_kl', 0.0064932879664607954), ('average_policy_step_size', 1.0), ('explained_variance', 0.7269028325863021)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:96.56507075305495\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:192800 episode:378 R:122.25982111825206\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 41.257652), ('average_entropy', 11.263396), ('average_kl', 0.0064932879664607954), ('average_policy_step_size', 1.0), ('explained_variance', 0.7269028325863021)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:129.0815238280943\n",
      "INFO:pfrl.agents.trpo:Line search iteration: 0 step size: 1.0\n",
      "INFO:pfrl.agents.trpo:Surrogate objective improve: 0.027894280312466435\n",
      "INFO:pfrl.agents.trpo:KL divergence: 0.006071800831705332\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:193300 episode:379 R:93.52902366563177\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 38.90715), ('average_entropy', 11.263396), ('average_kl', 0.006482196199756704), ('average_policy_step_size', 1.0), ('explained_variance', 0.7348946986526906)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:193800 episode:380 R:132.3008328389588\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 38.170162), ('average_entropy', 11.279526), ('average_kl', 0.006482196199756704), ('average_policy_step_size', 1.0), ('explained_variance', 0.7348946986526906)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:109.26600433166323\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:194300 episode:381 R:126.65473119473413\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 37.848392), ('average_entropy', 11.295655), ('average_kl', 0.006482196199756704), ('average_policy_step_size', 1.0), ('explained_variance', 0.7348946986526906)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:194800 episode:382 R:85.5417224343186\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 35.745975), ('average_entropy', 11.295655), ('average_kl', 0.006482196199756704), ('average_policy_step_size', 1.0), ('explained_variance', 0.7348946986526906)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:126.16747982575325\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:195300 episode:383 R:114.21957279597592\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 37.686707), ('average_entropy', 11.295655), ('average_kl', 0.006482196199756704), ('average_policy_step_size', 1.0), ('explained_variance', 0.7348946986526906)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:114.2602927191698\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:195800 episode:384 R:126.25157898091241\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 40.20363), ('average_entropy', 11.295655), ('average_kl', 0.006482196199756704), ('average_policy_step_size', 1.0), ('explained_variance', 0.7348946986526906)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:196300 episode:385 R:104.37408359067588\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 38.515118), ('average_entropy', 11.295655), ('average_kl', 0.006482196199756704), ('average_policy_step_size', 1.0), ('explained_variance', 0.7348946986526906)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:105.6991033557346\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:196800 episode:386 R:95.16527860343398\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 36.678616), ('average_entropy', 11.295655), ('average_kl', 0.006482196199756704), ('average_policy_step_size', 1.0), ('explained_variance', 0.7348946986526906)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:131.72192554456765\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:197300 episode:387 R:102.8311989986166\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 37.64744), ('average_entropy', 11.295655), ('average_kl', 0.006482196199756704), ('average_policy_step_size', 1.0), ('explained_variance', 0.7348946986526906)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:197800 episode:388 R:98.4562171987275\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 38.881424), ('average_entropy', 11.295655), ('average_kl', 0.006482196199756704), ('average_policy_step_size', 1.0), ('explained_variance', 0.7348946986526906)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:109.6727434919351\n",
      "INFO:pfrl.agents.trpo:Line search iteration: 0 step size: 1.0\n",
      "INFO:pfrl.agents.trpo:Surrogate objective improve: 0.03175208676839247\n",
      "INFO:pfrl.agents.trpo:KL divergence: 0.006166170816868544\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:198300 episode:389 R:126.94905520128914\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 39.72723), ('average_entropy', 11.295655), ('average_kl', 0.006474092984810853), ('average_policy_step_size', 1.0), ('explained_variance', 0.7957010861053486)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:198800 episode:390 R:113.28126793013021\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 38.99382), ('average_entropy', 11.282159), ('average_kl', 0.006474092984810853), ('average_policy_step_size', 1.0), ('explained_variance', 0.7957010861053486)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:110.66830583967281\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:199300 episode:391 R:128.43310536512573\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 39.60807), ('average_entropy', 11.268663), ('average_kl', 0.006474092984810853), ('average_policy_step_size', 1.0), ('explained_variance', 0.7957010861053486)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:108.61383727678303\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:199800 episode:392 R:132.12631022022305\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 40.821777), ('average_entropy', 11.268663), ('average_kl', 0.006474092984810853), ('average_policy_step_size', 1.0), ('explained_variance', 0.7957010861053486)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:200300 episode:393 R:115.18406842754051\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 40.90429), ('average_entropy', 11.268663), ('average_kl', 0.006474092984810853), ('average_policy_step_size', 1.0), ('explained_variance', 0.7957010861053486)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:89.17950049186587\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:200800 episode:394 R:122.5506300662294\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 39.922382), ('average_entropy', 11.268663), ('average_kl', 0.006474092984810853), ('average_policy_step_size', 1.0), ('explained_variance', 0.7957010861053486)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:110.43568401729115\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:201300 episode:395 R:99.71536522233092\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 39.898117), ('average_entropy', 11.268663), ('average_kl', 0.006474092984810853), ('average_policy_step_size', 1.0), ('explained_variance', 0.7957010861053486)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:201800 episode:396 R:138.41855314006355\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 41.145584), ('average_entropy', 11.268663), ('average_kl', 0.006474092984810853), ('average_policy_step_size', 1.0), ('explained_variance', 0.7957010861053486)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:98.29595778314378\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:202300 episode:397 R:95.54752380094905\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 40.180805), ('average_entropy', 11.268663), ('average_kl', 0.006474092984810853), ('average_policy_step_size', 1.0), ('explained_variance', 0.7957010861053486)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:202800 episode:398 R:85.94081004324933\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 36.082504), ('average_entropy', 11.268663), ('average_kl', 0.006474092984810853), ('average_policy_step_size', 1.0), ('explained_variance', 0.7957010861053486)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:124.68016073871185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pfrl.agents.trpo:Line search iteration: 0 step size: 1.0\n",
      "INFO:pfrl.agents.trpo:Surrogate objective improve: 0.028116692090407014\n",
      "INFO:pfrl.agents.trpo:KL divergence: 0.0052462294697761536\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:203300 episode:399 R:136.29600530247578\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 36.702545), ('average_entropy', 11.268663), ('average_kl', 0.006443396396934986), ('average_policy_step_size', 1.0), ('explained_variance', 0.8429111349830336)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:103.76551939479377\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:203800 episode:400 R:124.50794922699427\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 40.113956), ('average_entropy', 11.267175), ('average_kl', 0.006443396396934986), ('average_policy_step_size', 1.0), ('explained_variance', 0.8429111349830336)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:204300 episode:401 R:121.76206301307317\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 38.919243), ('average_entropy', 11.265688), ('average_kl', 0.006443396396934986), ('average_policy_step_size', 1.0), ('explained_variance', 0.8429111349830336)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:132.68799934267994\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:204800 episode:402 R:97.37166899719172\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 38.31877), ('average_entropy', 11.265688), ('average_kl', 0.006443396396934986), ('average_policy_step_size', 1.0), ('explained_variance', 0.8429111349830336)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:141.18027753294\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:205300 episode:403 R:98.81119571145388\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 37.59959), ('average_entropy', 11.265688), ('average_kl', 0.006443396396934986), ('average_policy_step_size', 1.0), ('explained_variance', 0.8429111349830336)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:205800 episode:404 R:115.84117234947283\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 38.471283), ('average_entropy', 11.265688), ('average_kl', 0.006443396396934986), ('average_policy_step_size', 1.0), ('explained_variance', 0.8429111349830336)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:88.47842211305156\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:206300 episode:405 R:122.9902621712227\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 41.373764), ('average_entropy', 11.265688), ('average_kl', 0.006443396396934986), ('average_policy_step_size', 1.0), ('explained_variance', 0.8429111349830336)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:206800 episode:406 R:104.65146335042502\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 40.16346), ('average_entropy', 11.265688), ('average_kl', 0.006443396396934986), ('average_policy_step_size', 1.0), ('explained_variance', 0.8429111349830336)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:131.6667759585789\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:207300 episode:407 R:125.29575878001535\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 38.216515), ('average_entropy', 11.265688), ('average_kl', 0.006443396396934986), ('average_policy_step_size', 1.0), ('explained_variance', 0.8429111349830336)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:113.71847686100331\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:207800 episode:408 R:126.17730736837187\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 40.86343), ('average_entropy', 11.265688), ('average_kl', 0.006443396396934986), ('average_policy_step_size', 1.0), ('explained_variance', 0.8429111349830336)]\n",
      "INFO:pfrl.agents.trpo:Line search iteration: 0 step size: 1.0\n",
      "INFO:pfrl.agents.trpo:Surrogate objective improve: 0.029707021931244526\n",
      "INFO:pfrl.agents.trpo:KL divergence: 0.0063750906847417355\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:208300 episode:409 R:140.955315322029\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 42.428406), ('average_entropy', 11.265688), ('average_kl', 0.006441730403954663), ('average_policy_step_size', 1.0), ('explained_variance', 0.877006041962669)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:108.38117092992343\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:208800 episode:410 R:60.961457046910795\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 39.959793), ('average_entropy', 11.274613), ('average_kl', 0.006441730403954663), ('average_policy_step_size', 1.0), ('explained_variance', 0.877006041962669)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:119.93264079232036\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:209300 episode:411 R:102.17672124738101\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 39.69487), ('average_entropy', 11.28354), ('average_kl', 0.006441730403954663), ('average_policy_step_size', 1.0), ('explained_variance', 0.877006041962669)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:209800 episode:412 R:136.76362941258444\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 42.377354), ('average_entropy', 11.28354), ('average_kl', 0.006441730403954663), ('average_policy_step_size', 1.0), ('explained_variance', 0.877006041962669)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:103.27461954373004\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:210300 episode:413 R:114.36865634582728\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 43.397373), ('average_entropy', 11.28354), ('average_kl', 0.006441730403954663), ('average_policy_step_size', 1.0), ('explained_variance', 0.877006041962669)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:210800 episode:414 R:119.64243370890973\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 42.327415), ('average_entropy', 11.28354), ('average_kl', 0.006441730403954663), ('average_policy_step_size', 1.0), ('explained_variance', 0.877006041962669)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:129.58453582014684\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:211300 episode:415 R:129.3309203047436\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 39.38777), ('average_entropy', 11.28354), ('average_kl', 0.006441730403954663), ('average_policy_step_size', 1.0), ('explained_variance', 0.877006041962669)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:103.69155659378343\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:211800 episode:416 R:113.72031583973495\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 39.0339), ('average_entropy', 11.28354), ('average_kl', 0.006441730403954663), ('average_policy_step_size', 1.0), ('explained_variance', 0.877006041962669)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:212300 episode:417 R:90.99013961252102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 41.242237), ('average_entropy', 11.28354), ('average_kl', 0.006441730403954663), ('average_policy_step_size', 1.0), ('explained_variance', 0.877006041962669)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:129.26001234827459\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:212800 episode:418 R:91.60765278584716\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 42.519), ('average_entropy', 11.28354), ('average_kl', 0.006441730403954663), ('average_policy_step_size', 1.0), ('explained_variance', 0.877006041962669)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:112.61111726493016\n",
      "INFO:pfrl.agents.trpo:Line search iteration: 0 step size: 1.0\n",
      "INFO:pfrl.agents.trpo:Surrogate objective improve: 0.036623685533413664\n",
      "INFO:pfrl.agents.trpo:KL divergence: 0.004804680589586496\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:213300 episode:419 R:107.73263255288771\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 42.823257), ('average_entropy', 11.28354), ('average_kl', 0.006402753027422088), ('average_policy_step_size', 1.0), ('explained_variance', 0.7010038816762809)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:213800 episode:420 R:119.85285771737217\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 41.89209), ('average_entropy', 11.284645), ('average_kl', 0.006402753027422088), ('average_policy_step_size', 1.0), ('explained_variance', 0.7010038816762809)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:138.40083590633796\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:214300 episode:421 R:127.19408184936714\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 41.883904), ('average_entropy', 11.285751), ('average_kl', 0.006402753027422088), ('average_policy_step_size', 1.0), ('explained_variance', 0.7010038816762809)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:214800 episode:422 R:118.54853890136606\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 42.39229), ('average_entropy', 11.285751), ('average_kl', 0.006402753027422088), ('average_policy_step_size', 1.0), ('explained_variance', 0.7010038816762809)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:87.73080364799058\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:215300 episode:423 R:132.95583102749825\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 41.22867), ('average_entropy', 11.285751), ('average_kl', 0.006402753027422088), ('average_policy_step_size', 1.0), ('explained_variance', 0.7010038816762809)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:103.21233535114848\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:215800 episode:424 R:142.38305996782393\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 41.83235), ('average_entropy', 11.285751), ('average_kl', 0.006402753027422088), ('average_policy_step_size', 1.0), ('explained_variance', 0.7010038816762809)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:216300 episode:425 R:139.31042655902144\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 42.644993), ('average_entropy', 11.285751), ('average_kl', 0.006402753027422088), ('average_policy_step_size', 1.0), ('explained_variance', 0.7010038816762809)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:89.93457537661696\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:216800 episode:426 R:138.07684738463337\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 43.058117), ('average_entropy', 11.285751), ('average_kl', 0.006402753027422088), ('average_policy_step_size', 1.0), ('explained_variance', 0.7010038816762809)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:89.89575051535797\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:217300 episode:427 R:119.59806507765221\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 41.114384), ('average_entropy', 11.285751), ('average_kl', 0.006402753027422088), ('average_policy_step_size', 1.0), ('explained_variance', 0.7010038816762809)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:217800 episode:428 R:118.2759737141799\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 41.765007), ('average_entropy', 11.285751), ('average_kl', 0.006402753027422088), ('average_policy_step_size', 1.0), ('explained_variance', 0.7010038816762809)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:101.6215653208426\n",
      "INFO:pfrl.agents.trpo:Line search iteration: 0 step size: 1.0\n",
      "INFO:pfrl.agents.trpo:Surrogate objective improve: 0.030605110649048584\n",
      "INFO:pfrl.agents.trpo:KL divergence: 0.005719495937228203\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:218300 episode:429 R:117.20060345207447\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 43.472702), ('average_entropy', 11.285751), ('average_kl', 0.006386863327650137), ('average_policy_step_size', 1.0), ('explained_variance', 0.7864979487778413)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:218800 episode:430 R:125.90965329963218\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 41.27734), ('average_entropy', 11.284572), ('average_kl', 0.006386863327650137), ('average_policy_step_size', 1.0), ('explained_variance', 0.7864979487778413)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:122.67130735392395\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:219300 episode:431 R:122.84541354008327\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 42.514465), ('average_entropy', 11.283391), ('average_kl', 0.006386863327650137), ('average_policy_step_size', 1.0), ('explained_variance', 0.7864979487778413)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:129.88459984260913\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:219800 episode:432 R:122.09590012724301\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 42.807007), ('average_entropy', 11.283391), ('average_kl', 0.006386863327650137), ('average_policy_step_size', 1.0), ('explained_variance', 0.7864979487778413)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:220300 episode:433 R:132.38470930763148\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 38.934124), ('average_entropy', 11.283391), ('average_kl', 0.006386863327650137), ('average_policy_step_size', 1.0), ('explained_variance', 0.7864979487778413)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:134.2011596475805\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:220800 episode:434 R:121.13982857629956\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 40.895405), ('average_entropy', 11.283391), ('average_kl', 0.006386863327650137), ('average_policy_step_size', 1.0), ('explained_variance', 0.7864979487778413)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:122.93128523081892\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:221300 episode:435 R:130.71001418581344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 45.022007), ('average_entropy', 11.283391), ('average_kl', 0.006386863327650137), ('average_policy_step_size', 1.0), ('explained_variance', 0.7864979487778413)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:221800 episode:436 R:159.6025090475832\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 45.385338), ('average_entropy', 11.283391), ('average_kl', 0.006386863327650137), ('average_policy_step_size', 1.0), ('explained_variance', 0.7864979487778413)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:118.3893639309895\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:222300 episode:437 R:95.13154554528572\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 37.924416), ('average_entropy', 11.283391), ('average_kl', 0.006386863327650137), ('average_policy_step_size', 1.0), ('explained_variance', 0.7864979487778413)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:222800 episode:438 R:130.8168991842978\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 35.104004), ('average_entropy', 11.283391), ('average_kl', 0.006386863327650137), ('average_policy_step_size', 1.0), ('explained_variance', 0.7864979487778413)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:142.05710623567063\n",
      "INFO:pfrl.agents.trpo:Line search iteration: 0 step size: 1.0\n",
      "INFO:pfrl.agents.trpo:Surrogate objective improve: 0.03290965322230477\n",
      "INFO:pfrl.agents.trpo:KL divergence: 0.006048381328582764\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:223300 episode:439 R:101.35375021439063\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 42.07813), ('average_entropy', 11.283391), ('average_kl', 0.00637917055494406), ('average_policy_step_size', 1.0), ('explained_variance', 0.9118850890684255)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:105.6881666221171\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:223800 episode:440 R:117.9117938223555\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 44.24859), ('average_entropy', 11.295629), ('average_kl', 0.00637917055494406), ('average_policy_step_size', 1.0), ('explained_variance', 0.9118850890684255)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:224300 episode:441 R:103.5033460223928\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 43.608284), ('average_entropy', 11.307867), ('average_kl', 0.00637917055494406), ('average_policy_step_size', 1.0), ('explained_variance', 0.9118850890684255)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:84.83837927317664\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:224800 episode:442 R:105.03772607603945\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 39.991524), ('average_entropy', 11.307867), ('average_kl', 0.00637917055494406), ('average_policy_step_size', 1.0), ('explained_variance', 0.9118850890684255)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:113.14135839317679\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:225300 episode:443 R:138.14238652707107\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 42.201992), ('average_entropy', 11.307867), ('average_kl', 0.00637917055494406), ('average_policy_step_size', 1.0), ('explained_variance', 0.9118850890684255)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:225800 episode:444 R:117.5377483198183\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 46.14785), ('average_entropy', 11.307867), ('average_kl', 0.00637917055494406), ('average_policy_step_size', 1.0), ('explained_variance', 0.9118850890684255)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:130.1981159201271\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:226300 episode:445 R:141.8392099080148\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 44.40983), ('average_entropy', 11.307867), ('average_kl', 0.00637917055494406), ('average_policy_step_size', 1.0), ('explained_variance', 0.9118850890684255)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:226800 episode:446 R:104.13793165574661\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 42.747166), ('average_entropy', 11.307867), ('average_kl', 0.00637917055494406), ('average_policy_step_size', 1.0), ('explained_variance', 0.9118850890684255)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:148.05795788436663\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:227300 episode:447 R:153.4218042225611\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 43.657547), ('average_entropy', 11.307867), ('average_kl', 0.00637917055494406), ('average_policy_step_size', 1.0), ('explained_variance', 0.9118850890684255)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:108.12615230362378\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:227800 episode:448 R:110.13581881445938\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 45.789246), ('average_entropy', 11.307867), ('average_kl', 0.00637917055494406), ('average_policy_step_size', 1.0), ('explained_variance', 0.9118850890684255)]\n",
      "INFO:pfrl.agents.trpo:Line search iteration: 0 step size: 1.0\n",
      "INFO:pfrl.agents.trpo:Surrogate objective improve: 0.03109807659711805\n",
      "INFO:pfrl.agents.trpo:KL divergence: 0.0048975651152431965\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:228300 episode:449 R:127.45610716152376\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 47.212578), ('average_entropy', 11.307867), ('average_kl', 0.0063462459896173745), ('average_policy_step_size', 1.0), ('explained_variance', 0.839609662370181)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:132.0411426954558\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:228800 episode:450 R:141.35682968009522\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 47.921753), ('average_entropy', 11.299923), ('average_kl', 0.0063462459896173745), ('average_policy_step_size', 1.0), ('explained_variance', 0.839609662370181)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:128.056238799729\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:229300 episode:451 R:137.63733524308958\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 47.3597), ('average_entropy', 11.291979), ('average_kl', 0.0063462459896173745), ('average_policy_step_size', 1.0), ('explained_variance', 0.839609662370181)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:229800 episode:452 R:105.36578755264749\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 44.04111), ('average_entropy', 11.291979), ('average_kl', 0.0063462459896173745), ('average_policy_step_size', 1.0), ('explained_variance', 0.839609662370181)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:120.0785651100862\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:230300 episode:453 R:128.6198956474928\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 39.24499), ('average_entropy', 11.291979), ('average_kl', 0.0063462459896173745), ('average_policy_step_size', 1.0), ('explained_variance', 0.839609662370181)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:230800 episode:454 R:105.87839343016181\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 40.460957), ('average_entropy', 11.291979), ('average_kl', 0.0063462459896173745), ('average_policy_step_size', 1.0), ('explained_variance', 0.839609662370181)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:126.12896804162149\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:231300 episode:455 R:121.32289952777731\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 45.274437), ('average_entropy', 11.291979), ('average_kl', 0.0063462459896173745), ('average_policy_step_size', 1.0), ('explained_variance', 0.839609662370181)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:131.54678815800068\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:231800 episode:456 R:117.81153857281983\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 45.09998), ('average_entropy', 11.291979), ('average_kl', 0.0063462459896173745), ('average_policy_step_size', 1.0), ('explained_variance', 0.839609662370181)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:232300 episode:457 R:115.44925856514494\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 44.494045), ('average_entropy', 11.291979), ('average_kl', 0.0063462459896173745), ('average_policy_step_size', 1.0), ('explained_variance', 0.839609662370181)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:79.37475706656684\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:232800 episode:458 R:104.76144015407382\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 43.485622), ('average_entropy', 11.291979), ('average_kl', 0.0063462459896173745), ('average_policy_step_size', 1.0), ('explained_variance', 0.839609662370181)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:138.729480976353\n",
      "INFO:pfrl.agents.trpo:Line search iteration: 0 step size: 1.0\n",
      "INFO:pfrl.agents.trpo:Surrogate objective improve: 0.029852371400920674\n",
      "INFO:pfrl.agents.trpo:KL divergence: 0.006080882158130407\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:233300 episode:459 R:128.14550079939565\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 44.789314), ('average_entropy', 11.291979), ('average_kl', 0.006340477210672006), ('average_policy_step_size', 1.0), ('explained_variance', 0.9125767723640789)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:233800 episode:460 R:141.93435200652223\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 47.69095), ('average_entropy', 11.294588), ('average_kl', 0.006340477210672006), ('average_policy_step_size', 1.0), ('explained_variance', 0.9125767723640789)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:127.36726109297577\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:234300 episode:461 R:121.35945077652578\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 46.53658), ('average_entropy', 11.297197), ('average_kl', 0.006340477210672006), ('average_policy_step_size', 1.0), ('explained_variance', 0.9125767723640789)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:234800 episode:462 R:128.28450101632387\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 45.78222), ('average_entropy', 11.297197), ('average_kl', 0.006340477210672006), ('average_policy_step_size', 1.0), ('explained_variance', 0.9125767723640789)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:140.58303277096468\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:235300 episode:463 R:137.62780681182994\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 47.175858), ('average_entropy', 11.297197), ('average_kl', 0.006340477210672006), ('average_policy_step_size', 1.0), ('explained_variance', 0.9125767723640789)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:124.23575099083813\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:235800 episode:464 R:115.92940436277489\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 46.63139), ('average_entropy', 11.297197), ('average_kl', 0.006340477210672006), ('average_policy_step_size', 1.0), ('explained_variance', 0.9125767723640789)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:236300 episode:465 R:127.39677674240241\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 45.95218), ('average_entropy', 11.297197), ('average_kl', 0.006340477210672006), ('average_policy_step_size', 1.0), ('explained_variance', 0.9125767723640789)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:120.31475996848067\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:236800 episode:466 R:114.59090123343438\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 47.69142), ('average_entropy', 11.297197), ('average_kl', 0.006340477210672006), ('average_policy_step_size', 1.0), ('explained_variance', 0.9125767723640789)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:118.17793557310357\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:237300 episode:467 R:111.2306695129502\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 44.478127), ('average_entropy', 11.297197), ('average_kl', 0.006340477210672006), ('average_policy_step_size', 1.0), ('explained_variance', 0.9125767723640789)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:237800 episode:468 R:85.7499130918766\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 43.109516), ('average_entropy', 11.297197), ('average_kl', 0.006340477210672006), ('average_policy_step_size', 1.0), ('explained_variance', 0.9125767723640789)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:141.82842704614703\n",
      "INFO:pfrl.agents.trpo:Line search iteration: 0 step size: 1.0\n",
      "INFO:pfrl.agents.trpo:Surrogate objective improve: 0.02776703740528319\n",
      "INFO:pfrl.agents.trpo:KL divergence: 0.005678141489624977\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:238300 episode:469 R:80.19445465474413\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 45.039513), ('average_entropy', 11.297197), ('average_kl', 0.006326384961288026), ('average_policy_step_size', 1.0), ('explained_variance', 0.7540694878090096)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:238800 episode:470 R:115.72867298640041\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 43.073048), ('average_entropy', 11.298803), ('average_kl', 0.006326384961288026), ('average_policy_step_size', 1.0), ('explained_variance', 0.7540694878090096)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:73.63894791674169\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:239300 episode:471 R:109.14287258634234\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 41.846546), ('average_entropy', 11.300409), ('average_kl', 0.006326384961288026), ('average_policy_step_size', 1.0), ('explained_variance', 0.7540694878090096)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:103.04449852293146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:239800 episode:472 R:139.17432428418354\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 46.3422), ('average_entropy', 11.300409), ('average_kl', 0.006326384961288026), ('average_policy_step_size', 1.0), ('explained_variance', 0.7540694878090096)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:240300 episode:473 R:132.18062037092002\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 47.57417), ('average_entropy', 11.300409), ('average_kl', 0.006326384961288026), ('average_policy_step_size', 1.0), ('explained_variance', 0.7540694878090096)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:116.71419191509523\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:240800 episode:474 R:135.53288349273754\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 47.19635), ('average_entropy', 11.300409), ('average_kl', 0.006326384961288026), ('average_policy_step_size', 1.0), ('explained_variance', 0.7540694878090096)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:136.78040361492438\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:241300 episode:475 R:126.97723236657916\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 48.802395), ('average_entropy', 11.300409), ('average_kl', 0.006326384961288026), ('average_policy_step_size', 1.0), ('explained_variance', 0.7540694878090096)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:241800 episode:476 R:130.3049642641881\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 44.254257), ('average_entropy', 11.300409), ('average_kl', 0.006326384961288026), ('average_policy_step_size', 1.0), ('explained_variance', 0.7540694878090096)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:141.41383165754513\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:242300 episode:477 R:125.01736010792237\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 41.846085), ('average_entropy', 11.300409), ('average_kl', 0.006326384961288026), ('average_policy_step_size', 1.0), ('explained_variance', 0.7540694878090096)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:242800 episode:478 R:112.00534266885442\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 44.58402), ('average_entropy', 11.300409), ('average_kl', 0.006326384961288026), ('average_policy_step_size', 1.0), ('explained_variance', 0.7540694878090096)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:108.9933294814647\n",
      "INFO:pfrl.agents.trpo:Line search iteration: 0 step size: 1.0\n",
      "INFO:pfrl.agents.trpo:Surrogate objective improve: 0.03217091194983368\n",
      "INFO:pfrl.agents.trpo:KL divergence: 0.0065992153249681\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:243300 episode:479 R:113.96844125784935\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 46.36042), ('average_entropy', 11.300409), ('average_kl', 0.006332068927198027), ('average_policy_step_size', 1.0), ('explained_variance', 0.8771117439324906)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:135.4628359453353\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:243800 episode:480 R:133.29042453778615\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 46.13671), ('average_entropy', 11.296872), ('average_kl', 0.006332068927198027), ('average_policy_step_size', 1.0), ('explained_variance', 0.8771117439324906)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:244300 episode:481 R:120.51353909315576\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 45.626713), ('average_entropy', 11.293335), ('average_kl', 0.006332068927198027), ('average_policy_step_size', 1.0), ('explained_variance', 0.8771117439324906)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:138.19687894343932\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:244800 episode:482 R:120.5393580437394\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 45.5234), ('average_entropy', 11.293335), ('average_kl', 0.006332068927198027), ('average_policy_step_size', 1.0), ('explained_variance', 0.8771117439324906)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:135.34116769041714\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:245300 episode:483 R:133.15053161392152\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 45.79876), ('average_entropy', 11.293335), ('average_kl', 0.006332068927198027), ('average_policy_step_size', 1.0), ('explained_variance', 0.8771117439324906)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:245800 episode:484 R:133.23803866755512\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 46.028595), ('average_entropy', 11.293335), ('average_kl', 0.006332068927198027), ('average_policy_step_size', 1.0), ('explained_variance', 0.8771117439324906)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:116.96427420848048\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:246300 episode:485 R:122.45966635159574\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 43.660202), ('average_entropy', 11.293335), ('average_kl', 0.006332068927198027), ('average_policy_step_size', 1.0), ('explained_variance', 0.8771117439324906)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:246800 episode:486 R:114.77190246541447\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 44.726933), ('average_entropy', 11.293335), ('average_kl', 0.006332068927198027), ('average_policy_step_size', 1.0), ('explained_variance', 0.8771117439324906)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:139.1879385897812\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:247300 episode:487 R:109.21809642304991\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 47.49505), ('average_entropy', 11.293335), ('average_kl', 0.006332068927198027), ('average_policy_step_size', 1.0), ('explained_variance', 0.8771117439324906)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:132.44716063502221\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:247800 episode:488 R:122.94419130641568\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 43.76229), ('average_entropy', 11.293335), ('average_kl', 0.006332068927198027), ('average_policy_step_size', 1.0), ('explained_variance', 0.8771117439324906)]\n",
      "INFO:pfrl.agents.trpo:Line search iteration: 0 step size: 1.0\n",
      "INFO:pfrl.agents.trpo:Surrogate objective improve: 0.02922877500532195\n",
      "INFO:pfrl.agents.trpo:KL divergence: 0.006142239086329937\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:248300 episode:489 R:135.21354721575239\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 42.82832), ('average_entropy', 11.293335), ('average_kl', 0.006328194848812965), ('average_policy_step_size', 1.0), ('explained_variance', 0.8628292486454274)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:133.16300294731815\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:248800 episode:490 R:107.16545394803273\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 43.632378), ('average_entropy', 11.2799835), ('average_kl', 0.006328194848812965), ('average_policy_step_size', 1.0), ('explained_variance', 0.8628292486454274)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:140.06173139515099\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:249300 episode:491 R:121.34996646675822\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 45.232445), ('average_entropy', 11.266631), ('average_kl', 0.006328194848812965), ('average_policy_step_size', 1.0), ('explained_variance', 0.8628292486454274)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:249800 episode:492 R:124.5656045922435\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 48.451588), ('average_entropy', 11.266631), ('average_kl', 0.006328194848812965), ('average_policy_step_size', 1.0), ('explained_variance', 0.8628292486454274)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:111.11273767541982\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:250300 episode:493 R:120.08461656933342\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 49.181007), ('average_entropy', 11.266631), ('average_kl', 0.006328194848812965), ('average_policy_step_size', 1.0), ('explained_variance', 0.8628292486454274)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:250800 episode:494 R:121.25364353130185\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 47.785572), ('average_entropy', 11.266631), ('average_kl', 0.006328194848812965), ('average_policy_step_size', 1.0), ('explained_variance', 0.8628292486454274)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:135.88129428995418\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:251300 episode:495 R:110.8442609769114\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 44.66), ('average_entropy', 11.266631), ('average_kl', 0.006328194848812965), ('average_policy_step_size', 1.0), ('explained_variance', 0.8628292486454274)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:104.6573510401008\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:251800 episode:496 R:152.00059869068107\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 45.368668), ('average_entropy', 11.266631), ('average_kl', 0.006328194848812965), ('average_policy_step_size', 1.0), ('explained_variance', 0.8628292486454274)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:252300 episode:497 R:113.66979117433078\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 46.269608), ('average_entropy', 11.266631), ('average_kl', 0.006328194848812965), ('average_policy_step_size', 1.0), ('explained_variance', 0.8628292486454274)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:124.27962349502592\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:252800 episode:498 R:152.93346129797402\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 47.44186), ('average_entropy', 11.266631), ('average_kl', 0.006328194848812965), ('average_policy_step_size', 1.0), ('explained_variance', 0.8628292486454274)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:122.93834524488081\n",
      "INFO:pfrl.agents.trpo:Line search iteration: 0 step size: 1.0\n",
      "INFO:pfrl.agents.trpo:Surrogate objective improve: 0.029401919015981548\n",
      "INFO:pfrl.agents.trpo:KL divergence: 0.005949212703853846\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:253300 episode:499 R:131.81811136573117\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 47.62278), ('average_entropy', 11.266631), ('average_kl', 0.0063206152059137825), ('average_policy_step_size', 1.0), ('explained_variance', 0.7871218250363927)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:253800 episode:500 R:138.0098300003308\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 46.843357), ('average_entropy', 11.262657), ('average_kl', 0.0063206152059137825), ('average_policy_step_size', 1.0), ('explained_variance', 0.7871218250363927)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:128.94529677924183\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:254300 episode:501 R:120.0681158796851\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 45.755898), ('average_entropy', 11.258682), ('average_kl', 0.0063206152059137825), ('average_policy_step_size', 1.0), ('explained_variance', 0.7871218250363927)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:254800 episode:502 R:116.8274537078159\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 46.624313), ('average_entropy', 11.258682), ('average_kl', 0.0063206152059137825), ('average_policy_step_size', 1.0), ('explained_variance', 0.7871218250363927)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:131.5042185179787\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:255300 episode:503 R:142.55967528289207\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 49.5721), ('average_entropy', 11.258682), ('average_kl', 0.0063206152059137825), ('average_policy_step_size', 1.0), ('explained_variance', 0.7871218250363927)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:122.81654047619969\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:255800 episode:504 R:119.54119098513416\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 47.738506), ('average_entropy', 11.258682), ('average_kl', 0.0063206152059137825), ('average_policy_step_size', 1.0), ('explained_variance', 0.7871218250363927)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:256300 episode:505 R:115.97775698084563\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 46.439), ('average_entropy', 11.258682), ('average_kl', 0.0063206152059137825), ('average_policy_step_size', 1.0), ('explained_variance', 0.7871218250363927)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:127.8997167462027\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:256800 episode:506 R:123.43103220807876\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 45.97011), ('average_entropy', 11.258682), ('average_kl', 0.0063206152059137825), ('average_policy_step_size', 1.0), ('explained_variance', 0.7871218250363927)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:124.09611237428972\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:257300 episode:507 R:102.13691170641623\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 45.3495), ('average_entropy', 11.258682), ('average_kl', 0.0063206152059137825), ('average_policy_step_size', 1.0), ('explained_variance', 0.7871218250363927)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:257800 episode:508 R:110.06756529844989\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 46.228218), ('average_entropy', 11.258682), ('average_kl', 0.0063206152059137825), ('average_policy_step_size', 1.0), ('explained_variance', 0.7871218250363927)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:128.48576806803462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pfrl.agents.trpo:Line search iteration: 0 step size: 1.0\n",
      "INFO:pfrl.agents.trpo:Surrogate objective improve: 0.02952539840771351\n",
      "INFO:pfrl.agents.trpo:KL divergence: 0.006422804668545723\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:258300 episode:509 R:153.41016674750847\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 48.807255), ('average_entropy', 11.258682), ('average_kl', 0.00632261892086735), ('average_policy_step_size', 1.0), ('explained_variance', 0.7890972424436757)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:258800 episode:510 R:142.68793915441358\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 50.1716), ('average_entropy', 11.266164), ('average_kl', 0.00632261892086735), ('average_policy_step_size', 1.0), ('explained_variance', 0.7890972424436757)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:137.36506098176932\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:259300 episode:511 R:139.21081901747036\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 48.908043), ('average_entropy', 11.273644), ('average_kl', 0.00632261892086735), ('average_policy_step_size', 1.0), ('explained_variance', 0.7890972424436757)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:135.3404224393713\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:259800 episode:512 R:129.57258975101252\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 46.842896), ('average_entropy', 11.273644), ('average_kl', 0.00632261892086735), ('average_policy_step_size', 1.0), ('explained_variance', 0.7890972424436757)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:260300 episode:513 R:129.12943338848734\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 45.066776), ('average_entropy', 11.273644), ('average_kl', 0.00632261892086735), ('average_policy_step_size', 1.0), ('explained_variance', 0.7890972424436757)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:133.7565111533489\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:260800 episode:514 R:123.42985721567648\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 46.27712), ('average_entropy', 11.273644), ('average_kl', 0.00632261892086735), ('average_policy_step_size', 1.0), ('explained_variance', 0.7890972424436757)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:104.18975016026172\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:261300 episode:515 R:139.40565522632392\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 49.592453), ('average_entropy', 11.273644), ('average_kl', 0.00632261892086735), ('average_policy_step_size', 1.0), ('explained_variance', 0.7890972424436757)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:261800 episode:516 R:130.34136490568116\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 50.628315), ('average_entropy', 11.273644), ('average_kl', 0.00632261892086735), ('average_policy_step_size', 1.0), ('explained_variance', 0.7890972424436757)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:136.81408550888904\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:262300 episode:517 R:118.19160397804326\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 47.79583), ('average_entropy', 11.273644), ('average_kl', 0.00632261892086735), ('average_policy_step_size', 1.0), ('explained_variance', 0.7890972424436757)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:262800 episode:518 R:106.42642974998358\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 45.97014), ('average_entropy', 11.273644), ('average_kl', 0.00632261892086735), ('average_policy_step_size', 1.0), ('explained_variance', 0.7890972424436757)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:128.18656082520874\n",
      "INFO:pfrl.agents.trpo:Line search iteration: 0 step size: 1.0\n",
      "INFO:pfrl.agents.trpo:Surrogate objective improve: 0.03387476901116315\n",
      "INFO:pfrl.agents.trpo:KL divergence: 0.006699767895042896\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:263300 episode:519 R:137.49925385124834\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 47.7452), ('average_entropy', 11.273644), ('average_kl', 0.006329871785755341), ('average_policy_step_size', 1.0), ('explained_variance', 0.8375570620884712)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:110.8842423760716\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:263800 episode:520 R:128.4262146823851\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 48.239662), ('average_entropy', 11.270728), ('average_kl', 0.006329871785755341), ('average_policy_step_size', 1.0), ('explained_variance', 0.8375570620884712)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:264300 episode:521 R:162.68655356718668\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 46.309383), ('average_entropy', 11.267813), ('average_kl', 0.006329871785755341), ('average_policy_step_size', 1.0), ('explained_variance', 0.8375570620884712)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:113.3730531836571\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:264800 episode:522 R:137.17731591428492\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 47.71164), ('average_entropy', 11.267813), ('average_kl', 0.006329871785755341), ('average_policy_step_size', 1.0), ('explained_variance', 0.8375570620884712)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:121.91927418812644\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:265300 episode:523 R:129.66905729974403\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 49.621017), ('average_entropy', 11.267813), ('average_kl', 0.006329871785755341), ('average_policy_step_size', 1.0), ('explained_variance', 0.8375570620884712)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:265800 episode:524 R:107.59521760466231\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 47.75611), ('average_entropy', 11.267813), ('average_kl', 0.006329871785755341), ('average_policy_step_size', 1.0), ('explained_variance', 0.8375570620884712)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:113.74049664640985\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:266300 episode:525 R:130.50353089494413\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 48.63021), ('average_entropy', 11.267813), ('average_kl', 0.006329871785755341), ('average_policy_step_size', 1.0), ('explained_variance', 0.8375570620884712)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:266800 episode:526 R:141.6230610192665\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 49.50046), ('average_entropy', 11.267813), ('average_kl', 0.006329871785755341), ('average_policy_step_size', 1.0), ('explained_variance', 0.8375570620884712)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:134.77377684494812\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:267300 episode:527 R:136.46080063645945\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 48.45399), ('average_entropy', 11.267813), ('average_kl', 0.006329871785755341), ('average_policy_step_size', 1.0), ('explained_variance', 0.8375570620884712)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:122.45383240730328\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:267800 episode:528 R:148.92597373928805\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 47.873985), ('average_entropy', 11.267813), ('average_kl', 0.006329871785755341), ('average_policy_step_size', 1.0), ('explained_variance', 0.8375570620884712)]\n",
      "INFO:pfrl.agents.trpo:Line search iteration: 0 step size: 1.0\n",
      "INFO:pfrl.agents.trpo:Surrogate objective improve: 0.026950978266540915\n",
      "INFO:pfrl.agents.trpo:KL divergence: 0.0058974046260118484\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:268300 episode:529 R:137.54377666139484\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 48.27967), ('average_entropy', 11.267813), ('average_kl', 0.006321712028024331), ('average_policy_step_size', 1.0), ('explained_variance', 0.7505044967805701)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:127.73504559060706\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:268800 episode:530 R:155.75965833267196\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 49.701008), ('average_entropy', 11.244675), ('average_kl', 0.006321712028024331), ('average_policy_step_size', 1.0), ('explained_variance', 0.7505044967805701)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:124.00282294609559\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:269300 episode:531 R:146.22499092356637\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 50.304047), ('average_entropy', 11.221539), ('average_kl', 0.006321712028024331), ('average_policy_step_size', 1.0), ('explained_variance', 0.7505044967805701)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:269800 episode:532 R:134.91552150331586\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 51.666588), ('average_entropy', 11.221539), ('average_kl', 0.006321712028024331), ('average_policy_step_size', 1.0), ('explained_variance', 0.7505044967805701)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:119.49202738727438\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:270300 episode:533 R:84.98167403918713\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 50.320686), ('average_entropy', 11.221539), ('average_kl', 0.006321712028024331), ('average_policy_step_size', 1.0), ('explained_variance', 0.7505044967805701)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:270800 episode:534 R:139.36529472129962\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 48.2629), ('average_entropy', 11.221539), ('average_kl', 0.006321712028024331), ('average_policy_step_size', 1.0), ('explained_variance', 0.7505044967805701)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:127.53240474951953\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:271300 episode:535 R:114.06118407413304\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 46.78174), ('average_entropy', 11.221539), ('average_kl', 0.006321712028024331), ('average_policy_step_size', 1.0), ('explained_variance', 0.7505044967805701)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:130.3577087792662\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:271800 episode:536 R:138.00685281464823\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 48.10286), ('average_entropy', 11.221539), ('average_kl', 0.006321712028024331), ('average_policy_step_size', 1.0), ('explained_variance', 0.7505044967805701)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:272300 episode:537 R:131.04747293855175\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 48.936398), ('average_entropy', 11.221539), ('average_kl', 0.006321712028024331), ('average_policy_step_size', 1.0), ('explained_variance', 0.7505044967805701)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:141.51708759217186\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:272800 episode:538 R:131.6585547964756\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 48.839203), ('average_entropy', 11.221539), ('average_kl', 0.006321712028024331), ('average_policy_step_size', 1.0), ('explained_variance', 0.7505044967805701)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:122.99996370851834\n",
      "INFO:pfrl.agents.trpo:Line search iteration: 0 step size: 1.0\n",
      "INFO:pfrl.agents.trpo:Surrogate objective improve: 0.03320025592984166\n",
      "INFO:pfrl.agents.trpo:KL divergence: 0.006577609106898308\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:273300 episode:539 R:124.47497997904223\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 50.366528), ('average_entropy', 11.221539), ('average_kl', 0.006326450862818294), ('average_policy_step_size', 1.0), ('explained_variance', 0.8005604345422954)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:273800 episode:540 R:121.73745034914478\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 48.84378), ('average_entropy', 11.212216), ('average_kl', 0.006326450862818294), ('average_policy_step_size', 1.0), ('explained_variance', 0.8005604345422954)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:136.114235165661\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:274300 episode:541 R:144.58484196349215\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 49.978867), ('average_entropy', 11.202894), ('average_kl', 0.006326450862818294), ('average_policy_step_size', 1.0), ('explained_variance', 0.8005604345422954)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:274800 episode:542 R:148.7658854141651\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 52.62486), ('average_entropy', 11.202894), ('average_kl', 0.006326450862818294), ('average_policy_step_size', 1.0), ('explained_variance', 0.8005604345422954)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:145.05632703155092\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:275300 episode:543 R:146.49744217528993\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 52.69801), ('average_entropy', 11.202894), ('average_kl', 0.006326450862818294), ('average_policy_step_size', 1.0), ('explained_variance', 0.8005604345422954)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:155.12946672930246\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:275800 episode:544 R:141.2564364895196\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 52.783512), ('average_entropy', 11.202894), ('average_kl', 0.006326450862818294), ('average_policy_step_size', 1.0), ('explained_variance', 0.8005604345422954)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:276300 episode:545 R:139.77004531937192\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 50.93317), ('average_entropy', 11.202894), ('average_kl', 0.006326450862818294), ('average_policy_step_size', 1.0), ('explained_variance', 0.8005604345422954)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:123.16631888534049\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:276800 episode:546 R:143.4167476809255\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 50.063026), ('average_entropy', 11.202894), ('average_kl', 0.006326450862818294), ('average_policy_step_size', 1.0), ('explained_variance', 0.8005604345422954)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:143.66607361660016\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:277300 episode:547 R:136.8269961670978\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 50.858788), ('average_entropy', 11.202894), ('average_kl', 0.006326450862818294), ('average_policy_step_size', 1.0), ('explained_variance', 0.8005604345422954)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:277800 episode:548 R:135.57284223270992\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 49.761604), ('average_entropy', 11.202894), ('average_kl', 0.006326450862818294), ('average_policy_step_size', 1.0), ('explained_variance', 0.8005604345422954)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:135.12250548622478\n",
      "INFO:pfrl.agents.trpo:Line search iteration: 0 step size: 1.0\n",
      "INFO:pfrl.agents.trpo:Surrogate objective improve: 0.028320197357970756\n",
      "INFO:pfrl.agents.trpo:KL divergence: 0.005816742777824402\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:278300 episode:549 R:136.05798027750438\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 50.090942), ('average_entropy', 11.202894), ('average_kl', 0.006317183443091132), ('average_policy_step_size', 1.0), ('explained_variance', 0.8197492422749565)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:278800 episode:550 R:105.99653582426551\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 48.615387), ('average_entropy', 11.193193), ('average_kl', 0.006317183443091132), ('average_policy_step_size', 1.0), ('explained_variance', 0.8197492422749565)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:135.95267567852548\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:279300 episode:551 R:133.146576369044\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 47.949184), ('average_entropy', 11.183491), ('average_kl', 0.006317183443091132), ('average_policy_step_size', 1.0), ('explained_variance', 0.8197492422749565)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:130.39852313105433\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:279800 episode:552 R:145.95991086854622\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 50.173775), ('average_entropy', 11.183491), ('average_kl', 0.006317183443091132), ('average_policy_step_size', 1.0), ('explained_variance', 0.8197492422749565)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:280300 episode:553 R:147.479846832873\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 50.656197), ('average_entropy', 11.183491), ('average_kl', 0.006317183443091132), ('average_policy_step_size', 1.0), ('explained_variance', 0.8197492422749565)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:149.58335417199945\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:280800 episode:554 R:132.79275091056374\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 49.1478), ('average_entropy', 11.183491), ('average_kl', 0.006317183443091132), ('average_policy_step_size', 1.0), ('explained_variance', 0.8197492422749565)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:128.96914202088456\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:281300 episode:555 R:149.9993520001286\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 50.268314), ('average_entropy', 11.183491), ('average_kl', 0.006317183443091132), ('average_policy_step_size', 1.0), ('explained_variance', 0.8197492422749565)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:281800 episode:556 R:105.3885583796268\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 51.076607), ('average_entropy', 11.183491), ('average_kl', 0.006317183443091132), ('average_policy_step_size', 1.0), ('explained_variance', 0.8197492422749565)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:117.79711687471628\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:282300 episode:557 R:146.71261081160915\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 51.610203), ('average_entropy', 11.183491), ('average_kl', 0.006317183443091132), ('average_policy_step_size', 1.0), ('explained_variance', 0.8197492422749565)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:282800 episode:558 R:138.03060365293365\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 52.088547), ('average_entropy', 11.183491), ('average_kl', 0.006317183443091132), ('average_policy_step_size', 1.0), ('explained_variance', 0.8197492422749565)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:151.04459147428435\n",
      "INFO:pfrl.agents.trpo:Line search iteration: 0 step size: 1.0\n",
      "INFO:pfrl.agents.trpo:Surrogate objective improve: 0.03171420375292655\n",
      "INFO:pfrl.agents.trpo:KL divergence: 0.006372049450874329\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:283300 episode:559 R:113.61060285729187\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 49.61543), ('average_entropy', 11.183491), ('average_kl', 0.0063181631932301184), ('average_policy_step_size', 1.0), ('explained_variance', 0.8410306240742254)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:134.05051957801044\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:283800 episode:560 R:167.47176059644158\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 50.97351), ('average_entropy', 11.187526), ('average_kl', 0.0063181631932301184), ('average_policy_step_size', 1.0), ('explained_variance', 0.8410306240742254)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:284300 episode:561 R:134.14317429348623\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 52.120678), ('average_entropy', 11.19156), ('average_kl', 0.0063181631932301184), ('average_policy_step_size', 1.0), ('explained_variance', 0.8410306240742254)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:142.9097647862517\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:284800 episode:562 R:108.01159147376934\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 49.4575), ('average_entropy', 11.19156), ('average_kl', 0.0063181631932301184), ('average_policy_step_size', 1.0), ('explained_variance', 0.8410306240742254)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:122.6739420521005\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:285300 episode:563 R:84.0548857963572\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 44.63225), ('average_entropy', 11.19156), ('average_kl', 0.0063181631932301184), ('average_policy_step_size', 1.0), ('explained_variance', 0.8410306240742254)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:285800 episode:564 R:157.32227356257056\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 46.866695), ('average_entropy', 11.19156), ('average_kl', 0.0063181631932301184), ('average_policy_step_size', 1.0), ('explained_variance', 0.8410306240742254)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:132.48564003463198\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:286300 episode:565 R:149.7385942548888\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 50.321465), ('average_entropy', 11.19156), ('average_kl', 0.0063181631932301184), ('average_policy_step_size', 1.0), ('explained_variance', 0.8410306240742254)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:286800 episode:566 R:141.81359378159618\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 50.785515), ('average_entropy', 11.19156), ('average_kl', 0.0063181631932301184), ('average_policy_step_size', 1.0), ('explained_variance', 0.8410306240742254)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:134.20000792589155\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:287300 episode:567 R:152.01521176361402\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 52.90939), ('average_entropy', 11.19156), ('average_kl', 0.0063181631932301184), ('average_policy_step_size', 1.0), ('explained_variance', 0.8410306240742254)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:110.0924472430729\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:287800 episode:568 R:163.60194704608534\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 51.78476), ('average_entropy', 11.19156), ('average_kl', 0.0063181631932301184), ('average_policy_step_size', 1.0), ('explained_variance', 0.8410306240742254)]\n",
      "INFO:pfrl.agents.trpo:Line search iteration: 0 step size: 1.0\n",
      "INFO:pfrl.agents.trpo:Surrogate objective improve: 0.0351981499188696\n",
      "INFO:pfrl.agents.trpo:KL divergence: 0.005098181776702404\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:288300 episode:569 R:129.3975101391932\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 50.7165), ('average_entropy', 11.19156), ('average_kl', 0.0062967600104840175), ('average_policy_step_size', 1.0), ('explained_variance', 0.8917110937430175)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:140.24980533833227\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:288800 episode:570 R:156.0671336661492\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 49.944275), ('average_entropy', 11.190179), ('average_kl', 0.0062967600104840175), ('average_policy_step_size', 1.0), ('explained_variance', 0.8917110937430175)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:149.54676686376231\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:289300 episode:571 R:117.30807561692427\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 48.232475), ('average_entropy', 11.188798), ('average_kl', 0.0062967600104840175), ('average_policy_step_size', 1.0), ('explained_variance', 0.8917110937430175)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:289800 episode:572 R:129.0885067694311\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 48.125633), ('average_entropy', 11.188798), ('average_kl', 0.0062967600104840175), ('average_policy_step_size', 1.0), ('explained_variance', 0.8917110937430175)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:142.82312594314809\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:290300 episode:573 R:137.24156294044195\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 51.512703), ('average_entropy', 11.188798), ('average_kl', 0.0062967600104840175), ('average_policy_step_size', 1.0), ('explained_variance', 0.8917110937430175)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:290800 episode:574 R:141.67915580252304\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 53.109173), ('average_entropy', 11.188798), ('average_kl', 0.0062967600104840175), ('average_policy_step_size', 1.0), ('explained_variance', 0.8917110937430175)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:127.29509510559892\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:291300 episode:575 R:132.09435549670746\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 51.46692), ('average_entropy', 11.188798), ('average_kl', 0.0062967600104840175), ('average_policy_step_size', 1.0), ('explained_variance', 0.8917110937430175)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:129.45877565391407\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:291800 episode:576 R:139.10656427967527\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 50.78485), ('average_entropy', 11.188798), ('average_kl', 0.0062967600104840175), ('average_policy_step_size', 1.0), ('explained_variance', 0.8917110937430175)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:292300 episode:577 R:135.02290657949757\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 51.316086), ('average_entropy', 11.188798), ('average_kl', 0.0062967600104840175), ('average_policy_step_size', 1.0), ('explained_variance', 0.8917110937430175)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:141.98284618993225\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:292800 episode:578 R:131.59098426077298\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 51.08182), ('average_entropy', 11.188798), ('average_kl', 0.0062967600104840175), ('average_policy_step_size', 1.0), ('explained_variance', 0.8917110937430175)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:62.17018588457186\n",
      "INFO:pfrl.agents.trpo:Line search iteration: 0 step size: 1.0\n",
      "INFO:pfrl.agents.trpo:Surrogate objective improve: 0.029607758415295393\n",
      "INFO:pfrl.agents.trpo:KL divergence: 0.006418578326702118\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:293300 episode:579 R:145.62846551139688\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 52.02217), ('average_entropy', 11.188798), ('average_kl', 0.0062988603262808815), ('average_policy_step_size', 1.0), ('explained_variance', 0.8481620279543133)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:293800 episode:580 R:135.73368089835446\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 52.768368), ('average_entropy', 11.186479), ('average_kl', 0.0062988603262808815), ('average_policy_step_size', 1.0), ('explained_variance', 0.8481620279543133)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:132.1363558429653\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:294300 episode:581 R:124.80660343364534\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 50.681416), ('average_entropy', 11.184159), ('average_kl', 0.0062988603262808815), ('average_policy_step_size', 1.0), ('explained_variance', 0.8481620279543133)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:294800 episode:582 R:133.88675110370608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 49.568874), ('average_entropy', 11.184159), ('average_kl', 0.0062988603262808815), ('average_policy_step_size', 1.0), ('explained_variance', 0.8481620279543133)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:136.38835058866047\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:295300 episode:583 R:145.031470118545\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 51.76904), ('average_entropy', 11.184159), ('average_kl', 0.0062988603262808815), ('average_policy_step_size', 1.0), ('explained_variance', 0.8481620279543133)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:83.10419763506322\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:295800 episode:584 R:125.49229735928274\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 52.74623), ('average_entropy', 11.184159), ('average_kl', 0.0062988603262808815), ('average_policy_step_size', 1.0), ('explained_variance', 0.8481620279543133)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:296300 episode:585 R:134.39261461831563\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 51.959465), ('average_entropy', 11.184159), ('average_kl', 0.0062988603262808815), ('average_policy_step_size', 1.0), ('explained_variance', 0.8481620279543133)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:146.0260337537019\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:296800 episode:586 R:127.85024725582373\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 49.92663), ('average_entropy', 11.184159), ('average_kl', 0.0062988603262808815), ('average_policy_step_size', 1.0), ('explained_variance', 0.8481620279543133)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:117.99674166396544\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:297300 episode:587 R:137.64203064649612\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 49.80373), ('average_entropy', 11.184159), ('average_kl', 0.0062988603262808815), ('average_policy_step_size', 1.0), ('explained_variance', 0.8481620279543133)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:297800 episode:588 R:140.19957954694644\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 52.272583), ('average_entropy', 11.184159), ('average_kl', 0.0062988603262808815), ('average_policy_step_size', 1.0), ('explained_variance', 0.8481620279543133)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:143.76865457482816\n",
      "INFO:pfrl.agents.trpo:Line search iteration: 0 step size: 1.0\n",
      "INFO:pfrl.agents.trpo:Surrogate objective improve: 0.03688821106334217\n",
      "INFO:pfrl.agents.trpo:KL divergence: 0.006541944574564695\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:298300 episode:589 R:141.23257113105393\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 52.745396), ('average_entropy', 11.184159), ('average_kl', 0.006302980398285692), ('average_policy_step_size', 1.0), ('explained_variance', 0.7917700983222498)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:298800 episode:590 R:143.3747568402509\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 53.179592), ('average_entropy', 11.186391), ('average_kl', 0.006302980398285692), ('average_policy_step_size', 1.0), ('explained_variance', 0.7917700983222498)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:135.00658549602772\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:299300 episode:591 R:148.28893414330528\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 54.009705), ('average_entropy', 11.188623), ('average_kl', 0.006302980398285692), ('average_policy_step_size', 1.0), ('explained_variance', 0.7917700983222498)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:147.37897328681603\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:299800 episode:592 R:143.88544202759581\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 53.73465), ('average_entropy', 11.188623), ('average_kl', 0.006302980398285692), ('average_policy_step_size', 1.0), ('explained_variance', 0.7917700983222498)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:300300 episode:593 R:128.23815362427794\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 52.80443), ('average_entropy', 11.188623), ('average_kl', 0.006302980398285692), ('average_policy_step_size', 1.0), ('explained_variance', 0.7917700983222498)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:139.54375284526594\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:300800 episode:594 R:143.40060362151678\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 53.385254), ('average_entropy', 11.188623), ('average_kl', 0.006302980398285692), ('average_policy_step_size', 1.0), ('explained_variance', 0.7917700983222498)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:161.0615646470471\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:301300 episode:595 R:141.54625922954295\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 53.53697), ('average_entropy', 11.188623), ('average_kl', 0.006302980398285692), ('average_policy_step_size', 1.0), ('explained_variance', 0.7917700983222498)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:301800 episode:596 R:168.71870121354988\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 53.620564), ('average_entropy', 11.188623), ('average_kl', 0.006302980398285692), ('average_policy_step_size', 1.0), ('explained_variance', 0.7917700983222498)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:162.66048673590214\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:302300 episode:597 R:126.00749707668368\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 54.401573), ('average_entropy', 11.188623), ('average_kl', 0.006302980398285692), ('average_policy_step_size', 1.0), ('explained_variance', 0.7917700983222498)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:302800 episode:598 R:143.73000082798637\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 53.70218), ('average_entropy', 11.188623), ('average_kl', 0.006302980398285692), ('average_policy_step_size', 1.0), ('explained_variance', 0.7917700983222498)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:151.93229916066784\n",
      "INFO:pfrl.agents.trpo:Line search iteration: 0 step size: 1.0\n",
      "INFO:pfrl.agents.trpo:Surrogate objective improve: 0.02990817949466873\n",
      "INFO:pfrl.agents.trpo:KL divergence: 0.006485197227448225\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:303300 episode:599 R:139.09149900955356\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 53.522865), ('average_entropy', 11.188623), ('average_kl', 0.006306017345438401), ('average_policy_step_size', 1.0), ('explained_variance', 0.5955015601737137)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:118.32580478829347\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:303800 episode:600 R:140.54972408236765\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 53.222454), ('average_entropy', 11.1765175), ('average_kl', 0.006306017345438401), ('average_policy_step_size', 1.0), ('explained_variance', 0.5955015601737137)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:304300 episode:601 R:149.37888025185921\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 52.261955), ('average_entropy', 11.164412), ('average_kl', 0.006306017345438401), ('average_policy_step_size', 1.0), ('explained_variance', 0.5955015601737137)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:192.4692791486627\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:304800 episode:602 R:144.23587633229366\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 53.23564), ('average_entropy', 11.164412), ('average_kl', 0.006306017345438401), ('average_policy_step_size', 1.0), ('explained_variance', 0.5955015601737137)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:150.66329827435865\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:305300 episode:603 R:124.0289941710121\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 51.956123), ('average_entropy', 11.164412), ('average_kl', 0.006306017345438401), ('average_policy_step_size', 1.0), ('explained_variance', 0.5955015601737137)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:305800 episode:604 R:117.69550469285284\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 46.99947), ('average_entropy', 11.164412), ('average_kl', 0.006306017345438401), ('average_policy_step_size', 1.0), ('explained_variance', 0.5955015601737137)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:137.15459668857136\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:306300 episode:605 R:144.5265438135002\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 49.7295), ('average_entropy', 11.164412), ('average_kl', 0.006306017345438401), ('average_policy_step_size', 1.0), ('explained_variance', 0.5955015601737137)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:306800 episode:606 R:140.02213940921132\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 55.181805), ('average_entropy', 11.164412), ('average_kl', 0.006306017345438401), ('average_policy_step_size', 1.0), ('explained_variance', 0.5955015601737137)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:111.45051742168384\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:307300 episode:607 R:137.97847896120598\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 52.04358), ('average_entropy', 11.164412), ('average_kl', 0.006306017345438401), ('average_policy_step_size', 1.0), ('explained_variance', 0.5955015601737137)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:90.98215668664612\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:307800 episode:608 R:143.69792364277345\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 50.598774), ('average_entropy', 11.164412), ('average_kl', 0.006306017345438401), ('average_policy_step_size', 1.0), ('explained_variance', 0.5955015601737137)]\n",
      "INFO:pfrl.agents.trpo:Line search iteration: 0 step size: 1.0\n",
      "INFO:pfrl.agents.trpo:Surrogate objective improve: 0.0437557700824982\n",
      "INFO:pfrl.agents.trpo:KL divergence: 0.005846266634762287\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:308300 episode:609 R:117.34359024200458\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 47.688858), ('average_entropy', 11.164412), ('average_kl', 0.006298480448542071), ('average_policy_step_size', 1.0), ('explained_variance', 0.9023141799944299)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:154.72805592378995\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:308800 episode:610 R:132.69657882359556\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 46.872547), ('average_entropy', 11.159048), ('average_kl', 0.006298480448542071), ('average_policy_step_size', 1.0), ('explained_variance', 0.9023141799944299)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:129.70433660211557\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:309300 episode:611 R:135.3891286103358\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 52.234688), ('average_entropy', 11.153686), ('average_kl', 0.006298480448542071), ('average_policy_step_size', 1.0), ('explained_variance', 0.9023141799944299)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:309800 episode:612 R:86.46400411776571\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 53.011227), ('average_entropy', 11.153686), ('average_kl', 0.006298480448542071), ('average_policy_step_size', 1.0), ('explained_variance', 0.9023141799944299)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:83.63765607868555\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:310300 episode:613 R:138.1042620521138\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 52.432632), ('average_entropy', 11.153686), ('average_kl', 0.006298480448542071), ('average_policy_step_size', 1.0), ('explained_variance', 0.9023141799944299)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:310800 episode:614 R:107.2227661057404\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 50.0999), ('average_entropy', 11.153686), ('average_kl', 0.006298480448542071), ('average_policy_step_size', 1.0), ('explained_variance', 0.9023141799944299)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:135.54916010956754\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:311300 episode:615 R:156.07067322950368\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 51.360844), ('average_entropy', 11.153686), ('average_kl', 0.006298480448542071), ('average_policy_step_size', 1.0), ('explained_variance', 0.9023141799944299)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:188.79708588604458\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:311800 episode:616 R:161.54480403638848\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 53.699287), ('average_entropy', 11.153686), ('average_kl', 0.006298480448542071), ('average_policy_step_size', 1.0), ('explained_variance', 0.9023141799944299)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:312300 episode:617 R:162.52134953649633\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 54.032673), ('average_entropy', 11.153686), ('average_kl', 0.006298480448542071), ('average_policy_step_size', 1.0), ('explained_variance', 0.9023141799944299)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:129.72074002515393\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:312800 episode:618 R:75.16953801521404\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 53.381855), ('average_entropy', 11.153686), ('average_kl', 0.006298480448542071), ('average_policy_step_size', 1.0), ('explained_variance', 0.9023141799944299)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:133.20242134120036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pfrl.agents.trpo:Line search iteration: 0 step size: 1.0\n",
      "INFO:pfrl.agents.trpo:Surrogate objective improve: 0.029656778322532773\n",
      "INFO:pfrl.agents.trpo:KL divergence: 0.004275864455848932\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:313300 episode:619 R:142.85601314583536\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 51.87504), ('average_entropy', 11.153686), ('average_kl', 0.006265857609950246), ('average_policy_step_size', 1.0), ('explained_variance', 0.5372958911016726)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:313800 episode:620 R:76.60682699122579\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 48.732876), ('average_entropy', 11.154977), ('average_kl', 0.006265857609950246), ('average_policy_step_size', 1.0), ('explained_variance', 0.5372958911016726)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:125.95301140174507\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:314300 episode:621 R:151.28361750329708\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 50.133274), ('average_entropy', 11.156267), ('average_kl', 0.006265857609950246), ('average_policy_step_size', 1.0), ('explained_variance', 0.5372958911016726)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:314800 episode:622 R:141.50532801515584\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 51.94326), ('average_entropy', 11.156267), ('average_kl', 0.006265857609950246), ('average_policy_step_size', 1.0), ('explained_variance', 0.5372958911016726)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:130.22002897115615\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:315300 episode:623 R:89.91618749655184\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 40.43956), ('average_entropy', 11.156267), ('average_kl', 0.006265857609950246), ('average_policy_step_size', 1.0), ('explained_variance', 0.5372958911016726)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:130.18484207616987\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:315800 episode:624 R:85.48851916002056\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 38.408817), ('average_entropy', 11.156267), ('average_kl', 0.006265857609950246), ('average_policy_step_size', 1.0), ('explained_variance', 0.5372958911016726)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:316300 episode:625 R:149.40934848287299\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 45.350864), ('average_entropy', 11.156267), ('average_kl', 0.006265857609950246), ('average_policy_step_size', 1.0), ('explained_variance', 0.5372958911016726)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:138.4406037203034\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:316800 episode:626 R:82.46923781122375\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 43.403687), ('average_entropy', 11.156267), ('average_kl', 0.006265857609950246), ('average_policy_step_size', 1.0), ('explained_variance', 0.5372958911016726)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:147.23737765024944\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:317300 episode:627 R:144.00572562516473\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 43.34336), ('average_entropy', 11.156267), ('average_kl', 0.006265857609950246), ('average_policy_step_size', 1.0), ('explained_variance', 0.5372958911016726)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:317800 episode:628 R:171.50549099838793\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 50.290596), ('average_entropy', 11.156267), ('average_kl', 0.006265857609950246), ('average_policy_step_size', 1.0), ('explained_variance', 0.5372958911016726)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:128.06267059914478\n",
      "INFO:pfrl.agents.trpo:Line search iteration: 0 step size: 1.0\n",
      "INFO:pfrl.agents.trpo:Surrogate objective improve: 0.030165547024807893\n",
      "INFO:pfrl.agents.trpo:KL divergence: 0.006303951144218445\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:318300 episode:629 R:124.0118779848286\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 53.807003), ('average_entropy', 11.156267), ('average_kl', 0.006266462269224345), ('average_policy_step_size', 1.0), ('explained_variance', 0.8756834689278593)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:318800 episode:630 R:141.14133779830644\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 53.997715), ('average_entropy', 11.147508), ('average_kl', 0.006266462269224345), ('average_policy_step_size', 1.0), ('explained_variance', 0.8756834689278593)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:129.14715254154495\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:319300 episode:631 R:129.88599443109055\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 46.875744), ('average_entropy', 11.138747), ('average_kl', 0.006266462269224345), ('average_policy_step_size', 1.0), ('explained_variance', 0.8756834689278593)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:141.01312607248994\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:319800 episode:632 R:84.39359639799746\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 40.475983), ('average_entropy', 11.138747), ('average_kl', 0.006266462269224345), ('average_policy_step_size', 1.0), ('explained_variance', 0.8756834689278593)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:320300 episode:633 R:138.06853487589723\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 47.428696), ('average_entropy', 11.138747), ('average_kl', 0.006266462269224345), ('average_policy_step_size', 1.0), ('explained_variance', 0.8756834689278593)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:69.38592994349891\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:320800 episode:634 R:133.75812721614395\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 54.29388), ('average_entropy', 11.138747), ('average_kl', 0.006266462269224345), ('average_policy_step_size', 1.0), ('explained_variance', 0.8756834689278593)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:127.40930848183254\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:321300 episode:635 R:110.3135400353441\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 50.097824), ('average_entropy', 11.138747), ('average_kl', 0.006266462269224345), ('average_policy_step_size', 1.0), ('explained_variance', 0.8756834689278593)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:321800 episode:636 R:108.77961619361002\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 47.649864), ('average_entropy', 11.138747), ('average_kl', 0.006266462269224345), ('average_policy_step_size', 1.0), ('explained_variance', 0.8756834689278593)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:142.26494219292837\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:322300 episode:637 R:156.9859017888514\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 50.267), ('average_entropy', 11.138747), ('average_kl', 0.006266462269224345), ('average_policy_step_size', 1.0), ('explained_variance', 0.8756834689278593)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:322800 episode:638 R:158.2376273350518\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 51.412495), ('average_entropy', 11.138747), ('average_kl', 0.006266462269224345), ('average_policy_step_size', 1.0), ('explained_variance', 0.8756834689278593)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:98.79243151696978\n",
      "INFO:pfrl.agents.trpo:Line search iteration: 0 step size: 1.0\n",
      "INFO:pfrl.agents.trpo:Surrogate objective improve: 0.031533102825051174\n",
      "INFO:pfrl.agents.trpo:KL divergence: 0.006160613149404526\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:323300 episode:639 R:137.53702116183482\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 51.034687), ('average_entropy', 11.138747), ('average_kl', 0.00626480837672716), ('average_policy_step_size', 1.0), ('explained_variance', 0.8803200841280102)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:134.35267995190975\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:323800 episode:640 R:131.8889051260823\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 44.976852), ('average_entropy', 11.110886), ('average_kl', 0.00626480837672716), ('average_policy_step_size', 1.0), ('explained_variance', 0.8803200841280102)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:324300 episode:641 R:114.6312348123014\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 46.79344), ('average_entropy', 11.083025), ('average_kl', 0.00626480837672716), ('average_policy_step_size', 1.0), ('explained_variance', 0.8803200841280102)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:124.65920015939878\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:324800 episode:642 R:143.93790495716675\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 52.658733), ('average_entropy', 11.083025), ('average_kl', 0.00626480837672716), ('average_policy_step_size', 1.0), ('explained_variance', 0.8803200841280102)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:146.73202317001935\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:325300 episode:643 R:90.2755244786809\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 51.958916), ('average_entropy', 11.083025), ('average_kl', 0.00626480837672716), ('average_policy_step_size', 1.0), ('explained_variance', 0.8803200841280102)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:325800 episode:644 R:117.97334136873967\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 49.98683), ('average_entropy', 11.083025), ('average_kl', 0.00626480837672716), ('average_policy_step_size', 1.0), ('explained_variance', 0.8803200841280102)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:102.58219460886633\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:326300 episode:645 R:137.95418974631917\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 50.018154), ('average_entropy', 11.083025), ('average_kl', 0.00626480837672716), ('average_policy_step_size', 1.0), ('explained_variance', 0.8803200841280102)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:326800 episode:646 R:116.66648808736146\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 52.704136), ('average_entropy', 11.083025), ('average_kl', 0.00626480837672716), ('average_policy_step_size', 1.0), ('explained_variance', 0.8803200841280102)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:149.10979547210687\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:327300 episode:647 R:170.44694818989547\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 54.000565), ('average_entropy', 11.083025), ('average_kl', 0.00626480837672716), ('average_policy_step_size', 1.0), ('explained_variance', 0.8803200841280102)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:138.08309862984711\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:327800 episode:648 R:140.97222242961803\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 53.192055), ('average_entropy', 11.083025), ('average_kl', 0.00626480837672716), ('average_policy_step_size', 1.0), ('explained_variance', 0.8803200841280102)]\n",
      "INFO:pfrl.agents.trpo:Line search iteration: 0 step size: 1.0\n",
      "INFO:pfrl.agents.trpo:Surrogate objective improve: 0.03419701936218189\n",
      "INFO:pfrl.agents.trpo:KL divergence: 0.006265194620937109\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:328300 episode:649 R:120.97955342051557\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 50.63549), ('average_entropy', 11.083025), ('average_kl', 0.006264814318945775), ('average_policy_step_size', 1.0), ('explained_variance', 0.8491061042776469)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:138.59995463931818\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:328800 episode:650 R:130.98976389907304\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 49.341324), ('average_entropy', 11.0613165), ('average_kl', 0.006264814318945775), ('average_policy_step_size', 1.0), ('explained_variance', 0.8491061042776469)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:157.09350870266778\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:329300 episode:651 R:142.88312738332607\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 51.620834), ('average_entropy', 11.039607), ('average_kl', 0.006264814318945775), ('average_policy_step_size', 1.0), ('explained_variance', 0.8491061042776469)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:329800 episode:652 R:147.11546206129293\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 52.044205), ('average_entropy', 11.039607), ('average_kl', 0.006264814318945775), ('average_policy_step_size', 1.0), ('explained_variance', 0.8491061042776469)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:144.45557508683174\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:330300 episode:653 R:130.96258206569317\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 53.063007), ('average_entropy', 11.039607), ('average_kl', 0.006264814318945775), ('average_policy_step_size', 1.0), ('explained_variance', 0.8491061042776469)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:330800 episode:654 R:93.6781338582824\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 51.7439), ('average_entropy', 11.039607), ('average_kl', 0.006264814318945775), ('average_policy_step_size', 1.0), ('explained_variance', 0.8491061042776469)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:126.61370798506506\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:331300 episode:655 R:136.18993426646148\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 51.693184), ('average_entropy', 11.039607), ('average_kl', 0.006264814318945775), ('average_policy_step_size', 1.0), ('explained_variance', 0.8491061042776469)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:139.99463298487186\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:331800 episode:656 R:149.68034738378114\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 54.01373), ('average_entropy', 11.039607), ('average_kl', 0.006264814318945775), ('average_policy_step_size', 1.0), ('explained_variance', 0.8491061042776469)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:332300 episode:657 R:132.64522265703664\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 50.89795), ('average_entropy', 11.039607), ('average_kl', 0.006264814318945775), ('average_policy_step_size', 1.0), ('explained_variance', 0.8491061042776469)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:149.8858349348007\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:332800 episode:658 R:148.92813230306825\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 52.295036), ('average_entropy', 11.039607), ('average_kl', 0.006264814318945775), ('average_policy_step_size', 1.0), ('explained_variance', 0.8491061042776469)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:135.03587856144904\n",
      "INFO:pfrl.agents.trpo:Line search iteration: 0 step size: 1.0\n",
      "INFO:pfrl.agents.trpo:Surrogate objective improve: 0.031895615149551304\n",
      "INFO:pfrl.agents.trpo:KL divergence: 0.006074280943721533\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:333300 episode:659 R:156.47048369789627\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 55.09387), ('average_entropy', 11.039607), ('average_kl', 0.006261927449624195), ('average_policy_step_size', 1.0), ('explained_variance', 0.8350096042651504)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:333800 episode:660 R:96.30363715013767\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 49.393658), ('average_entropy', 11.036851), ('average_kl', 0.006261927449624195), ('average_policy_step_size', 1.0), ('explained_variance', 0.8350096042651504)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:105.02846582961456\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:334300 episode:661 R:142.3296749986021\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 47.93496), ('average_entropy', 11.034094), ('average_kl', 0.006261927449624195), ('average_policy_step_size', 1.0), ('explained_variance', 0.8350096042651504)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:334800 episode:662 R:125.12391515975729\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 49.67334), ('average_entropy', 11.034094), ('average_kl', 0.006261927449624195), ('average_policy_step_size', 1.0), ('explained_variance', 0.8350096042651504)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:138.1601354891259\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:335300 episode:663 R:151.12912499821076\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 49.179737), ('average_entropy', 11.034094), ('average_kl', 0.006261927449624195), ('average_policy_step_size', 1.0), ('explained_variance', 0.8350096042651504)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:138.45043633174407\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:335800 episode:664 R:142.25472407539132\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 52.95961), ('average_entropy', 11.034094), ('average_kl', 0.006261927449624195), ('average_policy_step_size', 1.0), ('explained_variance', 0.8350096042651504)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:336300 episode:665 R:145.8915353307236\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 53.202744), ('average_entropy', 11.034094), ('average_kl', 0.006261927449624195), ('average_policy_step_size', 1.0), ('explained_variance', 0.8350096042651504)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:140.28649927611576\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:336800 episode:666 R:141.66225475538542\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 50.87968), ('average_entropy', 11.034094), ('average_kl', 0.006261927449624195), ('average_policy_step_size', 1.0), ('explained_variance', 0.8350096042651504)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:135.38683474107802\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:337300 episode:667 R:113.71556511537833\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 50.16521), ('average_entropy', 11.034094), ('average_kl', 0.006261927449624195), ('average_policy_step_size', 1.0), ('explained_variance', 0.8350096042651504)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:337800 episode:668 R:188.86087763755012\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 52.84632), ('average_entropy', 11.034094), ('average_kl', 0.006261927449624195), ('average_policy_step_size', 1.0), ('explained_variance', 0.8350096042651504)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:149.37892983547783\n",
      "INFO:pfrl.agents.trpo:Line search iteration: 0 step size: 1.0\n",
      "INFO:pfrl.agents.trpo:Surrogate objective improve: 0.03433986645904952\n",
      "INFO:pfrl.agents.trpo:KL divergence: 0.006598736625164747\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:338300 episode:669 R:132.9450805813038\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 55.456142), ('average_entropy', 11.034094), ('average_kl', 0.006266954452244204), ('average_policy_step_size', 1.0), ('explained_variance', 0.868948426530408)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:338800 episode:670 R:134.32992631962978\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 54.825836), ('average_entropy', 11.032693), ('average_kl', 0.006266954452244204), ('average_policy_step_size', 1.0), ('explained_variance', 0.868948426530408)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:150.40094292016582\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:339300 episode:671 R:148.8654739451249\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 54.698845), ('average_entropy', 11.031291), ('average_kl', 0.006266954452244204), ('average_policy_step_size', 1.0), ('explained_variance', 0.868948426530408)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:112.53347159579369\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:339800 episode:672 R:147.32222508668752\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 55.312298), ('average_entropy', 11.031291), ('average_kl', 0.006266954452244204), ('average_policy_step_size', 1.0), ('explained_variance', 0.868948426530408)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:340300 episode:673 R:150.42047273453312\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 52.59217), ('average_entropy', 11.031291), ('average_kl', 0.006266954452244204), ('average_policy_step_size', 1.0), ('explained_variance', 0.868948426530408)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:207.06279099377477\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pfrl.experiments.train_agent:The best score is updated 196.78586875202896 -> 207.06279099377477\n",
      "INFO:pfrl.experiments.train_agent:Saved the agent to results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f\\best\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:340800 episode:674 R:124.34142887995202\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 49.631092), ('average_entropy', 11.031291), ('average_kl', 0.006266954452244204), ('average_policy_step_size', 1.0), ('explained_variance', 0.868948426530408)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:135.1601091432284\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:341300 episode:675 R:76.69810499227839\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 43.882), ('average_entropy', 11.031291), ('average_kl', 0.006266954452244204), ('average_policy_step_size', 1.0), ('explained_variance', 0.868948426530408)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:341800 episode:676 R:140.26105986706645\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 46.68601), ('average_entropy', 11.031291), ('average_kl', 0.006266954452244204), ('average_policy_step_size', 1.0), ('explained_variance', 0.868948426530408)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:127.40643917870317\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:342300 episode:677 R:143.84680333221922\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 53.762047), ('average_entropy', 11.031291), ('average_kl', 0.006266954452244204), ('average_policy_step_size', 1.0), ('explained_variance', 0.868948426530408)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:342800 episode:678 R:151.86662139196642\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 52.1045), ('average_entropy', 11.031291), ('average_kl', 0.006266954452244204), ('average_policy_step_size', 1.0), ('explained_variance', 0.868948426530408)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:135.19391828094794\n",
      "INFO:pfrl.agents.trpo:Line search iteration: 0 step size: 1.0\n",
      "INFO:pfrl.agents.trpo:Surrogate objective improve: 0.03960912821639795\n",
      "INFO:pfrl.agents.trpo:KL divergence: 0.004844208247959614\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:343300 episode:679 R:152.08064437922226\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 53.068306), ('average_entropy', 11.031291), ('average_kl', 0.006246031713945901), ('average_policy_step_size', 1.0), ('explained_variance', 0.9117874484950432)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:146.12625669602505\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:343800 episode:680 R:137.0204248089139\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 54.070587), ('average_entropy', 11.022054), ('average_kl', 0.006246031713945901), ('average_policy_step_size', 1.0), ('explained_variance', 0.9117874484950432)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:344300 episode:681 R:124.926262369312\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 52.03487), ('average_entropy', 11.012816), ('average_kl', 0.006246031713945901), ('average_policy_step_size', 1.0), ('explained_variance', 0.9117874484950432)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:177.91753112888162\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:344800 episode:682 R:140.59763722238858\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 52.058846), ('average_entropy', 11.012816), ('average_kl', 0.006246031713945901), ('average_policy_step_size', 1.0), ('explained_variance', 0.9117874484950432)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:137.815313539856\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:345300 episode:683 R:108.93520769640607\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 52.02843), ('average_entropy', 11.012816), ('average_kl', 0.006246031713945901), ('average_policy_step_size', 1.0), ('explained_variance', 0.9117874484950432)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:345800 episode:684 R:138.57606946776693\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 51.334053), ('average_entropy', 11.012816), ('average_kl', 0.006246031713945901), ('average_policy_step_size', 1.0), ('explained_variance', 0.9117874484950432)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:149.3236362729116\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:346300 episode:685 R:124.85281310880912\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 49.625553), ('average_entropy', 11.012816), ('average_kl', 0.006246031713945901), ('average_policy_step_size', 1.0), ('explained_variance', 0.9117874484950432)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:346800 episode:686 R:145.95235044653228\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 50.689636), ('average_entropy', 11.012816), ('average_kl', 0.006246031713945901), ('average_policy_step_size', 1.0), ('explained_variance', 0.9117874484950432)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:135.3969594289456\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:347300 episode:687 R:139.64205689459106\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 53.768013), ('average_entropy', 11.012816), ('average_kl', 0.006246031713945901), ('average_policy_step_size', 1.0), ('explained_variance', 0.9117874484950432)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:145.25878980933143\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:347800 episode:688 R:144.7226652970687\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 53.742577), ('average_entropy', 11.012816), ('average_kl', 0.006246031713945901), ('average_policy_step_size', 1.0), ('explained_variance', 0.9117874484950432)]\n",
      "INFO:pfrl.agents.trpo:Line search iteration: 0 step size: 1.0\n",
      "INFO:pfrl.agents.trpo:Surrogate objective improve: 0.02924514915503096\n",
      "INFO:pfrl.agents.trpo:KL divergence: 0.005799243692308664\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:348300 episode:689 R:134.15703145816315\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 54.398235), ('average_entropy', 11.012816), ('average_kl', 0.0062395565252265205), ('average_policy_step_size', 1.0), ('explained_variance', 0.9060922571602279)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:113.09929696188102\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:348800 episode:690 R:127.57895551533333\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 55.167267), ('average_entropy', 11.010127), ('average_kl', 0.0062395565252265205), ('average_policy_step_size', 1.0), ('explained_variance', 0.9060922571602279)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:155.255841399517\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:349300 episode:691 R:139.2178503476178\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 53.37068), ('average_entropy', 11.007437), ('average_kl', 0.0062395565252265205), ('average_policy_step_size', 1.0), ('explained_variance', 0.9060922571602279)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:349800 episode:692 R:137.18226363591216\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 51.90579), ('average_entropy', 11.007437), ('average_kl', 0.0062395565252265205), ('average_policy_step_size', 1.0), ('explained_variance', 0.9060922571602279)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:119.02519444070195\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:350300 episode:693 R:113.38548981524839\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 51.821167), ('average_entropy', 11.007437), ('average_kl', 0.0062395565252265205), ('average_policy_step_size', 1.0), ('explained_variance', 0.9060922571602279)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:350800 episode:694 R:132.45929855890674\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 49.95378), ('average_entropy', 11.007437), ('average_kl', 0.0062395565252265205), ('average_policy_step_size', 1.0), ('explained_variance', 0.9060922571602279)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:150.4095616782655\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:351300 episode:695 R:164.72359774073558\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 53.040188), ('average_entropy', 11.007437), ('average_kl', 0.0062395565252265205), ('average_policy_step_size', 1.0), ('explained_variance', 0.9060922571602279)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:132.2994197976832\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:351800 episode:696 R:137.61639181183918\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 52.569126), ('average_entropy', 11.007437), ('average_kl', 0.0062395565252265205), ('average_policy_step_size', 1.0), ('explained_variance', 0.9060922571602279)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:352300 episode:697 R:147.2444922115484\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 51.307503), ('average_entropy', 11.007437), ('average_kl', 0.0062395565252265205), ('average_policy_step_size', 1.0), ('explained_variance', 0.9060922571602279)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:151.26113854206835\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:352800 episode:698 R:140.0492647048048\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 52.92259), ('average_entropy', 11.007437), ('average_kl', 0.0062395565252265205), ('average_policy_step_size', 1.0), ('explained_variance', 0.9060922571602279)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:144.785180813837\n",
      "INFO:pfrl.agents.trpo:Line search iteration: 0 step size: 1.0\n",
      "INFO:pfrl.agents.trpo:Surrogate objective improve: 0.032912623340962455\n",
      "INFO:pfrl.agents.trpo:KL divergence: 0.006314562633633614\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:353300 episode:699 R:134.72138056029362\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 51.774548), ('average_entropy', 11.007437), ('average_kl', 0.006240628041060907), ('average_policy_step_size', 1.0), ('explained_variance', 0.7760747555858157)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:353800 episode:700 R:136.18580452368883\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 51.2461), ('average_entropy', 11.000791), ('average_kl', 0.006240628041060907), ('average_policy_step_size', 1.0), ('explained_variance', 0.7760747555858157)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:89.84438105953359\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:354300 episode:701 R:150.1611059090107\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 51.06329), ('average_entropy', 10.994145), ('average_kl', 0.006240628041060907), ('average_policy_step_size', 1.0), ('explained_variance', 0.7760747555858157)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:354800 episode:702 R:143.0967355911872\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 53.48306), ('average_entropy', 10.994145), ('average_kl', 0.006240628041060907), ('average_policy_step_size', 1.0), ('explained_variance', 0.7760747555858157)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:113.39895267370076\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:355300 episode:703 R:125.18621878279787\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 55.31778), ('average_entropy', 10.994145), ('average_kl', 0.006240628041060907), ('average_policy_step_size', 1.0), ('explained_variance', 0.7760747555858157)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:151.2473016288158\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:355800 episode:704 R:144.12206633723216\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 54.509483), ('average_entropy', 10.994145), ('average_kl', 0.006240628041060907), ('average_policy_step_size', 1.0), ('explained_variance', 0.7760747555858157)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:356300 episode:705 R:148.0449720520124\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 55.528233), ('average_entropy', 10.994145), ('average_kl', 0.006240628041060907), ('average_policy_step_size', 1.0), ('explained_variance', 0.7760747555858157)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:130.89934869387878\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:356800 episode:706 R:160.55597135000596\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 55.835484), ('average_entropy', 10.994145), ('average_kl', 0.006240628041060907), ('average_policy_step_size', 1.0), ('explained_variance', 0.7760747555858157)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:206.4262125716271\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:357300 episode:707 R:133.30165208272814\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 53.714123), ('average_entropy', 10.994145), ('average_kl', 0.006240628041060907), ('average_policy_step_size', 1.0), ('explained_variance', 0.7760747555858157)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:357800 episode:708 R:143.72504268179523\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 53.58731), ('average_entropy', 10.994145), ('average_kl', 0.006240628041060907), ('average_policy_step_size', 1.0), ('explained_variance', 0.7760747555858157)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:152.36142316741456\n",
      "INFO:pfrl.agents.trpo:Line search iteration: 0 step size: 1.0\n",
      "INFO:pfrl.agents.trpo:Surrogate objective improve: 0.03186843916773796\n",
      "INFO:pfrl.agents.trpo:KL divergence: 0.006644765846431255\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:358300 episode:709 R:151.48960306746233\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 53.542126), ('average_entropy', 10.994145), ('average_kl', 0.006246320122826687), ('average_policy_step_size', 1.0), ('explained_variance', 0.8222206411294609)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:358800 episode:710 R:146.2308387510108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 54.475643), ('average_entropy', 10.972481), ('average_kl', 0.006246320122826687), ('average_policy_step_size', 1.0), ('explained_variance', 0.8222206411294609)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:160.3900580014953\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:359300 episode:711 R:145.65742227531683\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 55.182518), ('average_entropy', 10.950815), ('average_kl', 0.006246320122826687), ('average_policy_step_size', 1.0), ('explained_variance', 0.8222206411294609)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:143.52342265506505\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:359800 episode:712 R:131.37557437955346\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 53.567593), ('average_entropy', 10.950815), ('average_kl', 0.006246320122826687), ('average_policy_step_size', 1.0), ('explained_variance', 0.8222206411294609)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:360300 episode:713 R:132.52224551170653\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 52.61627), ('average_entropy', 10.950815), ('average_kl', 0.006246320122826687), ('average_policy_step_size', 1.0), ('explained_variance', 0.8222206411294609)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:149.11620628686032\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:360800 episode:714 R:146.1073395582296\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 53.237465), ('average_entropy', 10.950815), ('average_kl', 0.006246320122826687), ('average_policy_step_size', 1.0), ('explained_variance', 0.8222206411294609)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:154.11384040392485\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:361300 episode:715 R:148.32065050952974\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 55.42479), ('average_entropy', 10.950815), ('average_kl', 0.006246320122826687), ('average_policy_step_size', 1.0), ('explained_variance', 0.8222206411294609)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:361800 episode:716 R:123.16804562126958\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 53.721954), ('average_entropy', 10.950815), ('average_kl', 0.006246320122826687), ('average_policy_step_size', 1.0), ('explained_variance', 0.8222206411294609)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:138.69162736194536\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:362300 episode:717 R:144.10110403680514\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 51.683548), ('average_entropy', 10.950815), ('average_kl', 0.006246320122826687), ('average_policy_step_size', 1.0), ('explained_variance', 0.8222206411294609)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:362800 episode:718 R:141.35439345124595\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 52.08205), ('average_entropy', 10.950815), ('average_kl', 0.006246320122826687), ('average_policy_step_size', 1.0), ('explained_variance', 0.8222206411294609)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:120.6226686868657\n",
      "INFO:pfrl.agents.trpo:Line search iteration: 0 step size: 1.0\n",
      "INFO:pfrl.agents.trpo:Surrogate objective improve: 0.030624543969679507\n",
      "INFO:pfrl.agents.trpo:KL divergence: 0.0063543180003762245\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:363300 episode:719 R:143.01223355027082\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 53.366135), ('average_entropy', 10.950815), ('average_kl', 0.006247820093348209), ('average_policy_step_size', 1.0), ('explained_variance', 0.8595337688063371)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:121.19583656414449\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:363800 episode:720 R:155.83256066721847\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 53.916763), ('average_entropy', 10.95433), ('average_kl', 0.006247820093348209), ('average_policy_step_size', 1.0), ('explained_variance', 0.8595337688063371)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:364300 episode:721 R:120.88736079961794\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 53.1595), ('average_entropy', 10.957845), ('average_kl', 0.006247820093348209), ('average_policy_step_size', 1.0), ('explained_variance', 0.8595337688063371)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:145.39122088743082\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:364800 episode:722 R:144.93742686961195\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 53.415672), ('average_entropy', 10.957845), ('average_kl', 0.006247820093348209), ('average_policy_step_size', 1.0), ('explained_variance', 0.8595337688063371)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:138.9772584982805\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:365300 episode:723 R:115.74202079180608\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 50.592022), ('average_entropy', 10.957845), ('average_kl', 0.006247820093348209), ('average_policy_step_size', 1.0), ('explained_variance', 0.8595337688063371)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:365800 episode:724 R:138.5845066098565\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 50.7194), ('average_entropy', 10.957845), ('average_kl', 0.006247820093348209), ('average_policy_step_size', 1.0), ('explained_variance', 0.8595337688063371)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:151.02543977689515\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:366300 episode:725 R:139.05816412791887\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 52.557426), ('average_entropy', 10.957845), ('average_kl', 0.006247820093348209), ('average_policy_step_size', 1.0), ('explained_variance', 0.8595337688063371)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:366800 episode:726 R:113.83750070359154\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 51.211437), ('average_entropy', 10.957845), ('average_kl', 0.006247820093348209), ('average_policy_step_size', 1.0), ('explained_variance', 0.8595337688063371)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:144.48136320390543\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:367300 episode:727 R:180.72612112922369\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 53.39515), ('average_entropy', 10.957845), ('average_kl', 0.006247820093348209), ('average_policy_step_size', 1.0), ('explained_variance', 0.8595337688063371)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:140.44747576860888\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:367800 episode:728 R:140.40645057733957\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 53.852978), ('average_entropy', 10.957845), ('average_kl', 0.006247820093348209), ('average_policy_step_size', 1.0), ('explained_variance', 0.8595337688063371)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pfrl.agents.trpo:Line search iteration: 0 step size: 1.0\n",
      "INFO:pfrl.agents.trpo:Surrogate objective improve: 0.03446093856473453\n",
      "INFO:pfrl.agents.trpo:KL divergence: 0.005964208859950304\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:368300 episode:729 R:153.17782990965\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 52.970287), ('average_entropy', 10.957845), ('average_kl', 0.006243935007959196), ('average_policy_step_size', 1.0), ('explained_variance', 0.7892975030562925)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:154.31091547577654\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:368800 episode:730 R:47.12679263194983\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 36.486176), ('average_entropy', 10.952879), ('average_kl', 0.006243935007959196), ('average_policy_step_size', 1.0), ('explained_variance', 0.7892975030562925)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:151.79882383703276\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:369300 episode:731 R:149.02941368472497\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 36.398663), ('average_entropy', 10.947912), ('average_kl', 0.006243935007959196), ('average_policy_step_size', 1.0), ('explained_variance', 0.7892975030562925)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:369800 episode:732 R:129.83896167668757\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 54.828125), ('average_entropy', 10.947912), ('average_kl', 0.006243935007959196), ('average_policy_step_size', 1.0), ('explained_variance', 0.7892975030562925)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:124.64715498529804\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:370300 episode:733 R:144.2081391217142\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 54.603256), ('average_entropy', 10.947912), ('average_kl', 0.006243935007959196), ('average_policy_step_size', 1.0), ('explained_variance', 0.7892975030562925)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:370800 episode:734 R:143.87707349423658\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 53.56985), ('average_entropy', 10.947912), ('average_kl', 0.006243935007959196), ('average_policy_step_size', 1.0), ('explained_variance', 0.7892975030562925)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:133.29578154669628\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:371300 episode:735 R:131.95542196779667\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 52.241623), ('average_entropy', 10.947912), ('average_kl', 0.006243935007959196), ('average_policy_step_size', 1.0), ('explained_variance', 0.7892975030562925)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:136.2308542909982\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:371800 episode:736 R:144.91750645308204\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 52.04966), ('average_entropy', 10.947912), ('average_kl', 0.006243935007959196), ('average_policy_step_size', 1.0), ('explained_variance', 0.7892975030562925)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:372300 episode:737 R:137.940803202092\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 54.088673), ('average_entropy', 10.947912), ('average_kl', 0.006243935007959196), ('average_policy_step_size', 1.0), ('explained_variance', 0.7892975030562925)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:141.97548291755837\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:372800 episode:738 R:138.78283800592774\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 54.336647), ('average_entropy', 10.947912), ('average_kl', 0.006243935007959196), ('average_policy_step_size', 1.0), ('explained_variance', 0.7892975030562925)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:148.840216870505\n",
      "INFO:pfrl.agents.trpo:Line search iteration: 0 step size: 1.0\n",
      "INFO:pfrl.agents.trpo:Surrogate objective improve: 0.04268669133307412\n",
      "INFO:pfrl.agents.trpo:KL divergence: 0.005837647244334221\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:373300 episode:739 R:64.92883565397983\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 35.71696), ('average_entropy', 10.947912), ('average_kl', 0.006238444632775075), ('average_policy_step_size', 1.0), ('explained_variance', 0.9585789605165306)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:373800 episode:740 R:146.43712793246448\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 35.696384), ('average_entropy', 10.949594), ('average_kl', 0.006238444632775075), ('average_policy_step_size', 1.0), ('explained_variance', 0.9585789605165306)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:144.68637395300905\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:374300 episode:741 R:141.88970576612175\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 54.798378), ('average_entropy', 10.951275), ('average_kl', 0.006238444632775075), ('average_policy_step_size', 1.0), ('explained_variance', 0.9585789605165306)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:374800 episode:742 R:172.3198444720117\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 54.377186), ('average_entropy', 10.951275), ('average_kl', 0.006238444632775075), ('average_policy_step_size', 1.0), ('explained_variance', 0.9585789605165306)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:130.70573229546267\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:375300 episode:743 R:150.6870606247357\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 52.133953), ('average_entropy', 10.951275), ('average_kl', 0.006238444632775075), ('average_policy_step_size', 1.0), ('explained_variance', 0.9585789605165306)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:144.93449197803434\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:375800 episode:744 R:108.16540715228402\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 50.390194), ('average_entropy', 10.951275), ('average_kl', 0.006238444632775075), ('average_policy_step_size', 1.0), ('explained_variance', 0.9585789605165306)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:376300 episode:745 R:139.9702966093968\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 49.185596), ('average_entropy', 10.951275), ('average_kl', 0.006238444632775075), ('average_policy_step_size', 1.0), ('explained_variance', 0.9585789605165306)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:145.08378219907914\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:376800 episode:746 R:144.52634059627923\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 50.90036), ('average_entropy', 10.951275), ('average_kl', 0.006238444632775075), ('average_policy_step_size', 1.0), ('explained_variance', 0.9585789605165306)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:133.3931413614093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:377300 episode:747 R:161.63015008438617\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 52.728912), ('average_entropy', 10.951275), ('average_kl', 0.006238444632775075), ('average_policy_step_size', 1.0), ('explained_variance', 0.9585789605165306)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:377800 episode:748 R:136.64267630368482\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 54.14512), ('average_entropy', 10.951275), ('average_kl', 0.006238444632775075), ('average_policy_step_size', 1.0), ('explained_variance', 0.9585789605165306)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:156.79070156377844\n",
      "INFO:pfrl.agents.trpo:Line search iteration: 0 step size: 1.0\n",
      "INFO:pfrl.agents.trpo:Surrogate objective improve: 0.031230800683260895\n",
      "INFO:pfrl.agents.trpo:KL divergence: 0.006537924986332655\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:378300 episode:749 R:150.24309983766796\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 55.345398), ('average_entropy', 10.951275), ('average_kl', 0.006242437704155842), ('average_policy_step_size', 1.0), ('explained_variance', 0.7166697232935588)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:378800 episode:750 R:149.3388347525081\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 55.22551), ('average_entropy', 10.950452), ('average_kl', 0.006242437704155842), ('average_policy_step_size', 1.0), ('explained_variance', 0.7166697232935588)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:140.53300555415908\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:379300 episode:751 R:146.48611015781574\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 56.105656), ('average_entropy', 10.94963), ('average_kl', 0.006242437704155842), ('average_policy_step_size', 1.0), ('explained_variance', 0.7166697232935588)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:143.92820736586947\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:379800 episode:752 R:140.73305415289508\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 55.87954), ('average_entropy', 10.94963), ('average_kl', 0.006242437704155842), ('average_policy_step_size', 1.0), ('explained_variance', 0.7166697232935588)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:380300 episode:753 R:114.74747839401904\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 52.90498), ('average_entropy', 10.94963), ('average_kl', 0.006242437704155842), ('average_policy_step_size', 1.0), ('explained_variance', 0.7166697232935588)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:136.9204437971368\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:380800 episode:754 R:146.1613269330561\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 53.032383), ('average_entropy', 10.94963), ('average_kl', 0.006242437704155842), ('average_policy_step_size', 1.0), ('explained_variance', 0.7166697232935588)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:147.4801745742641\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:381300 episode:755 R:118.39296394490955\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 52.761074), ('average_entropy', 10.94963), ('average_kl', 0.006242437704155842), ('average_policy_step_size', 1.0), ('explained_variance', 0.7166697232935588)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:381800 episode:756 R:149.4333007152548\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 52.45179), ('average_entropy', 10.94963), ('average_kl', 0.006242437704155842), ('average_policy_step_size', 1.0), ('explained_variance', 0.7166697232935588)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:149.73891714910522\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:382300 episode:757 R:131.79870372911856\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 53.376194), ('average_entropy', 10.94963), ('average_kl', 0.006242437704155842), ('average_policy_step_size', 1.0), ('explained_variance', 0.7166697232935588)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:382800 episode:758 R:150.6633416019002\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 53.182835), ('average_entropy', 10.94963), ('average_kl', 0.006242437704155842), ('average_policy_step_size', 1.0), ('explained_variance', 0.7166697232935588)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:135.24573418060768\n",
      "INFO:pfrl.agents.trpo:Line search iteration: 0 step size: 1.0\n",
      "INFO:pfrl.agents.trpo:Surrogate objective improve: 0.030574477670597844\n",
      "INFO:pfrl.agents.trpo:KL divergence: 0.005994653794914484\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:383300 episode:759 R:148.41266646227578\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 55.619522), ('average_entropy', 10.94963), ('average_kl', 0.006239177389560561), ('average_policy_step_size', 1.0), ('explained_variance', 0.8523254857203315)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:154.76875582178278\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:383800 episode:760 R:103.73280480784278\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 54.461838), ('average_entropy', 10.947403), ('average_kl', 0.006239177389560561), ('average_policy_step_size', 1.0), ('explained_variance', 0.8523254857203315)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:384300 episode:761 R:88.2405151182274\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 48.65657), ('average_entropy', 10.945177), ('average_kl', 0.006239177389560561), ('average_policy_step_size', 1.0), ('explained_variance', 0.8523254857203315)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:159.14818309444053\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:384800 episode:762 R:150.50838034595316\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 50.447487), ('average_entropy', 10.945177), ('average_kl', 0.006239177389560561), ('average_policy_step_size', 1.0), ('explained_variance', 0.8523254857203315)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:132.83340431216448\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:385300 episode:763 R:141.06269025270748\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 54.240585), ('average_entropy', 10.945177), ('average_kl', 0.006239177389560561), ('average_policy_step_size', 1.0), ('explained_variance', 0.8523254857203315)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:385800 episode:764 R:158.8431477211385\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 54.05778), ('average_entropy', 10.945177), ('average_kl', 0.006239177389560561), ('average_policy_step_size', 1.0), ('explained_variance', 0.8523254857203315)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:144.55443339791944\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:386300 episode:765 R:136.8432356892861\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 51.258778), ('average_entropy', 10.945177), ('average_kl', 0.006239177389560561), ('average_policy_step_size', 1.0), ('explained_variance', 0.8523254857203315)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:386800 episode:766 R:158.16913827468002\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 50.66243), ('average_entropy', 10.945177), ('average_kl', 0.006239177389560561), ('average_policy_step_size', 1.0), ('explained_variance', 0.8523254857203315)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:145.56943415285076\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:387300 episode:767 R:150.06221618644244\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 55.295773), ('average_entropy', 10.945177), ('average_kl', 0.006239177389560561), ('average_policy_step_size', 1.0), ('explained_variance', 0.8523254857203315)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:145.54705293903342\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:387800 episode:768 R:157.73610095349838\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 57.13467), ('average_entropy', 10.945177), ('average_kl', 0.006239177389560561), ('average_policy_step_size', 1.0), ('explained_variance', 0.8523254857203315)]\n",
      "INFO:pfrl.agents.trpo:Line search iteration: 0 step size: 1.0\n",
      "INFO:pfrl.agents.trpo:Surrogate objective improve: 0.05106731607520487\n",
      "INFO:pfrl.agents.trpo:KL divergence: 0.005093216430395842\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:388300 episode:769 R:148.1702149776453\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 56.57369), ('average_entropy', 10.945177), ('average_kl', 0.006224294779701279), ('average_policy_step_size', 1.0), ('explained_variance', 0.7411603322823316)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:126.59100348901755\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:388800 episode:770 R:153.06905894537036\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 55.90382), ('average_entropy', 10.948309), ('average_kl', 0.006224294779701279), ('average_policy_step_size', 1.0), ('explained_variance', 0.7411603322823316)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:23.02413306619412\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:389300 episode:771 R:135.19476899519597\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 55.113968), ('average_entropy', 10.951442), ('average_kl', 0.006224294779701279), ('average_policy_step_size', 1.0), ('explained_variance', 0.7411603322823316)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:389800 episode:772 R:145.9057730657698\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 53.218845), ('average_entropy', 10.951442), ('average_kl', 0.006224294779701279), ('average_policy_step_size', 1.0), ('explained_variance', 0.7411603322823316)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:147.1546145833564\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:390300 episode:773 R:159.24230417518223\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 53.31399), ('average_entropy', 10.951442), ('average_kl', 0.006224294779701279), ('average_policy_step_size', 1.0), ('explained_variance', 0.7411603322823316)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:390800 episode:774 R:135.5519344693457\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 52.739727), ('average_entropy', 10.951442), ('average_kl', 0.006224294779701279), ('average_policy_step_size', 1.0), ('explained_variance', 0.7411603322823316)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:142.69172080410806\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:391300 episode:775 R:129.80646576357566\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 51.048557), ('average_entropy', 10.951442), ('average_kl', 0.006224294779701279), ('average_policy_step_size', 1.0), ('explained_variance', 0.7411603322823316)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:145.89908754970398\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:391800 episode:776 R:138.98411257523543\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 53.306973), ('average_entropy', 10.951442), ('average_kl', 0.006224294779701279), ('average_policy_step_size', 1.0), ('explained_variance', 0.7411603322823316)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:392300 episode:777 R:99.03990357487548\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 50.528103), ('average_entropy', 10.951442), ('average_kl', 0.006224294779701279), ('average_policy_step_size', 1.0), ('explained_variance', 0.7411603322823316)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:150.67337233535403\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:392800 episode:778 R:159.06180587467315\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 50.115566), ('average_entropy', 10.951442), ('average_kl', 0.006224294779701279), ('average_policy_step_size', 1.0), ('explained_variance', 0.7411603322823316)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:150.85793292819835\n",
      "INFO:pfrl.agents.trpo:Line search iteration: 0 step size: 1.0\n",
      "INFO:pfrl.agents.trpo:Surrogate objective improve: 0.04371338943747105\n",
      "INFO:pfrl.agents.trpo:KL divergence: 0.004896269645541906\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:393300 episode:779 R:151.7222362197213\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 54.955124), ('average_entropy', 10.951442), ('average_kl', 0.006207268816442826), ('average_policy_step_size', 1.0), ('explained_variance', 0.8071264717138438)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:393800 episode:780 R:132.1684930226737\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 50.164616), ('average_entropy', 10.947992), ('average_kl', 0.006207268816442826), ('average_policy_step_size', 1.0), ('explained_variance', 0.8071264717138438)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:154.57212009324743\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:394300 episode:781 R:143.11593832891077\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 49.6512), ('average_entropy', 10.944543), ('average_kl', 0.006207268816442826), ('average_policy_step_size', 1.0), ('explained_variance', 0.8071264717138438)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:394800 episode:782 R:127.58264194205083\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 51.12143), ('average_entropy', 10.944543), ('average_kl', 0.006207268816442826), ('average_policy_step_size', 1.0), ('explained_variance', 0.8071264717138438)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:143.23994130544634\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:395300 episode:783 R:145.39440963506502\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 50.65109), ('average_entropy', 10.944543), ('average_kl', 0.006207268816442826), ('average_policy_step_size', 1.0), ('explained_variance', 0.8071264717138438)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:148.39730009671342\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:395800 episode:784 R:154.50853433606352\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 50.50222), ('average_entropy', 10.944543), ('average_kl', 0.006207268816442826), ('average_policy_step_size', 1.0), ('explained_variance', 0.8071264717138438)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:396300 episode:785 R:152.2732688548364\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 50.79643), ('average_entropy', 10.944543), ('average_kl', 0.006207268816442826), ('average_policy_step_size', 1.0), ('explained_variance', 0.8071264717138438)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:144.00795878035314\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:396800 episode:786 R:148.63903009902654\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 55.018288), ('average_entropy', 10.944543), ('average_kl', 0.006207268816442826), ('average_policy_step_size', 1.0), ('explained_variance', 0.8071264717138438)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:131.65823829444145\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:397300 episode:787 R:198.70985797487617\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 55.956303), ('average_entropy', 10.944543), ('average_kl', 0.006207268816442826), ('average_policy_step_size', 1.0), ('explained_variance', 0.8071264717138438)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:397800 episode:788 R:134.34566091548095\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 55.65051), ('average_entropy', 10.944543), ('average_kl', 0.006207268816442826), ('average_policy_step_size', 1.0), ('explained_variance', 0.8071264717138438)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:144.79242722533562\n",
      "INFO:pfrl.agents.trpo:Line search iteration: 0 step size: 1.0\n",
      "INFO:pfrl.agents.trpo:Surrogate objective improve: 0.03471868013139101\n",
      "INFO:pfrl.agents.trpo:KL divergence: 0.005252012517303228\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:398300 episode:789 R:149.39009425104513\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 56.649704), ('average_entropy', 10.944543), ('average_kl', 0.006195176964554983), ('average_policy_step_size', 1.0), ('explained_variance', 0.7902202786501175)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:398800 episode:790 R:151.76542557352593\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 54.428658), ('average_entropy', 10.933572), ('average_kl', 0.006195176964554983), ('average_policy_step_size', 1.0), ('explained_variance', 0.7902202786501175)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:137.49850887008753\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:399300 episode:791 R:148.6002545778949\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 51.874207), ('average_entropy', 10.922603), ('average_kl', 0.006195176964554983), ('average_policy_step_size', 1.0), ('explained_variance', 0.7902202786501175)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:147.76865106450816\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:399800 episode:792 R:229.4245427939326\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 53.926323), ('average_entropy', 10.922603), ('average_kl', 0.006195176964554983), ('average_policy_step_size', 1.0), ('explained_variance', 0.7902202786501175)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:400300 episode:793 R:143.64874784139099\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 55.06534), ('average_entropy', 10.922603), ('average_kl', 0.006195176964554983), ('average_policy_step_size', 1.0), ('explained_variance', 0.7902202786501175)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:148.72206803448253\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:400800 episode:794 R:126.74220951097479\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 51.04129), ('average_entropy', 10.922603), ('average_kl', 0.006195176964554983), ('average_policy_step_size', 1.0), ('explained_variance', 0.7902202786501175)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:142.98224189216273\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:401300 episode:795 R:148.28083164366987\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 51.525368), ('average_entropy', 10.922603), ('average_kl', 0.006195176964554983), ('average_policy_step_size', 1.0), ('explained_variance', 0.7902202786501175)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:401800 episode:796 R:130.34505600174595\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 55.858406), ('average_entropy', 10.922603), ('average_kl', 0.006195176964554983), ('average_policy_step_size', 1.0), ('explained_variance', 0.7902202786501175)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:148.39734344746506\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:402300 episode:797 R:150.30088924035977\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 55.750782), ('average_entropy', 10.922603), ('average_kl', 0.006195176964554983), ('average_policy_step_size', 1.0), ('explained_variance', 0.7902202786501175)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:402800 episode:798 R:148.28026691753797\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 55.749218), ('average_entropy', 10.922603), ('average_kl', 0.006195176964554983), ('average_policy_step_size', 1.0), ('explained_variance', 0.7902202786501175)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:148.93731797392692\n",
      "INFO:pfrl.agents.trpo:Line search iteration: 0 step size: 1.0\n",
      "INFO:pfrl.agents.trpo:Surrogate objective improve: 0.03748535524937324\n",
      "INFO:pfrl.agents.trpo:KL divergence: 0.006170059088617563\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:403300 episode:799 R:127.85737656257947\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 52.21598), ('average_entropy', 10.922603), ('average_kl', 0.006194862991105765), ('average_policy_step_size', 1.0), ('explained_variance', 0.7214885862943324)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:149.94061449625528\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:403800 episode:800 R:137.08358257436058\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 52.650837), ('average_entropy', 10.923407), ('average_kl', 0.006194862991105765), ('average_policy_step_size', 1.0), ('explained_variance', 0.7214885862943324)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:404300 episode:801 R:137.72838299217747\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 56.32872), ('average_entropy', 10.9242115), ('average_kl', 0.006194862991105765), ('average_policy_step_size', 1.0), ('explained_variance', 0.7214885862943324)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:143.60605598200115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:404800 episode:802 R:142.30380089855583\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 56.204327), ('average_entropy', 10.9242115), ('average_kl', 0.006194862991105765), ('average_policy_step_size', 1.0), ('explained_variance', 0.7214885862943324)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:139.85047291773145\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:405300 episode:803 R:143.21716827210415\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 56.7736), ('average_entropy', 10.9242115), ('average_kl', 0.006194862991105765), ('average_policy_step_size', 1.0), ('explained_variance', 0.7214885862943324)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:405800 episode:804 R:127.19913625840488\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 54.985603), ('average_entropy', 10.9242115), ('average_kl', 0.006194862991105765), ('average_policy_step_size', 1.0), ('explained_variance', 0.7214885862943324)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:95.81031913112999\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:406300 episode:805 R:148.9273387325834\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 55.10232), ('average_entropy', 10.9242115), ('average_kl', 0.006194862991105765), ('average_policy_step_size', 1.0), ('explained_variance', 0.7214885862943324)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:406800 episode:806 R:145.7893860413626\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 56.058643), ('average_entropy', 10.9242115), ('average_kl', 0.006194862991105765), ('average_policy_step_size', 1.0), ('explained_variance', 0.7214885862943324)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:150.1898813469531\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:407300 episode:807 R:148.03627206418605\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 54.217422), ('average_entropy', 10.9242115), ('average_kl', 0.006194862991105765), ('average_policy_step_size', 1.0), ('explained_variance', 0.7214885862943324)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:143.40071848854734\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:407800 episode:808 R:141.75896246720544\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 54.484146), ('average_entropy', 10.9242115), ('average_kl', 0.006194862991105765), ('average_policy_step_size', 1.0), ('explained_variance', 0.7214885862943324)]\n",
      "INFO:pfrl.agents.trpo:Line search iteration: 0 step size: 1.0\n",
      "INFO:pfrl.agents.trpo:Surrogate objective improve: 0.0340126458031591\n",
      "INFO:pfrl.agents.trpo:KL divergence: 0.006147542968392372\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:408300 episode:809 R:145.34600922330395\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 54.25489), ('average_entropy', 10.9242115), ('average_kl', 0.006194278793294488), ('average_policy_step_size', 1.0), ('explained_variance', 0.6506106796215831)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:150.85078483187925\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:408800 episode:810 R:73.69404015529497\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 38.59806), ('average_entropy', 10.928964), ('average_kl', 0.006194278793294488), ('average_policy_step_size', 1.0), ('explained_variance', 0.6506106796215831)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:145.102121860988\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:409300 episode:811 R:137.57801728754583\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 40.121895), ('average_entropy', 10.933715), ('average_kl', 0.006194278793294488), ('average_policy_step_size', 1.0), ('explained_variance', 0.6506106796215831)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:409800 episode:812 R:132.44955244868774\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 55.157444), ('average_entropy', 10.933715), ('average_kl', 0.006194278793294488), ('average_policy_step_size', 1.0), ('explained_variance', 0.6506106796215831)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:150.07141028640544\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:410300 episode:813 R:41.71314135176418\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 33.38807), ('average_entropy', 10.933715), ('average_kl', 0.006194278793294488), ('average_policy_step_size', 1.0), ('explained_variance', 0.6506106796215831)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:410800 episode:814 R:143.46152864723462\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 32.954258), ('average_entropy', 10.933715), ('average_kl', 0.006194278793294488), ('average_policy_step_size', 1.0), ('explained_variance', 0.6506106796215831)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:147.00645461618322\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:411300 episode:815 R:151.3599243404193\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 54.869793), ('average_entropy', 10.933715), ('average_kl', 0.006194278793294488), ('average_policy_step_size', 1.0), ('explained_variance', 0.6506106796215831)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:137.5843366161157\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:411800 episode:816 R:143.29599657771703\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 54.43776), ('average_entropy', 10.933715), ('average_kl', 0.006194278793294488), ('average_policy_step_size', 1.0), ('explained_variance', 0.6506106796215831)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:412300 episode:817 R:70.17875420772253\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 54.747997), ('average_entropy', 10.933715), ('average_kl', 0.006194278793294488), ('average_policy_step_size', 1.0), ('explained_variance', 0.6506106796215831)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:147.50662508229405\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:412800 episode:818 R:137.46136816294978\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 57.177948), ('average_entropy', 10.933715), ('average_kl', 0.006194278793294488), ('average_policy_step_size', 1.0), ('explained_variance', 0.6506106796215831)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:130.0812667721204\n",
      "INFO:pfrl.agents.trpo:Line search iteration: 0 step size: 1.0\n",
      "INFO:pfrl.agents.trpo:Surrogate objective improve: 0.038416699186200276\n",
      "INFO:pfrl.agents.trpo:KL divergence: 0.005973064806312323\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:413300 episode:819 R:145.31462116948188\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 56.908844), ('average_entropy', 10.933715), ('average_kl', 0.006191581061745926), ('average_policy_step_size', 1.0), ('explained_variance', 0.9765327351001888)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:413800 episode:820 R:147.51206802542293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 55.003326), ('average_entropy', 10.925545), ('average_kl', 0.006191581061745926), ('average_policy_step_size', 1.0), ('explained_variance', 0.9765327351001888)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:125.55316825972746\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:414300 episode:821 R:145.61209952275001\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 54.930866), ('average_entropy', 10.917374), ('average_kl', 0.006191581061745926), ('average_policy_step_size', 1.0), ('explained_variance', 0.9765327351001888)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:414800 episode:822 R:143.13789185710803\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 56.240807), ('average_entropy', 10.917374), ('average_kl', 0.006191581061745926), ('average_policy_step_size', 1.0), ('explained_variance', 0.9765327351001888)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:154.07423959743252\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:415300 episode:823 R:169.8404342485085\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 56.658947), ('average_entropy', 10.917374), ('average_kl', 0.006191581061745926), ('average_policy_step_size', 1.0), ('explained_variance', 0.9765327351001888)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:138.130124032957\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:415800 episode:824 R:143.34576623043864\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 56.211796), ('average_entropy', 10.917374), ('average_kl', 0.006191581061745926), ('average_policy_step_size', 1.0), ('explained_variance', 0.9765327351001888)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:416300 episode:825 R:139.0496086898409\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 55.395782), ('average_entropy', 10.917374), ('average_kl', 0.006191581061745926), ('average_policy_step_size', 1.0), ('explained_variance', 0.9765327351001888)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:89.58707915407228\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:416800 episode:826 R:140.32433360749798\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 55.595085), ('average_entropy', 10.917374), ('average_kl', 0.006191581061745926), ('average_policy_step_size', 1.0), ('explained_variance', 0.9765327351001888)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:158.69148395891415\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:417300 episode:827 R:151.6084695087829\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 54.208202), ('average_entropy', 10.917374), ('average_kl', 0.006191581061745926), ('average_policy_step_size', 1.0), ('explained_variance', 0.9765327351001888)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:417800 episode:828 R:153.88618013090075\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 54.61717), ('average_entropy', 10.917374), ('average_kl', 0.006191581061745926), ('average_policy_step_size', 1.0), ('explained_variance', 0.9765327351001888)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:152.57318756554176\n",
      "INFO:pfrl.agents.trpo:Line search iteration: 0 step size: 1.0\n",
      "INFO:pfrl.agents.trpo:Surrogate objective improve: 0.029437203800625866\n",
      "INFO:pfrl.agents.trpo:KL divergence: 0.00603820476680994\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:418300 episode:829 R:153.2718871867762\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 56.99824), ('average_entropy', 10.917374), ('average_kl', 0.0061897331545780225), ('average_policy_step_size', 1.0), ('explained_variance', 0.6449184281326007)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:418800 episode:830 R:111.1412135683304\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 55.82094), ('average_entropy', 10.913752), ('average_kl', 0.0061897331545780225), ('average_policy_step_size', 1.0), ('explained_variance', 0.6449184281326007)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:150.79258430000715\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:419300 episode:831 R:171.61478049258554\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 54.77825), ('average_entropy', 10.9101305), ('average_kl', 0.0061897331545780225), ('average_policy_step_size', 1.0), ('explained_variance', 0.6449184281326007)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:123.52381083063568\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:419800 episode:832 R:152.37887527965785\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 54.786552), ('average_entropy', 10.9101305), ('average_kl', 0.0061897331545780225), ('average_policy_step_size', 1.0), ('explained_variance', 0.6449184281326007)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:420300 episode:833 R:140.2053075107512\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 54.860237), ('average_entropy', 10.9101305), ('average_kl', 0.0061897331545780225), ('average_policy_step_size', 1.0), ('explained_variance', 0.6449184281326007)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:147.57875302905236\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:420800 episode:834 R:99.2184469770607\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 54.037415), ('average_entropy', 10.9101305), ('average_kl', 0.0061897331545780225), ('average_policy_step_size', 1.0), ('explained_variance', 0.6449184281326007)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:100.51377908344448\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:421300 episode:835 R:145.22247334681467\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 54.327938), ('average_entropy', 10.9101305), ('average_kl', 0.0061897331545780225), ('average_policy_step_size', 1.0), ('explained_variance', 0.6449184281326007)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:421800 episode:836 R:142.44706439118417\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 55.802853), ('average_entropy', 10.9101305), ('average_kl', 0.0061897331545780225), ('average_policy_step_size', 1.0), ('explained_variance', 0.6449184281326007)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:137.07919811995356\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:422300 episode:837 R:139.2087066016232\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 56.556), ('average_entropy', 10.9101305), ('average_kl', 0.0061897331545780225), ('average_policy_step_size', 1.0), ('explained_variance', 0.6449184281326007)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:422800 episode:838 R:142.27394187687435\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 56.16379), ('average_entropy', 10.9101305), ('average_kl', 0.0061897331545780225), ('average_policy_step_size', 1.0), ('explained_variance', 0.6449184281326007)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:120.48094545950676\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pfrl.agents.trpo:Line search iteration: 0 step size: 1.0\n",
      "INFO:pfrl.agents.trpo:Surrogate objective improve: 0.04205893170001218\n",
      "INFO:pfrl.agents.trpo:KL divergence: 0.005277795251458883\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:423300 episode:839 R:59.84289169641732\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 40.80189), ('average_entropy', 10.9101305), ('average_kl', 0.006178876750969461), ('average_policy_step_size', 1.0), ('explained_variance', 0.9307349164506944)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:134.2821898578202\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:423800 episode:840 R:82.55282263693898\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 30.373318), ('average_entropy', 10.91127), ('average_kl', 0.006178876750969461), ('average_policy_step_size', 1.0), ('explained_variance', 0.9307349164506944)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:424300 episode:841 R:168.2022077672196\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 45.757008), ('average_entropy', 10.91241), ('average_kl', 0.006178876750969461), ('average_policy_step_size', 1.0), ('explained_variance', 0.9307349164506944)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:146.66951146971968\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:424800 episode:842 R:151.1690257101182\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 57.36088), ('average_entropy', 10.91241), ('average_kl', 0.006178876750969461), ('average_policy_step_size', 1.0), ('explained_variance', 0.9307349164506944)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:104.97095997686749\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:425300 episode:843 R:141.44336812231472\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 55.539852), ('average_entropy', 10.91241), ('average_kl', 0.006178876750969461), ('average_policy_step_size', 1.0), ('explained_variance', 0.9307349164506944)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:425800 episode:844 R:139.0409211022185\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 49.69081), ('average_entropy', 10.91241), ('average_kl', 0.006178876750969461), ('average_policy_step_size', 1.0), ('explained_variance', 0.9307349164506944)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:126.7699223462193\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:426300 episode:845 R:107.53409753412495\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 47.85549), ('average_entropy', 10.91241), ('average_kl', 0.006178876750969461), ('average_policy_step_size', 1.0), ('explained_variance', 0.9307349164506944)]\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:426800 episode:846 R:147.64130136469672\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 53.47439), ('average_entropy', 10.91241), ('average_kl', 0.006178876750969461), ('average_policy_step_size', 1.0), ('explained_variance', 0.9307349164506944)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:155.20665783237033\n",
      "INFO:pfrl.experiments.train_agent:outdir:results\\74b7ccfb1886c5e2ff20c581aa398dfd7298d1cf-00000000-1554415f step:427300 episode:847 R:131.48571885251621\n",
      "INFO:pfrl.experiments.train_agent:statistics:[('average_value', 55.57617), ('average_entropy', 10.91241), ('average_kl', 0.006178876750969461), ('average_policy_step_size', 1.0), ('explained_variance', 0.9307349164506944)]\n",
      "INFO:pfrl.experiments.train_agent:evaluation episode 0 length:500 R:101.58374831188665\n"
     ]
    }
   ],
   "source": [
    "# Run training experiments\n",
    "pfrl.experiments.train_agent_with_evaluation(\n",
    "            agent=agent,\n",
    "            env=sawyer_env,\n",
    "            eval_env=make_env(env, seed, outdir),\n",
    "            outdir=outdir,\n",
    "            steps=steps,\n",
    "            step_offset=offset,\n",
    "            eval_n_steps=None,\n",
    "            eval_n_episodes=eval_n_runs,\n",
    "            eval_interval=eval_interval,\n",
    "            train_max_episode_len=timestep_limit,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pfrl.experiments.train_agent_with_evaluation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
